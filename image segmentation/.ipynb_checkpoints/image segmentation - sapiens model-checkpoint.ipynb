{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927e6842-3c61-40d2-85f3-743ee619d7b0",
   "metadata": {},
   "source": [
    "1. download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f259a-c01b-47eb-9adc-3358d8427751",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O sapiens_2b_goliath_best_goliath_mIoU_8179_epoch_181_torchscript.pt2 \\\n",
    "  \"https://huggingface.co/spaces/fashn-ai/sapiens-body-part-segmentation/resolve/main/assets/checkpoints/sapiens_2b_goliath_best_goliath_mIoU_8179_epoch_181_torchscript.pt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34607be2-ea6c-41c9-960d-d07346c14c15",
   "metadata": {},
   "source": [
    "2. send the model to s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362d21d-a7a5-4d33-8c00-f15bf04ddf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Local file (already downloaded in your notebook directory)\n",
    "local_file = \"sapiens_2b_goliath_best_goliath_mIoU_8179_epoch_181_torchscript.pt2\"\n",
    "\n",
    "# S3 info\n",
    "bucket_name = \"ai-bmi-predictor\"\n",
    "s3_key = f\"image-segmentation/sapiens/{local_file}\"  # creates the 'folders' via prefix\n",
    "\n",
    "# Upload\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(local_file, bucket_name, s3_key)\n",
    "\n",
    "print(\"Uploaded to:\", f\"s3://{bucket_name}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea03c80-72ab-4ed5-a326-a71ec6b88faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Creating preprocessing pipeline...\n",
      "Preprocessing pipeline ready.\n",
      "Step 1/7: Loading TorchScript model (this can take a while)...\n",
      "Model loaded and moved to device.\n",
      "Step 2/7: Loading input image...\n",
      "Input image size: 413x627\n",
      "Input image converted to RGB.\n",
      "Step 3/7: Preprocessing image for the model...\n",
      "Preprocessed tensor shape: (1, 3, 1024, 768)\n",
      "Step 4/7: Running model inference (this is usually the slowest step)...\n",
      "Model inference completed.\n",
      "Step 5/7: Postprocessing model output...\n",
      "Resizing logits back to original image size...\n",
      "Segmentation map created.\n",
      "Step 6/7: Creating binary body mask...\n",
      "Binary body mask created.\n",
      "Step 7/7: Saving black-and-white mask image...\n",
      "Done! Mask saved to: man_mask_bw.png\n"
     ]
    }
   ],
   "source": [
    "import cv2                      # OpenCV for loading and saving images\n",
    "import torch                    # PyTorch for running the TorchScript model\n",
    "import numpy as np              # NumPy for array operations\n",
    "from torchvision import transforms  # For image preprocessing\n",
    "import torch.nn.functional as F     # For resizing (interpolation)\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "\n",
    "model_path = \"sapiens_2b_goliath_best_goliath_mIoU_8179_epoch_181_torchscript.pt2\"  # Path to the Sapiens 2B model\n",
    "input_image_path = \"man.png\"                                                        # Input image file\n",
    "output_mask_path = \"man_mask_bw.png\"                                               # Output mask file (black & white)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")              # Use GPU if available, else CPU\n",
    "print(f\"Using device: {device}\")                                                   # Print which device is used\n",
    "\n",
    "# ----------------- PREPROCESSOR -----------------\n",
    "\n",
    "print(\"Creating preprocessing pipeline...\")                                        # Inform about preprocessing creation\n",
    "preprocess = transforms.Compose([                                                  # Define preprocessing steps\n",
    "    transforms.ToPILImage(),                                                       # Convert NumPy array to PIL image\n",
    "    transforms.Resize((1024, 768)),                                                # Resize image to model's expected size\n",
    "    transforms.ToTensor(),                                                         # Convert PIL image to Tensor in [0, 1]\n",
    "    transforms.Normalize(                                                          # Normalize with ImageNet stats\n",
    "        mean=(0.485, 0.456, 0.406),                                                # Mean for each RGB channel\n",
    "        std=(0.229, 0.224, 0.225)                                                  # Std for each RGB channel\n",
    "    ),\n",
    "    transforms.Lambda(lambda x: x.unsqueeze(0))                                    # Add batch dimension -> (1, C, H, W)\n",
    "])\n",
    "print(\"Preprocessing pipeline ready.\")                                             # Confirm preprocessing is ready\n",
    "\n",
    "# ----------------- LOAD MODEL -----------------\n",
    "\n",
    "print(\"Step 1/7: Loading TorchScript model (this can take a while)...\")            # Inform that model loading starts\n",
    "model = torch.jit.load(model_path)                                                # Load the model from disk\n",
    "model = model.eval().to(device)                                                   # Set to eval mode and move to device\n",
    "print(\"Model loaded and moved to device.\")                                        # Confirm model loaded\n",
    "\n",
    "# ----------------- LOAD IMAGE -----------------\n",
    "\n",
    "print(\"Step 2/7: Loading input image...\")                                         # Inform that image loading starts\n",
    "img_bgr = cv2.imread(input_image_path)                                            # Read the image from file (BGR)\n",
    "assert img_bgr is not None, \"Could not load man.png\"                              # Ensure image exists\n",
    "\n",
    "orig_h, orig_w = img_bgr.shape[:2]                                                # Get original height and width\n",
    "print(f\"Input image size: {orig_w}x{orig_h}\")                                     # Print original size\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)                                # Convert BGR to RGB\n",
    "print(\"Input image converted to RGB.\")                                            # Confirm conversion\n",
    "\n",
    "# ----------------- PREPARE TENSOR -----------------\n",
    "\n",
    "print(\"Step 3/7: Preprocessing image for the model...\")                           # Inform preprocessing starts\n",
    "input_tensor = preprocess(img_rgb)                                                # Apply preprocessing pipeline\n",
    "input_tensor = input_tensor.to(device)                                            # Move tensor to device\n",
    "print(f\"Preprocessed tensor shape: {tuple(input_tensor.shape)}\")                  # Print tensor shape\n",
    "\n",
    "# ----------------- RUN MODEL -----------------\n",
    "\n",
    "print(\"Step 4/7: Running model inference (this is usually the slowest step)...\")  # Inform that inference starts\n",
    "with torch.inference_mode():                                                      # Disable gradients for inference\n",
    "    output = model(input_tensor)                                                  # Forward pass through the model\n",
    "print(\"Model inference completed.\")                                               # Confirm inference done\n",
    "\n",
    "# ----------------- POSTPROCESS: GET SEGMENTATION MAP -----------------\n",
    "\n",
    "print(\"Step 5/7: Postprocessing model output...\")                                 # Inform that postprocessing starts\n",
    "logits_small = output[0].cpu()                                                    # Take first output and move to CPU\n",
    "\n",
    "print(\"Resizing logits back to original image size...\")                           # Inform about resizing\n",
    "logits = F.interpolate(                                                           # Resize logits\n",
    "    logits_small.unsqueeze(0),                                                    # Add batch dimension: (1, C, H', W')\n",
    "    size=(orig_h, orig_w),                                                        # Target size (H, W)\n",
    "    mode=\"bilinear\"                                                               # Bilinear interpolation\n",
    ").squeeze(0)                                                                      # Remove batch dimension -> (C, H, W)\n",
    "\n",
    "segmentation_map = logits.argmax(dim=0)                                           # Take argmax over classes -> (H, W)\n",
    "segmentation_map_np = segmentation_map.numpy().astype(np.uint8)                   # Convert to uint8 NumPy array\n",
    "print(\"Segmentation map created.\")                                                # Confirm segmentation done\n",
    "\n",
    "# ----------------- CREATE BINARY BODY MASK -----------------\n",
    "\n",
    "print(\"Step 6/7: Creating binary body mask...\")                                   # Inform that mask creation starts\n",
    "body_mask = (segmentation_map_np != 0).astype(np.uint8)                           # 1 where body, 0 where background\n",
    "body_mask_bw = (body_mask * 255).astype(np.uint8)                                 # Scale to 0 or 255 for B/W\n",
    "print(\"Binary body mask created.\")                                                # Confirm mask ready\n",
    "\n",
    "# ----------------- SAVE RESULT -----------------\n",
    "\n",
    "print(\"Step 7/7: Saving black-and-white mask image...\")                           # Inform that saving starts\n",
    "cv2.imwrite(output_mask_path, body_mask_bw)                                       # Save mask as grayscale PNG\n",
    "print(f\"Done! Mask saved to: {output_mask_path}\")                                 # Final confirmation message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043a354-b5ce-4bf1-bdea-1779b0306ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
