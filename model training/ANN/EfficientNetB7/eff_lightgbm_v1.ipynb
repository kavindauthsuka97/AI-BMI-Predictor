{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a089bb-ebd7-4d32-b8ce-89424733811e",
   "metadata": {},
   "source": [
    "1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca32a18-ee45-42b9-848f-47c53613db38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ab1d061f51c6079633aeceed2faeb0b</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.108145</td>\n",
       "      <td>-0.138813</td>\n",
       "      <td>0.633156</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>-0.046055</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>-0.058632</td>\n",
       "      <td>0.097968</td>\n",
       "      <td>...</td>\n",
       "      <td>105.333900</td>\n",
       "      <td>76.817467</td>\n",
       "      <td>35.362858</td>\n",
       "      <td>65.993683</td>\n",
       "      <td>54.459591</td>\n",
       "      <td>88.813789</td>\n",
       "      <td>16.764332</td>\n",
       "      <td>female</td>\n",
       "      <td>170.50</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e94e2e05fb8b099955bbc4fa5ce81e22</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>-0.093442</td>\n",
       "      <td>0.736929</td>\n",
       "      <td>0.240569</td>\n",
       "      <td>0.089982</td>\n",
       "      <td>-0.112391</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.076110</td>\n",
       "      <td>...</td>\n",
       "      <td>101.478989</td>\n",
       "      <td>85.154358</td>\n",
       "      <td>37.256760</td>\n",
       "      <td>65.861588</td>\n",
       "      <td>52.773052</td>\n",
       "      <td>89.176338</td>\n",
       "      <td>15.690955</td>\n",
       "      <td>male</td>\n",
       "      <td>178.30</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba6951a4f37fc9302243370e927a02e2</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>-0.071332</td>\n",
       "      <td>-0.154407</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.196485</td>\n",
       "      <td>-0.125341</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>-0.027295</td>\n",
       "      <td>0.094879</td>\n",
       "      <td>...</td>\n",
       "      <td>97.488243</td>\n",
       "      <td>81.410393</td>\n",
       "      <td>37.503147</td>\n",
       "      <td>66.042679</td>\n",
       "      <td>57.059261</td>\n",
       "      <td>82.201988</td>\n",
       "      <td>16.686253</td>\n",
       "      <td>male</td>\n",
       "      <td>176.25</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947d16539d4702427aa74f737329ffb9</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>-0.128497</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>-0.089796</td>\n",
       "      <td>-0.011273</td>\n",
       "      <td>...</td>\n",
       "      <td>120.586845</td>\n",
       "      <td>69.361534</td>\n",
       "      <td>34.084633</td>\n",
       "      <td>60.413330</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>102.323845</td>\n",
       "      <td>17.693762</td>\n",
       "      <td>female</td>\n",
       "      <td>152.10</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9326695bf62926ec22690f576a633bba</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>-0.154224</td>\n",
       "      <td>0.528140</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>-0.108486</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>-0.099909</td>\n",
       "      <td>0.080770</td>\n",
       "      <td>...</td>\n",
       "      <td>110.543564</td>\n",
       "      <td>77.160583</td>\n",
       "      <td>38.086231</td>\n",
       "      <td>68.400543</td>\n",
       "      <td>57.172279</td>\n",
       "      <td>107.378578</td>\n",
       "      <td>16.594791</td>\n",
       "      <td>male</td>\n",
       "      <td>171.50</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           photo_id        f1        f2        f3        f4  \\\n",
       "0  6ab1d061f51c6079633aeceed2faeb0b  0.000068  0.108145 -0.138813  0.633156   \n",
       "1  e94e2e05fb8b099955bbc4fa5ce81e22  0.020843  0.026005 -0.093442  0.736929   \n",
       "2  ba6951a4f37fc9302243370e927a02e2  0.014542 -0.071332 -0.154407  0.577781   \n",
       "3  947d16539d4702427aa74f737329ffb9  0.041775  0.075746 -0.128497  0.485010   \n",
       "4  9326695bf62926ec22690f576a633bba  0.004397  0.058590 -0.154224  0.528140   \n",
       "\n",
       "         f5        f6        f7        f8        f9  ...         hip  \\\n",
       "0  0.346266 -0.046055  0.016021 -0.058632  0.097968  ...  105.333900   \n",
       "1  0.240569  0.089982 -0.112391  0.000435 -0.076110  ...  101.478989   \n",
       "2  0.196485 -0.125341 -0.056713 -0.027295  0.094879  ...   97.488243   \n",
       "3  0.120409  0.011227  0.017852 -0.089796 -0.011273  ...  120.586845   \n",
       "4  0.290956 -0.108486 -0.021441 -0.099909  0.080770  ...  110.543564   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh       waist  \\\n",
       "0   76.817467         35.362858           65.993683  54.459591   88.813789   \n",
       "1   85.154358         37.256760           65.861588  52.773052   89.176338   \n",
       "2   81.410393         37.503147           66.042679  57.059261   82.201988   \n",
       "3   69.361534         34.084633           60.413330  65.000000  102.323845   \n",
       "4   77.160583         38.086231           68.400543  57.172279  107.378578   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  16.764332  female     170.50       72.0  \n",
       "1  15.690955    male     178.30       71.8  \n",
       "2  16.686253    male     176.25       76.5  \n",
       "3  17.693762  female     152.10       88.9  \n",
       "4  16.594791    male     171.50       88.4  \n",
       "\n",
       "[5 rows x 5138 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "bucket = \"ai-bmi-predictor\"\n",
    "key = \"data/eff_training.csv\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "data = pd.read_csv(obj[\"Body\"])\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca77b-fb2a-4f3c-9897-29c1e84fcde0",
   "metadata": {},
   "source": [
    "2. data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9d28a-110f-4e9d-9936-f18919462e0e",
   "metadata": {},
   "source": [
    "2.1. categorical encoding for 'gender' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a49b37-abd8-4b37-8802-2c181918c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # import pandas for data handling\n",
    "\n",
    "data['gender'] = data['gender'].astype('category')  # convert 'gender' values to categorical type\n",
    "data['gender'] = data['gender'].cat.codes           # replace 'gender' with its numeric category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73940a3b-8471-40f4-93c3-d720861de107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: gender, dtype: int8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9787987-59e1-42a5-be40-d041b7ec47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['height_cm'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054494a2-7444-472e-837b-ab49865ccca7",
   "metadata": {},
   "source": [
    "2.2. define weight frequencies for class imbalance issue for weight_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e3f129-bcd9-4eb8-b9c6-045dc0d70955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples in dataset: 6134\n",
      "\n",
      "Class frequencies:\n",
      "Class 1 (weight_kg < 60): 1049\n",
      "Class 2 (weight_kg > 100): 514\n",
      "Class 3 (60 <= weight_kg <= 100): 4571\n",
      "\n",
      "Number of classes: 3\n",
      "\n",
      "Class weights (inverse frequency):\n",
      "Weight for Class 1 (weight_kg < 60): 1.9491579281855735\n",
      "Weight for Class 2 (weight_kg > 100): 3.9779507133592737\n",
      "Weight for Class 3 (60 <= weight_kg <= 100): 0.4473127689054182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                     # import pandas for data handling\n",
    "import numpy as np                      # import numpy to help with safe division\n",
    "\n",
    "# Assume 'data' is your DataFrame and already loaded\n",
    "#print(\"Preview of data:\\n\", data.head())  # print first few rows to check data\n",
    "print(\"\\nTotal samples in dataset:\", len(data))  # print total number of rows\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Create boolean masks for the three weight_kg classes\n",
    "# -----------------------------\n",
    "class_1_mask = data['weight_kg'] < 60                      # True where weight_kg is less than 60\n",
    "class_2_mask = data['weight_kg'] > 100                     # True where weight_kg is greater than 100\n",
    "class_3_mask = (data['weight_kg'] >= 60) & (data['weight_kg'] <= 100)  # True where weight is between 60 and 100\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Calculate class frequencies (counts)\n",
    "# -----------------------------\n",
    "freq_class_1 = class_1_mask.sum()          # number of samples with weight_kg < 60\n",
    "freq_class_2 = class_2_mask.sum()          # number of samples with weight_kg > 100\n",
    "freq_class_3 = class_3_mask.sum()          # number of samples with 60 <= weight_kg <= 100\n",
    "\n",
    "print(\"\\nClass frequencies:\")              # header for clarity\n",
    "print(\"Class 1 (weight_kg < 60):\", freq_class_1)   # print frequency of class 1\n",
    "print(\"Class 2 (weight_kg > 100):\", freq_class_2)  # print frequency of class 2\n",
    "print(\"Class 3 (60 <= weight_kg <= 100):\", freq_class_3)  # print frequency of class 3\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Number of classes according to the strategy\n",
    "# -----------------------------\n",
    "num_classes = 3                             # we defined three classes by the rules above\n",
    "print(\"\\nNumber of classes:\", num_classes)  # print number of classes\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compute inverse-frequency weights for each class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------\n",
    "total_samples = len(data)                   # total number of rows in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                # helper function to avoid division by zero\n",
    "    if class_freq == 0:                     # check if a class has zero samples\n",
    "        return np.nan                       # return NaN if no samples exist for that class\n",
    "    return total_samples / (num_classes * class_freq)  # apply weighting formula\n",
    "\n",
    "weight_class_1 = safe_weight(freq_class_1)  # compute weight for class 1\n",
    "weight_class_2 = safe_weight(freq_class_2)  # compute weight for class 2\n",
    "weight_class_3 = safe_weight(freq_class_3)  # compute weight for class 3\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency):\")          # header for class weights\n",
    "print(\"Weight for Class 1 (weight_kg < 60):\", weight_class_1)   # print weight of class 1\n",
    "print(\"Weight for Class 2 (weight_kg > 100):\", weight_class_2)  # print weight of class 2\n",
    "print(\"Weight for Class 3 (60 <= weight_kg <= 100):\", weight_class_3)  # print weight of class 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6008f8b-e977-4bef-ae79-33879ec53c33",
   "metadata": {},
   "source": [
    "2.3. define weight frequencies for class imbalance issue for gender feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f089c02-aff3-4c91-b679-be4b012a9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of gender column:\n",
      " 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: gender, dtype: int8\n",
      "\n",
      "Class frequencies for gender:\n",
      "Class 1: 3650\n",
      "Class 0: 2484\n",
      "\n",
      "Number of gender classes: 2\n",
      "\n",
      "Class weights (inverse frequency) for gender:\n",
      "Weight for class 1: 0.8402739726027397\n",
      "Weight for class 0: 1.2347020933977455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                                      # import numpy for numeric utilities (like NaN)\n",
    "\n",
    "print(\"Preview of gender column:\\n\", data['gender'].head())  # show first few gender values to inspect\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Calculate class frequencies for gender\n",
    "# -----------------------------------\n",
    "gender_counts = data['gender'].value_counts()           # count how many samples belong to each gender class\n",
    "\n",
    "print(\"\\nClass frequencies for gender:\")                # header for class frequency output\n",
    "for gender_class, freq in gender_counts.items():        # loop over each gender class and its frequency\n",
    "    print(f\"Class {gender_class}: {freq}\")              # print the class label and its frequency\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Number of gender classes\n",
    "# -----------------------------------\n",
    "num_gender_classes = len(gender_counts)                 # compute how many distinct gender classes we have\n",
    "print(\"\\nNumber of gender classes:\", num_gender_classes)  # print number of gender classes\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Compute inverse-frequency weights for each gender class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------------\n",
    "total_samples = len(data)                               # total number of samples in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                            # define helper function to compute class weight safely\n",
    "    if class_freq == 0:                                 # check for zero frequency to avoid division by zero\n",
    "        return np.nan                                   # return NaN if a class somehow has zero samples\n",
    "    return total_samples / (num_gender_classes * class_freq)  # apply the inverse-frequency weight formula\n",
    "\n",
    "gender_weights = {}                                     # create an empty dictionary to store weights per class\n",
    "for gender_class, freq in gender_counts.items():        # loop through each gender class and its frequency\n",
    "    gender_weights[gender_class] = safe_weight(freq)    # compute and store the weight for this gender class\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency) for gender:\")  # header for weight output\n",
    "for gender_class, weight in gender_weights.items():     # loop over each class and its weight\n",
    "    print(f\"Weight for class {gender_class}: {weight}\") # print the computed weight for this gender class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981d197-ad20-473e-a854-ffca369ef51e",
   "metadata": {},
   "source": [
    "2.4. weight frequencies for weight classes and gender classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bc2d86a-9f9f-4ab2-8749-8dc2bd7644a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight-class weights: {'weight_<60': 1.9491579281855735, 'weight_>100': 3.9779507133592737, 'weight_60_100': 0.4473127689054182}\n",
      "Gender-class weights: {1: 0.8402739726027397, 0: 1.2347020933977455}\n",
      "\n",
      "Combined weights for each (weight_class, gender_class):\n",
      "weight_<60 & gender 1: 1.6378266755466175\n",
      "weight_<60 & gender 0: 2.4066293742935403\n",
      "weight_>100 & gender 1: 3.3425684487322993\n",
      "weight_>100 & gender 0: 4.9115840732177505\n",
      "weight_60_100 & gender 1: 0.37586527732408703\n",
      "weight_60_100 & gender 0: 0.5522980121710618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np   # import numpy for numeric operations\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Store the already-computed weights for weight classes\n",
    "#    (use the variables you created when handling weight_kg)\n",
    "# -------------------------------------------------\n",
    "weight_class_weights = {                          # dictionary to hold weight-class weights\n",
    "    'weight_<60':  weight_class_1,                # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,                # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3               # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights to check\n",
    "\n",
    "# gender_weights dict is assumed from previous step, e.g. {0: w0, 1: w1}\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights to check\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Multiply each gender class with each weight class\n",
    "#    wi = w_weight * w_gender\n",
    "# -------------------------------------------------\n",
    "combined_weights = {}                                # dictionary to store combined class weights\n",
    "\n",
    "print(\"\\nCombined weights for each (weight_class, gender_class):\")  # header\n",
    "for w_label, w_w in weight_class_weights.items():    # loop over weight classes\n",
    "    for g_label, w_g in gender_weights.items():      # loop over gender classes\n",
    "        wi = w_w * w_g                               # multiply weight and gender class weights\n",
    "        combined_weights[(w_label, g_label)] = wi    # store in dictionary\n",
    "        print(f\"{w_label} & gender {g_label}: {wi}\") # print each combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487c312-8683-4912-9b37-7e99383b1ed4",
   "metadata": {},
   "source": [
    "2.5. create a dictionary for weights and row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806866b5-519d-48b6-be00-77c2fd191d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before adding index column:\n",
      " Index(['photo_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
      "       ...\n",
      "       'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
      "       'waist', 'wrist', 'gender', 'height_cm', 'weight_kg'],\n",
      "      dtype='object', length=5138)\n"
     ]
    }
   ],
   "source": [
    "# Check current columns in the DataFrame\n",
    "print(\"Columns before adding index column:\\n\", data.columns)\n",
    "\n",
    "# Add a new column named 'index' with values from 0 to number_of_rows-1\n",
    "data['index'] = range(len(data))\n",
    "\n",
    "# Move 'index' to the front (optional, just for nicer viewing)\n",
    "cols = ['index'] + [c for c in data.columns if c != 'index']  # build new column order\n",
    "data = data[cols]                                            # reorder columns\n",
    "\n",
    "# Show first few rows to verify the new indexing column\n",
    "#print(\"\\nDataFrame after adding 'index' column:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41807157-b19f-4328-9e9a-faf126794665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight-class weights: {'weight_<60': 1.9491579281855735, 'weight_>100': 3.9779507133592737, 'weight_60_100': 0.4473127689054182}\n",
      "Gender-class weights: {1: 0.8402739726027397, 0: 1.2347020933977455}\n",
      "\n",
      "Building final_weights dictionary...\n",
      "Number of entries in final_weights: 6134\n",
      "First 5 items in final_weights: [(0, 0.5522980121710618), (1, 0.37586527732408703), (2, 0.37586527732408703), (3, 0.5522980121710618), (4, 0.37586527732408703)]\n",
      "\n",
      "Checking entry with index 0...\n",
      "Row 0 -> gender: 0\n",
      "Row 0 -> weight_kg: 72.0\n",
      "Row 0 -> weight class: weight_60_100\n",
      "w_weight for row 0: 0.4473127689054182\n",
      "w_gender for row 0: 1.2347020933977455\n",
      "Combined weight (calculated): 0.5522980121710618\n",
      "Combined weight from final_weights[0]: 0.5522980121710618\n",
      "\n",
      "Saving final_weights dictionary as pickle file...\n",
      "Dictionary saved to 'final_weights.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np               # import numpy for numeric operations\n",
    "import pickle                    # import pickle to save Python objects\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. We assume these already exist:\n",
    "#    - weight_class_1, weight_class_2, weight_class_3\n",
    "#    - gender_weights   (dict: {gender_class: weight})\n",
    "# -------------------------------------------------\n",
    "\n",
    "# create a dictionary of weight-class weights (same as before)\n",
    "weight_class_weights = {         # dictionary mapping weight class labels to their weights\n",
    "    'weight_<60':  weight_class_1,      # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,      # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3     # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Helper function to get the weight class label for a given weight_kg\n",
    "# -------------------------------------------------\n",
    "def get_weight_class(w):         # define a function that receives a single weight value\n",
    "    if w < 60:                   # check if weight is less than 60\n",
    "        return 'weight_<60'      # return label for class 1\n",
    "    elif w > 100:                # check if weight is greater than 100\n",
    "        return 'weight_>100'     # return label for class 2\n",
    "    else:                        # otherwise weight is between 60 and 100 (inclusive)\n",
    "        return 'weight_60_100'   # return label for class 3\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Build dictionary: keys = index values, values = combined weights\n",
    "# -------------------------------------------------\n",
    "final_weights = {}               # create empty dictionary to store final weights\n",
    "\n",
    "print(\"\\nBuilding final_weights dictionary...\")  # message to track progress\n",
    "\n",
    "for _, row in data.iterrows():   # loop over each row of the DataFrame\n",
    "    idx_val = row['index']       # get the value from the 'index' column for this row\n",
    "    gender_val = row['gender']   # get the gender class value for this row\n",
    "    weight_val = row['weight_kg']# get the weight_kg value for this row\n",
    "\n",
    "    w_class = get_weight_class(weight_val)        # determine weight class label from weight_kg\n",
    "    w_weight = weight_class_weights[w_class]      # look up the weight-class weight\n",
    "    w_gender = gender_weights[gender_val]         # look up the gender-class weight\n",
    "\n",
    "    combined_w = w_weight * w_gender             # multiply to get combined weight w_i\n",
    "    final_weights[idx_val] = combined_w          # store combined weight in dictionary with key=index\n",
    "\n",
    "print(\"Number of entries in final_weights:\", len(final_weights))  # print number of entries\n",
    "print(\"First 5 items in final_weights:\", list(final_weights.items())[:5])  # show first few items\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Check index 0: gender, weight_kg, and combined weight\n",
    "# -------------------------------------------------\n",
    "print(\"\\nChecking entry with index 0...\")        # message to show what we're doing\n",
    "\n",
    "row0 = data.loc[data['index'] == 0].iloc[0]      # select the row where 'index' column equals 0\n",
    "\n",
    "gender0 = row0['gender']                         # get gender value for index 0\n",
    "weight0 = row0['weight_kg']                      # get weight_kg value for index 0\n",
    "w_class0 = get_weight_class(weight0)             # get weight class label for index 0\n",
    "\n",
    "w_weight0 = weight_class_weights[w_class0]       # get weight-class weight for index 0\n",
    "w_gender0 = gender_weights[gender0]              # get gender-class weight for index 0\n",
    "combined0_calc = w_weight0 * w_gender0           # calculate combined weight for index 0\n",
    "\n",
    "print(\"Row 0 -> gender:\", gender0)               # print gender class for index 0\n",
    "print(\"Row 0 -> weight_kg:\", weight0)            # print weight_kg for index 0\n",
    "print(\"Row 0 -> weight class:\", w_class0)        # print weight class label for index 0\n",
    "print(\"w_weight for row 0:\", w_weight0)          # print weight-class weight for index 0\n",
    "print(\"w_gender for row 0:\", w_gender0)          # print gender-class weight for index 0\n",
    "print(\"Combined weight (calculated):\", combined0_calc)        # print calculated combined weight\n",
    "print(\"Combined weight from final_weights[0]:\", final_weights[0])  # print value from dictionary\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Save final_weights dictionary as a pickle file\n",
    "# -------------------------------------------------\n",
    "print(\"\\nSaving final_weights dictionary as pickle file...\")   # message to track saving step\n",
    "\n",
    "with open('final_weights.pkl', 'wb') as f:       # open a file named 'final_weights.pkl' in binary write mode\n",
    "    pickle.dump(final_weights, f)                # write dictionary to the file using pickle\n",
    "\n",
    "print(\"Dictionary saved to 'final_weights.pkl'.\")# confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f74299-3350-46fa-a49f-988b733ca1b8",
   "metadata": {},
   "source": [
    "2.6. apply min-max scaling with range -1 to 1 for body measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eedc423f-20a2-4ff2-a8b9-17d1c011c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler   # import the scaler for min-max normalization\n",
    "\n",
    "# list of columns to scale between -1 and 1\n",
    "cols_to_scale = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'height_cm', 'weight_kg'\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))    # create a scaler that maps values to range [-1, 1]\n",
    "\n",
    "data[cols_to_scale] = scaler.fit_transform(     # fit the scaler and transform the selected columns\n",
    "    data[cols_to_scale]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4707456-2e11-4ead-9ab7-534b91ca8d19",
   "metadata": {},
   "source": [
    "3. model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc13570-373f-4fe7-af95-83edf7035fa6",
   "metadata": {},
   "source": [
    "3.1. Split the data for independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66bbc6ec-221b-4c89-b3ec-7bfa429e0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "Shape of Y (samples, targets): (6134, 14)\n",
      "Shape of X (samples, features): (6134, 5122)\n"
     ]
    }
   ],
   "source": [
    "# 3.1. split the data for independent and dependent features\n",
    "\n",
    "# List of columns to be used as dependent (target) features\n",
    "target_cols = [\n",
    "    'ankle',              # target: ankle circumference\n",
    "    'arm-length',         # target: arm length\n",
    "    'bicep',              # target: bicep circumference\n",
    "    'calf',               # target: calf circumference\n",
    "    'chest',              # target: chest circumference\n",
    "    'forearm',            # target: forearm circumference\n",
    "    'hip',                # target: hip circumference\n",
    "    'leg-length',         # target: leg length\n",
    "    'shoulder-breadth',   # target: shoulder breadth\n",
    "    'shoulder-to-crotch', # target: shoulder-to-crotch distance\n",
    "    'thigh',              # target: thigh circumference\n",
    "    'waist',              # target: waist circumference\n",
    "    'wrist',              # target: wrist circumference\n",
    "    'weight_kg'           # target: body weight (already scaled)\n",
    "]\n",
    "\n",
    "# Select these columns from the DataFrame as the multi-target Y\n",
    "Y = data[target_cols]     # Y will hold all dependent variables for multi-target regression\n",
    "\n",
    "# Columns to drop from X (independent features)\n",
    "drop_cols = ['photo_id', 'subject_id', 'index'] + target_cols  # ID + target columns to remove from feature matrix\n",
    "\n",
    "# Create X by dropping unwanted columns\n",
    "X = data.drop(columns=drop_cols)  # X will contain only independent features (e.g., gender + scaled body measures)\n",
    "\n",
    "# Print shapes to check that everything is correct\n",
    "print(\"Selected target columns:\", target_cols)           # show which columns are used as targets\n",
    "print(\"Shape of Y (samples, targets):\", Y.shape)         # show size of target matrix\n",
    "print(\"Shape of X (samples, features):\", X.shape)        # show size of feature matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a0665-1282-44d3-8e48-e729dd102b17",
   "metadata": {},
   "source": [
    "3.2. Prepare sample weights and train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e5082f-005c-473e-938d-c88cbdaca182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weights shape: (6134,)\n",
      "First 10 sample weights: [0.552298   0.37586528 0.37586528 0.552298   0.37586528 0.552298\n",
      " 0.37586528 0.37586528 0.552298   0.37586528]\n",
      "X_train shape: (4907, 5122)\n",
      "Y_train shape: (4907, 14)\n",
      "X_val shape: (1227, 5122)\n",
      "Y_val shape: (1227, 14)\n",
      "w_train shape: (4907,)\n",
      "w_val shape: (1227,)\n"
     ]
    }
   ],
   "source": [
    "# 3.2. prepare sample weights and train/validation split\n",
    "\n",
    "import numpy as np                                      # numerical operations on arrays\n",
    "import pickle                                           # load saved Python objects\n",
    "from sklearn.model_selection import train_test_split    # split arrays into train and validation sets\n",
    "\n",
    "# Load final sample weights dictionary created in step 2.5\n",
    "with open('final_weights.pkl', 'rb') as f:              # open the pickle file in read-binary mode\n",
    "    final_weights_dict = pickle.load(f)                 # load dictionary {index: combined_weight}\n",
    "\n",
    "# Build sample_weight array, aligned with DataFrame row order via the 'index' column\n",
    "sample_weights = data['index'].map(final_weights_dict).values.astype('float32')  # map each row index to its weight\n",
    "\n",
    "# Print some basic information about the weights\n",
    "print(\"Sample weights shape:\", sample_weights.shape)    # show number of sample weights\n",
    "print(\"First 10 sample weights:\", sample_weights[:10])  # preview the first few weights\n",
    "\n",
    "# Split X, Y, and sample_weights into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val, w_train, w_val = train_test_split(\n",
    "    X,                      # full feature matrix\n",
    "    Y,                      # full target matrix\n",
    "    sample_weights,         # sample weights array\n",
    "    test_size=0.2,          # allocate 20% of data for validation\n",
    "    random_state=42,        # fixed random seed for reproducibility\n",
    "    shuffle=True            # shuffle samples before splitting\n",
    ")\n",
    "\n",
    "# Print shapes of the resulting arrays to verify\n",
    "print(\"X_train shape:\", X_train.shape)                  # shape of training features\n",
    "print(\"Y_train shape:\", Y_train.shape)                  # shape of training targets\n",
    "print(\"X_val shape:\", X_val.shape)                      # shape of validation features\n",
    "print(\"Y_val shape:\", Y_val.shape)                      # shape of validation targets\n",
    "print(\"w_train shape:\", w_train.shape)                  # shape of training weights\n",
    "print(\"w_val shape:\", w_val.shape)                      # shape of validation weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f334be-21c6-4cc1-8bb8-acce390c822d",
   "metadata": {},
   "source": [
    "3.3. Save train/validation arrays and upload them to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1c3ac2f-bb69-4fa0-8e6c-f5b57ffdfd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# 3.3. save train/validation arrays and upload them to S3 for the training job\n",
    "\n",
    "import os                                           # filesystem and path operations\n",
    "import numpy as np                                  # saving numpy arrays\n",
    "import sagemaker                                    # SageMaker SDK\n",
    "from sagemaker.inputs import TrainingInput          # helper class for defining input channels\n",
    "\n",
    "# Create a local root directory to hold temporary .npy files\n",
    "local_data_root = \"local_np_data\"                   # base folder for local numpy data\n",
    "os.makedirs(local_data_root, exist_ok=True)         # create the folder if it does not already exist\n",
    "\n",
    "# Create separate subfolders for training and validation data\n",
    "local_train_dir = os.path.join(local_data_root, \"train\")      # path to local training folder\n",
    "local_val_dir   = os.path.join(local_data_root, \"validation\") # path to local validation folder\n",
    "os.makedirs(local_train_dir, exist_ok=True)         # create training folder if needed\n",
    "os.makedirs(local_val_dir, exist_ok=True)           # create validation folder if needed\n",
    "\n",
    "# Save training arrays as .npy files\n",
    "np.save(os.path.join(local_train_dir, \"X_train.npy\"), X_train)  # save training features\n",
    "np.save(os.path.join(local_train_dir, \"Y_train.npy\"), Y_train)  # save training targets\n",
    "np.save(os.path.join(local_train_dir, \"w_train.npy\"), w_train)  # save training sample weights\n",
    "\n",
    "# Save validation arrays as .npy files\n",
    "np.save(os.path.join(local_val_dir, \"X_val.npy\"), X_val)        # save validation features\n",
    "np.save(os.path.join(local_val_dir, \"Y_val.npy\"), Y_val)        # save validation targets\n",
    "np.save(os.path.join(local_val_dir, \"w_val.npy\"), w_val)        # save validation sample weights\n",
    "\n",
    "# Create a SageMaker session object\n",
    "sess = sagemaker.Session()                         # create a SageMaker session for interacting with AWS\n",
    "\n",
    "# Get the execution role for this notebook environment\n",
    "role = sagemaker.get_execution_role()              # get IAM role that SageMaker will use\n",
    "\n",
    "# Define the S3 bucket and key prefixes used for the training data\n",
    "bucket = \"ai-bmi-predictor\"                        # target S3 bucket\n",
    "base_prefix = \"trained-models/efficientnet-models/train-val-arrays\"  # base S3 prefix for numpy arrays\n",
    "train_prefix = f\"{base_prefix}/train\"              # S3 prefix for training data\n",
    "val_prefix   = f\"{base_prefix}/validation\"         # S3 prefix for validation data\n",
    "\n",
    "# Upload local training folder to S3\n",
    "train_s3_path = sess.upload_data(                  # upload training data to S3\n",
    "    path=local_train_dir,                          # local training folder path\n",
    "    bucket=bucket,                                 # destination S3 bucket\n",
    "    key_prefix=train_prefix                        # S3 key prefix for training data\n",
    ")\n",
    "\n",
    "# Upload local validation folder to S3\n",
    "val_s3_path = sess.upload_data(                    # upload validation data to S3\n",
    "    path=local_val_dir,                            # local validation folder path\n",
    "    bucket=bucket,                                 # destination S3 bucket\n",
    "    key_prefix=val_prefix                          # S3 key prefix for validation data\n",
    ")\n",
    "\n",
    "# Create TrainingInput objects for each channel so SageMaker can mount them in the container\n",
    "train_input = TrainingInput(                       # training channel configuration\n",
    "    s3_data=train_s3_path,                         # S3 path with training .npy files\n",
    "    content_type=\"application/x-npy\"               # MIME type for numpy arrays\n",
    ")\n",
    "\n",
    "validation_input = TrainingInput(                  # validation channel configuration\n",
    "    s3_data=val_s3_path,                           # S3 path with validation .npy files\n",
    "    content_type=\"application/x-npy\"               # MIME type for numpy arrays\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dedd8-be1d-4ad4-b74d-b5735afc0b9f",
   "metadata": {},
   "source": [
    "3.4. LightGBM training script (multi-target, weighted MSE) for SKLearn container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1db7082-99ad-47dd-91cb-3c850d195e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_eff_gbm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_eff_gbm.py\n",
    "# 3.4. LightGBM multi-output regression training script for SageMaker SKLearn container\n",
    "\n",
    "import os                                           # OS utilities for paths and environment variables\n",
    "import numpy as np                                  # numerical operations with arrays\n",
    "import joblib                                       # saving and loading sklearn-style models\n",
    "import boto3                                        # AWS SDK for uploading the model to S3\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor        # wrapper for multi-target regression\n",
    "from sklearn.metrics import mean_squared_error              # function to compute (weighted) MSE\n",
    "\n",
    "from lightgbm import LGBMRegressor                         # LightGBM regressor (ensure lightgbm is installed)\n",
    "\n",
    "def load_data():                                           # function to load .npy arrays from SageMaker channels\n",
    "    train_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")         # directory path for training channel\n",
    "    val_dir   = os.environ.get(\"SM_CHANNEL_VALIDATION\")    # directory path for validation channel\n",
    "\n",
    "    print(f\"Train dir: {train_dir}\")                       # show training directory\n",
    "    print(f\"Validation dir: {val_dir}\")                    # show validation directory\n",
    "\n",
    "    X_train = np.load(os.path.join(train_dir, \"X_train.npy\"))  # load training features\n",
    "    Y_train = np.load(os.path.join(train_dir, \"Y_train.npy\"))  # load training targets\n",
    "    w_train = np.load(os.path.join(train_dir, \"w_train.npy\"))  # load training sample weights\n",
    "\n",
    "    X_val = np.load(os.path.join(val_dir, \"X_val.npy\"))        # load validation features\n",
    "    Y_val = np.load(os.path.join(val_dir, \"Y_val.npy\"))        # load validation targets\n",
    "    w_val = np.load(os.path.join(val_dir, \"w_val.npy\"))        # load validation sample weights\n",
    "\n",
    "    return X_train, Y_train, w_train, X_val, Y_val, w_val      # return all loaded arrays\n",
    "\n",
    "def weighted_mse(y_true, y_pred, sample_weight):               # function to compute weighted MSE\n",
    "    \"\"\"\n",
    "    Compute weighted mean squared error over all targets.      # short description of the function\n",
    "    \"\"\"\n",
    "    return mean_squared_error(                                # use sklearn's mean_squared_error\n",
    "        y_true,                                               # true target values\n",
    "        y_pred,                                               # predicted target values\n",
    "        sample_weight=sample_weight,                          # per-sample weights\n",
    "        multioutput=\"uniform_average\"                         # average error uniformly across all targets\n",
    "    )\n",
    "\n",
    "def main():                                                   # main training function\n",
    "    print(\"Loading data ...\")                                 # status message\n",
    "    X_train, Y_train, w_train, X_val, Y_val, w_val = load_data()  # load training and validation arrays\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)                    # print shape of training features\n",
    "    print(\"Y_train shape:\", Y_train.shape)                    # print shape of training targets\n",
    "    print(\"X_val shape:\", X_val.shape)                        # print shape of validation features\n",
    "    print(\"Y_val shape:\", Y_val.shape)                        # print shape of validation targets\n",
    "\n",
    "    # Define hyper-parameter grids to search over             # comment for grid definition\n",
    "    num_leaves_list      = [35, 100, 200]                     # number of leaves for each tree\n",
    "    boosting_type_list   = ['gbdt', 'dart']                   # boosting type (standard gradient boosting or DART)\n",
    "    learning_rate_list   = [0.1, 0.001, 0.01]                 # learning rates to try\n",
    "    num_boost_round_list = [100, 200, 50]                   # number of boosting iterations (n_estimators)\n",
    "\n",
    "    # Compute total number of combinations                    # comment for combination count\n",
    "    total_combinations = (len(num_leaves_list) *\n",
    "                          len(boosting_type_list) *\n",
    "                          len(learning_rate_list) *\n",
    "                          len(num_boost_round_list))          # multiply all grid dimensions\n",
    "\n",
    "    print(f\"Total hyper-parameter combinations: {total_combinations}\")  # show grid size\n",
    "\n",
    "    best_val_wmse = np.inf                                   # initialize best validation weighted MSE\n",
    "    best_model = None                                        # placeholder for best model\n",
    "    best_params = None                                       # placeholder for best hyper-parameters\n",
    "    combo_counter = 0                                        # counter for combinations\n",
    "\n",
    "    # Manual grid search over all hyper-parameter combinations  # comment for outer loops\n",
    "    for num_leaves in num_leaves_list:                       # loop over num_leaves options\n",
    "        for boosting_type in boosting_type_list:             # loop over boosting types\n",
    "            for learning_rate in learning_rate_list:         # loop over learning rates\n",
    "                for num_boost_round in num_boost_round_list: # loop over number of boosting rounds\n",
    "                    combo_counter += 1                       # increment combination counter\n",
    "\n",
    "                    print(\"\\n======================================\")      # separator for readability\n",
    "                    print(f\"Training combination {combo_counter}/{total_combinations}\")  # show index\n",
    "                    print(f\"num_leaves: {num_leaves}\")                        # print current num_leaves\n",
    "                    print(f\"boosting_type: {boosting_type}\")                  # print current boosting type\n",
    "                    print(f\"learning_rate: {learning_rate}\")                  # print current learning rate\n",
    "                    print(f\"num_boost_round: {num_boost_round}\")              # print current num_boost_round\n",
    "                    print(\"======================================\")          # separator line\n",
    "\n",
    "                    # Define base LightGBM regressor with current hyper-parameters  # comment\n",
    "                    base_model = LGBMRegressor(\n",
    "                        objective=\"regression\",             # regression objective (MSE-based)\n",
    "                        num_leaves=num_leaves,              # number of leaves for each tree\n",
    "                        boosting_type=boosting_type,        # boosting algorithm type\n",
    "                        learning_rate=learning_rate,        # learning rate for boosting\n",
    "                        n_estimators=num_boost_round,       # number of boosting iterations\n",
    "                        random_state=42,                    # random seed for reproducibility\n",
    "                        n_jobs=-1                           # use all available CPU cores\n",
    "                    )\n",
    "\n",
    "                    # Wrap the base model for multi-target regression           # comment\n",
    "                    model = MultiOutputRegressor(\n",
    "                        estimator=base_model                # base LightGBM regressor used for each target\n",
    "                    )\n",
    "\n",
    "                    # Fit the model using training data and sample weights      # comment\n",
    "                    model.fit(\n",
    "                        X_train,                            # training features\n",
    "                        Y_train,                            # training targets\n",
    "                        sample_weight=w_train               # sample weights for balancing\n",
    "                    )\n",
    "\n",
    "                    # Predict on the validation set                             # comment\n",
    "                    Y_val_pred = model.predict(X_val)       # compute predictions for validation inputs\n",
    "\n",
    "                    # Compute weighted MSE on the validation set                # comment\n",
    "                    val_wmse = weighted_mse(\n",
    "                        Y_val,                              # true validation targets\n",
    "                        Y_val_pred,                         # predicted validation targets\n",
    "                        w_val                               # validation sample weights\n",
    "                    )\n",
    "\n",
    "                    print(f\"Validation weighted MSE: {val_wmse:.6f}\")  # show current combination score\n",
    "\n",
    "                    # Check if this model is better than any previous model     # comment\n",
    "                    if val_wmse < best_val_wmse:           # if current score improves best score\n",
    "                        print(\">>> New best model found! Updating best model ...\")  # log improvement\n",
    "                        best_val_wmse = val_wmse           # update best validation weighted MSE\n",
    "                        best_model = model                  # store current model as best\n",
    "                        best_params = {                     # store hyper-parameters of best model\n",
    "                            \"num_leaves\": num_leaves,\n",
    "                            \"boosting_type\": boosting_type,\n",
    "                            \"learning_rate\": learning_rate,\n",
    "                            \"num_boost_round\": num_boost_round\n",
    "                        }\n",
    "\n",
    "    print(\"\\n================ BEST MODEL =================\")      # header for best model summary\n",
    "    print(f\"Best validation weighted MSE: {best_val_wmse}\")    # print best validation weighted MSE\n",
    "    print(\"Best hyper-parameters:\")                            # header for parameters\n",
    "    if best_params is not None:                                # check that best_params exists\n",
    "        for key, value in best_params.items():                 # iterate over parameter dictionary\n",
    "            print(f\"  {key}: {value}\")                         # print each name and value\n",
    "    print(\"=============================================\")      # footer line\n",
    "\n",
    "    # Determine model directory inside the container            # comment\n",
    "    model_dir = os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\")  # get model directory from environment\n",
    "    os.makedirs(model_dir, exist_ok=True)                      # create directory if it does not exist\n",
    "\n",
    "    # Path where the best model will be saved                   # comment\n",
    "    local_model_path = os.path.join(model_dir, \"eff_gbm_v1.pkl\")  # full path to output pickle file\n",
    "\n",
    "    print(f\"\\nSaving best model to {local_model_path} ...\")    # log save path\n",
    "    joblib.dump(best_model, local_model_path)                  # save best model as a pickle file\n",
    "    print(\"Model saved.\")                                      # confirm save\n",
    "\n",
    "    # Upload the saved model directly to the specified S3 bucket # comment\n",
    "    target_bucket = \"ai-bmi-predictor\"                         # S3 bucket where model will be stored\n",
    "    target_key = \"trained-models/efficientnet-models/eff_gbm_v1.pkl\"  # S3 object key for the model\n",
    "\n",
    "    print(f\"Uploading best model to s3://{target_bucket}/{target_key} ...\")  # log upload target\n",
    "    s3_client = boto3.client(\"s3\")                             # create S3 client\n",
    "    s3_client.upload_file(local_model_path, target_bucket, target_key)  # upload model file to S3\n",
    "    print(\"Upload complete.\")                                  # confirm upload\n",
    "\n",
    "if __name__ == \"__main__\":                                     # execute main() when script is run\n",
    "    main()                                                     # call main training function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5633b-02a4-4d3e-af3c-bb6ef8f6fb19",
   "metadata": {},
   "source": [
    "3.5. Configure and launch the SageMaker SKLearn training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48cc3009-9b2d-4757-846e-367a3bde0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt created with contents:\n",
      "lightgbm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NEW CELL: create requirements.txt so the SKLearn container installs LightGBM\n",
    "\n",
    "requirements_text = \"lightgbm\\n\"        # define the contents of requirements.txt (request LightGBM package)\n",
    "\n",
    "with open(\"requirements.txt\", \"w\") as f:  # open a new file named requirements.txt in write mode\n",
    "    f.write(requirements_text)            # write the required packages into the file\n",
    "\n",
    "print(\"requirements.txt created with contents:\")  # confirm that the file was created\n",
    "print(requirements_text)                          # print the contents of requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec13512-1340-48a9-9648-5c9af49e4b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: eff-gbm-v1-training-2025-12-11-07-28-55-278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-11 07:28:57 Starting - Starting the training job...\n",
      "2025-12-11 07:29:11 Starting - Preparing the instances for training......\n",
      "2025-12-11 07:30:16 Downloading - Downloading the training image...\n",
      "2025-12-11 07:30:37 Training - Training image download completed. Training in progress...\u001b[34m/miniconda3/lib/python3.9/site-packages/sagemaker_containers/_server.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:10,439 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:10,441 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:10,443 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:10,453 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:10,651 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting lightgbm (from -r requirements.txt (line 1))\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.0 in /miniconda3/lib/python3.9/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.9/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.8.0)\u001b[0m\n",
      "\u001b[34mDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 105.8 MB/s  0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: lightgbm\u001b[0m\n",
      "\u001b[34mSuccessfully installed lightgbm-4.6.0\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 25.2 -> 25.3\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,278 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,280 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,293 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,295 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,306 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,308 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,319 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c6i.32xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/x-npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"application/x-npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c6i.32xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"eff-gbm-v1-training-2025-12-11-07-28-55-278\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://ai-bmi-predictor/eff-gbm-v1-training-2025-12-11-07-28-55-278/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_eff_gbm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 128,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c6i.32xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c6i.32xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_eff_gbm.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_eff_gbm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c6i.32xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c6i.32xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c6i.32xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c6i.32xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_eff_gbm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=128\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://ai-bmi-predictor/eff-gbm-v1-training-2025-12-11-07-28-55-278/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c6i.32xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c6i.32xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"eff-gbm-v1-training-2025-12-11-07-28-55-278\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://ai-bmi-predictor/eff-gbm-v1-training-2025-12-11-07-28-55-278/source/sourcedir.tar.gz\",\"module_name\":\"train_eff_gbm\",\"network_interface_name\":\"eth0\",\"num_cpus\":128,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c6i.32xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c6i.32xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_eff_gbm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python39.zip:/miniconda3/lib/python3.9:/miniconda3/lib/python3.9/lib-dynload:/miniconda3/lib/python3.9/site-packages:/miniconda3/lib/python3.9/site-packages/setuptools/_vendor\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train_eff_gbm.py\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,319 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-12-11 07:31:11,319 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mLoading data ...\u001b[0m\n",
      "\u001b[34mTrain dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mValidation dir: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mX_train shape: (4907, 5122)\u001b[0m\n",
      "\u001b[34mY_train shape: (4907, 14)\u001b[0m\n",
      "\u001b[34mX_val shape: (1227, 5122)\u001b[0m\n",
      "\u001b[34mY_val shape: (1227, 14)\u001b[0m\n",
      "\u001b[34mTotal hyper-parameter combinations: 54\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 1/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.656390 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.666841 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.665685 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.669545 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.673893 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.671198 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.673367 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683546 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686423 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686637 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691111 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688907 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691481 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692317 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.018874\u001b[0m\n",
      "\u001b[34m>>> New best model found! Updating best model ...\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 2/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693069 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.781928 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.788258 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.784166 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.789386 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698020 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700395 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705617 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705903 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703929 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702197 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701743 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700937 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700160 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.018304\u001b[0m\n",
      "\u001b[34m>>> New best model found! Updating best model ...\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 3/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685949 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688693 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693190 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693241 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695542 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712954 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.803637 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.804211 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.804524 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.804825 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.804812 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.805628 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.804165 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.802797 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.020580\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 4/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.770700 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.767927 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.773647 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.793872 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699784 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693515 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704191 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705755 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711170 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716206 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710042 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713958 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712691 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710853 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.205826\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 5/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683454 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687674 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693879 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700257 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702950 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703577 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701276 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703359 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708368 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707789 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712405 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.819324 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709294 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710174 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.176528\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 6/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.678596 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680875 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684714 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689978 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694505 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698202 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707702 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709503 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714134 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716749 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.720656 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713678 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718006 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718700 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.222787\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 7/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688984 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687313 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690429 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697457 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695791 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701963 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707343 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705920 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707112 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708993 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714486 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715030 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713911 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714397 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.063711\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 8/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686309 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695992 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689974 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694812 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700688 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701586 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703732 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704087 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703855 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706662 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707165 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708021 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718661 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.720134 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.031752\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 9/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688865 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693857 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695066 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.773420 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700902 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708949 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706282 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708889 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.797891 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.803715 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.779063 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.724050 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718051 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717851 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.114811\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 10/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689798 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695186 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697586 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689339 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693901 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698094 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699219 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718505 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715174 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717105 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.721574 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718503 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716247 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711420 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.025678\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 11/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686662 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687583 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688954 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692129 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699179 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700890 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703563 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706451 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712001 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710365 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715278 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715272 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718577 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715220 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.023606\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 12/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691113 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693587 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695127 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701908 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698840 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703577 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705891 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707442 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711328 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707152 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708193 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708606 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707808 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708705 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.032119\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 13/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680857 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687972 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692886 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692932 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694466 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699010 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699205 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704555 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700286 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698680 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709771 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712916 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713960 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715870 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.238180\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 14/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687707 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686797 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689172 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693713 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698358 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705508 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708322 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708106 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712136 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712616 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713231 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.812484 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715561 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715301 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.238753\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 15/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688267 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684690 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691110 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694437 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702180 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701058 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703516 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705547 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711060 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709671 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709549 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709537 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705323 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707151 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.239025\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 16/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680905 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683230 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689646 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695806 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.696437 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699692 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706484 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708294 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708990 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712056 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712154 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711074 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706653 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711217 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.145968\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 17/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688261 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690555 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.772243 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706511 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695123 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697228 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706015 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704401 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713414 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705834 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709818 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711884 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709526 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713796 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.126563\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 18/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 35\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690012 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688194 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691501 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697443 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702793 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.820760 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.824063 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.826658 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709329 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709403 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709217 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714655 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713836 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709898 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.171290\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 19/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684580 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.682147 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686952 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693589 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694309 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698931 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710379 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708668 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708898 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708322 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704536 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706147 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706633 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707938 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.020710\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 20/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.766536 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.781934 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692176 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701519 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697548 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705336 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707854 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710676 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713875 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716936 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.719382 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717619 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.722850 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718573 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.020577\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 21/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683619 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.781049 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688208 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695609 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697457 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699707 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707374 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709143 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710456 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712912 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713233 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717043 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714666 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713210 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.021586\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 22/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685560 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693467 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695406 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695350 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699122 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710007 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710179 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709955 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717590 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705095 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706544 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707469 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707470 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710703 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.205428\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 23/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685426 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687726 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692597 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693348 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695343 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697847 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705483 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712331 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.804027 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711906 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712745 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712679 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708655 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714858 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.175574\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 24/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687325 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692005 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694264 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693343 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701034 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699574 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703128 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707275 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711713 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709330 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714874 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710808 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710731 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717171 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.222608\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 25/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683135 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686543 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693919 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701571 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700989 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704032 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713775 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706421 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707199 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707639 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708792 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709862 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709731 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.781447 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.061933\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 26/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693754 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703335 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705540 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711319 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.723481 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716406 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.821522 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.790053 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704269 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705765 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716164 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717119 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714440 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707887 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.031046\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 27/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: gbdt\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.679447 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683080 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686228 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691658 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695496 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701078 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702336 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708027 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702219 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706982 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704740 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707927 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705263 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714276 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.113066\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 28/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685813 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690668 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685215 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690993 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695247 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699046 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700448 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703560 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706749 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710028 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710817 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706006 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707471 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706803 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.026786\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 29/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680216 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684320 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684691 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690587 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697339 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704103 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706873 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712784 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709171 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713522 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.814773 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.815984 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712501 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710941 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.025249\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 30/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.1\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684076 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690719 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688522 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701319 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700767 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700783 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.703192 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709692 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710445 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708895 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708035 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707523 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706359 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705593 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.032504\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 31/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.681016 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.682811 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686892 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691375 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.697043 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701978 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701958 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704372 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705064 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707545 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.801313 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.707477 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713204 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713832 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.238038\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 32/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686039 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687785 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691015 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.691568 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698548 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.700712 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708919 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708025 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.713110 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716613 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714272 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711822 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714283 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710482 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.238556\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 33/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.001\u001b[0m\n",
      "\u001b[34mnum_boost_round: 50\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680387 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.681897 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685940 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693811 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702834 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.702821 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711439 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.119297\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.708780 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.193206\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712656 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.214917\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709445 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711977 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.712375 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710389 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710799 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.238926\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 34/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 100\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.718484 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.077609\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.717023 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.171584\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711500 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.064251\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.709931 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.014923\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.710331 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.012611\u001b[0m\n",
      "\u001b[34mValidation weighted MSE: 0.144656\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 35/54\u001b[0m\n",
      "\u001b[34mnum_leaves: 100\u001b[0m\n",
      "\u001b[34mboosting_type: dart\u001b[0m\n",
      "\u001b[34mlearning_rate: 0.01\u001b[0m\n",
      "\u001b[34mnum_boost_round: 200\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.681423 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.010122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685488 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.562611\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.789154 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.002565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.786652 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.068932\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.791354 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.036365\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.818563 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 1305844\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 5122\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score -0.047772\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# UPDATED CELL: configure and launch the SageMaker SKLearn training job for LightGBM\n",
    "\n",
    "from sagemaker.sklearn import SKLearn                 # import the SKLearn estimator class from SageMaker\n",
    "\n",
    "# define the SKLearn estimator that will run train_eff_gbm.py inside the SKLearn container\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train_eff_gbm.py\",                   # training script that runs the LightGBM grid search\n",
    "    dependencies=[\"requirements.txt\"],                # extra files to package with the script (installs lightgbm)\n",
    "    role=role,                                       # IAM role used by the training job\n",
    "    instance_type=\"ml.c6i.32xlarge\",                   # instance type for the training job\n",
    "    instance_count=1,                                # number of instances for training\n",
    "    framework_version=\"1.2-1\",                       # version of the SKLearn SageMaker container\n",
    "    py_version=\"py3\",                                # Python version in the container\n",
    "    sagemaker_session=sess,                          # SageMaker session created earlier\n",
    "    base_job_name=\"eff-gbm-v1-training\",             # base name for the training job\n",
    "    output_path=\"s3://ai-bmi-predictor/trained-models/efficientnet-models/\"  # S3 path for model artifacts\n",
    ")\n",
    "\n",
    "# launch the training job with the prepared S3 inputs for train and validation channels\n",
    "sklearn_estimator.fit(\n",
    "    inputs={                                         # map channel names to TrainingInput objects\n",
    "        \"train\": train_input,                        # training data channel\n",
    "        \"validation\": validation_input               # validation data channel\n",
    "    },\n",
    "    wait=True,                                       # wait until the training job completes\n",
    "    logs=\"All\"                                       # stream all logs from the training job into the notebook\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e81fc-4a8f-4bb9-90f5-6128dcb027a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
