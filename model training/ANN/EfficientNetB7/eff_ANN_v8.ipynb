{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a089bb-ebd7-4d32-b8ce-89424733811e",
   "metadata": {},
   "source": [
    "1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca32a18-ee45-42b9-848f-47c53613db38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ab1d061f51c6079633aeceed2faeb0b</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.108145</td>\n",
       "      <td>-0.138813</td>\n",
       "      <td>0.633156</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>-0.046055</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>-0.058632</td>\n",
       "      <td>0.097968</td>\n",
       "      <td>...</td>\n",
       "      <td>105.333900</td>\n",
       "      <td>76.817467</td>\n",
       "      <td>35.362858</td>\n",
       "      <td>65.993683</td>\n",
       "      <td>54.459591</td>\n",
       "      <td>88.813789</td>\n",
       "      <td>16.764332</td>\n",
       "      <td>female</td>\n",
       "      <td>170.50</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e94e2e05fb8b099955bbc4fa5ce81e22</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>-0.093442</td>\n",
       "      <td>0.736929</td>\n",
       "      <td>0.240569</td>\n",
       "      <td>0.089982</td>\n",
       "      <td>-0.112391</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.076110</td>\n",
       "      <td>...</td>\n",
       "      <td>101.478989</td>\n",
       "      <td>85.154358</td>\n",
       "      <td>37.256760</td>\n",
       "      <td>65.861588</td>\n",
       "      <td>52.773052</td>\n",
       "      <td>89.176338</td>\n",
       "      <td>15.690955</td>\n",
       "      <td>male</td>\n",
       "      <td>178.30</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba6951a4f37fc9302243370e927a02e2</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>-0.071332</td>\n",
       "      <td>-0.154407</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.196485</td>\n",
       "      <td>-0.125341</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>-0.027295</td>\n",
       "      <td>0.094879</td>\n",
       "      <td>...</td>\n",
       "      <td>97.488243</td>\n",
       "      <td>81.410393</td>\n",
       "      <td>37.503147</td>\n",
       "      <td>66.042679</td>\n",
       "      <td>57.059261</td>\n",
       "      <td>82.201988</td>\n",
       "      <td>16.686253</td>\n",
       "      <td>male</td>\n",
       "      <td>176.25</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947d16539d4702427aa74f737329ffb9</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>-0.128497</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>-0.089796</td>\n",
       "      <td>-0.011273</td>\n",
       "      <td>...</td>\n",
       "      <td>120.586845</td>\n",
       "      <td>69.361534</td>\n",
       "      <td>34.084633</td>\n",
       "      <td>60.413330</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>102.323845</td>\n",
       "      <td>17.693762</td>\n",
       "      <td>female</td>\n",
       "      <td>152.10</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9326695bf62926ec22690f576a633bba</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>-0.154224</td>\n",
       "      <td>0.528140</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>-0.108486</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>-0.099909</td>\n",
       "      <td>0.080770</td>\n",
       "      <td>...</td>\n",
       "      <td>110.543564</td>\n",
       "      <td>77.160583</td>\n",
       "      <td>38.086231</td>\n",
       "      <td>68.400543</td>\n",
       "      <td>57.172279</td>\n",
       "      <td>107.378578</td>\n",
       "      <td>16.594791</td>\n",
       "      <td>male</td>\n",
       "      <td>171.50</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           photo_id        f1        f2        f3        f4  \\\n",
       "0  6ab1d061f51c6079633aeceed2faeb0b  0.000068  0.108145 -0.138813  0.633156   \n",
       "1  e94e2e05fb8b099955bbc4fa5ce81e22  0.020843  0.026005 -0.093442  0.736929   \n",
       "2  ba6951a4f37fc9302243370e927a02e2  0.014542 -0.071332 -0.154407  0.577781   \n",
       "3  947d16539d4702427aa74f737329ffb9  0.041775  0.075746 -0.128497  0.485010   \n",
       "4  9326695bf62926ec22690f576a633bba  0.004397  0.058590 -0.154224  0.528140   \n",
       "\n",
       "         f5        f6        f7        f8        f9  ...         hip  \\\n",
       "0  0.346266 -0.046055  0.016021 -0.058632  0.097968  ...  105.333900   \n",
       "1  0.240569  0.089982 -0.112391  0.000435 -0.076110  ...  101.478989   \n",
       "2  0.196485 -0.125341 -0.056713 -0.027295  0.094879  ...   97.488243   \n",
       "3  0.120409  0.011227  0.017852 -0.089796 -0.011273  ...  120.586845   \n",
       "4  0.290956 -0.108486 -0.021441 -0.099909  0.080770  ...  110.543564   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh       waist  \\\n",
       "0   76.817467         35.362858           65.993683  54.459591   88.813789   \n",
       "1   85.154358         37.256760           65.861588  52.773052   89.176338   \n",
       "2   81.410393         37.503147           66.042679  57.059261   82.201988   \n",
       "3   69.361534         34.084633           60.413330  65.000000  102.323845   \n",
       "4   77.160583         38.086231           68.400543  57.172279  107.378578   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  16.764332  female     170.50       72.0  \n",
       "1  15.690955    male     178.30       71.8  \n",
       "2  16.686253    male     176.25       76.5  \n",
       "3  17.693762  female     152.10       88.9  \n",
       "4  16.594791    male     171.50       88.4  \n",
       "\n",
       "[5 rows x 5138 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "bucket = \"ai-bmi-predictor\"\n",
    "key = \"data/eff_training.csv\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "data = pd.read_csv(obj[\"Body\"])\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca77b-fb2a-4f3c-9897-29c1e84fcde0",
   "metadata": {},
   "source": [
    "2. data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9d28a-110f-4e9d-9936-f18919462e0e",
   "metadata": {},
   "source": [
    "2.1. categorical encoding for 'gender' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a49b37-abd8-4b37-8802-2c181918c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # import pandas for data handling\n",
    "\n",
    "data['gender'] = data['gender'].astype('category')  # convert 'gender' values to categorical type\n",
    "data['gender'] = data['gender'].cat.codes           # replace 'gender' with its numeric category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73940a3b-8471-40f4-93c3-d720861de107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: gender, dtype: int8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9787987-59e1-42a5-be40-d041b7ec47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['height_cm'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054494a2-7444-472e-837b-ab49865ccca7",
   "metadata": {},
   "source": [
    "2.2. define weight frequencies for class imbalance issue for weight_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e3f129-bcd9-4eb8-b9c6-045dc0d70955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples in dataset: 6134\n",
      "\n",
      "Class frequencies:\n",
      "Class 1 (weight_kg < 60): 1049\n",
      "Class 2 (weight_kg > 100): 514\n",
      "Class 3 (60 <= weight_kg <= 100): 4571\n",
      "\n",
      "Number of classes: 3\n",
      "\n",
      "Class weights (inverse frequency):\n",
      "Weight for Class 1 (weight_kg < 60): 1.9491579281855735\n",
      "Weight for Class 2 (weight_kg > 100): 3.9779507133592737\n",
      "Weight for Class 3 (60 <= weight_kg <= 100): 0.4473127689054182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                     # import pandas for data handling\n",
    "import numpy as np                      # import numpy to help with safe division\n",
    "\n",
    "# Assume 'data' is your DataFrame and already loaded\n",
    "#print(\"Preview of data:\\n\", data.head())  # print first few rows to check data\n",
    "print(\"\\nTotal samples in dataset:\", len(data))  # print total number of rows\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Create boolean masks for the three weight_kg classes\n",
    "# -----------------------------\n",
    "class_1_mask = data['weight_kg'] < 60                      # True where weight_kg is less than 60\n",
    "class_2_mask = data['weight_kg'] > 100                     # True where weight_kg is greater than 100\n",
    "class_3_mask = (data['weight_kg'] >= 60) & (data['weight_kg'] <= 100)  # True where weight is between 60 and 100\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Calculate class frequencies (counts)\n",
    "# -----------------------------\n",
    "freq_class_1 = class_1_mask.sum()          # number of samples with weight_kg < 60\n",
    "freq_class_2 = class_2_mask.sum()          # number of samples with weight_kg > 100\n",
    "freq_class_3 = class_3_mask.sum()          # number of samples with 60 <= weight_kg <= 100\n",
    "\n",
    "print(\"\\nClass frequencies:\")              # header for clarity\n",
    "print(\"Class 1 (weight_kg < 60):\", freq_class_1)   # print frequency of class 1\n",
    "print(\"Class 2 (weight_kg > 100):\", freq_class_2)  # print frequency of class 2\n",
    "print(\"Class 3 (60 <= weight_kg <= 100):\", freq_class_3)  # print frequency of class 3\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Number of classes according to the strategy\n",
    "# -----------------------------\n",
    "num_classes = 3                             # we defined three classes by the rules above\n",
    "print(\"\\nNumber of classes:\", num_classes)  # print number of classes\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compute inverse-frequency weights for each class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------\n",
    "total_samples = len(data)                   # total number of rows in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                # helper function to avoid division by zero\n",
    "    if class_freq == 0:                     # check if a class has zero samples\n",
    "        return np.nan                       # return NaN if no samples exist for that class\n",
    "    return total_samples / (num_classes * class_freq)  # apply weighting formula\n",
    "\n",
    "weight_class_1 = safe_weight(freq_class_1)  # compute weight for class 1\n",
    "weight_class_2 = safe_weight(freq_class_2)  # compute weight for class 2\n",
    "weight_class_3 = safe_weight(freq_class_3)  # compute weight for class 3\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency):\")          # header for class weights\n",
    "print(\"Weight for Class 1 (weight_kg < 60):\", weight_class_1)   # print weight of class 1\n",
    "print(\"Weight for Class 2 (weight_kg > 100):\", weight_class_2)  # print weight of class 2\n",
    "print(\"Weight for Class 3 (60 <= weight_kg <= 100):\", weight_class_3)  # print weight of class 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6008f8b-e977-4bef-ae79-33879ec53c33",
   "metadata": {},
   "source": [
    "2.3. define weight frequencies for class imbalance issue for gender feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f089c02-aff3-4c91-b679-be4b012a9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of gender column:\n",
      " 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: gender, dtype: int8\n",
      "\n",
      "Class frequencies for gender:\n",
      "Class 1: 3650\n",
      "Class 0: 2484\n",
      "\n",
      "Number of gender classes: 2\n",
      "\n",
      "Class weights (inverse frequency) for gender:\n",
      "Weight for class 1: 0.8402739726027397\n",
      "Weight for class 0: 1.2347020933977455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                                      # import numpy for numeric utilities (like NaN)\n",
    "\n",
    "print(\"Preview of gender column:\\n\", data['gender'].head())  # show first few gender values to inspect\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Calculate class frequencies for gender\n",
    "# -----------------------------------\n",
    "gender_counts = data['gender'].value_counts()           # count how many samples belong to each gender class\n",
    "\n",
    "print(\"\\nClass frequencies for gender:\")                # header for class frequency output\n",
    "for gender_class, freq in gender_counts.items():        # loop over each gender class and its frequency\n",
    "    print(f\"Class {gender_class}: {freq}\")              # print the class label and its frequency\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Number of gender classes\n",
    "# -----------------------------------\n",
    "num_gender_classes = len(gender_counts)                 # compute how many distinct gender classes we have\n",
    "print(\"\\nNumber of gender classes:\", num_gender_classes)  # print number of gender classes\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Compute inverse-frequency weights for each gender class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------------\n",
    "total_samples = len(data)                               # total number of samples in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                            # define helper function to compute class weight safely\n",
    "    if class_freq == 0:                                 # check for zero frequency to avoid division by zero\n",
    "        return np.nan                                   # return NaN if a class somehow has zero samples\n",
    "    return total_samples / (num_gender_classes * class_freq)  # apply the inverse-frequency weight formula\n",
    "\n",
    "gender_weights = {}                                     # create an empty dictionary to store weights per class\n",
    "for gender_class, freq in gender_counts.items():        # loop through each gender class and its frequency\n",
    "    gender_weights[gender_class] = safe_weight(freq)    # compute and store the weight for this gender class\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency) for gender:\")  # header for weight output\n",
    "for gender_class, weight in gender_weights.items():     # loop over each class and its weight\n",
    "    print(f\"Weight for class {gender_class}: {weight}\") # print the computed weight for this gender class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981d197-ad20-473e-a854-ffca369ef51e",
   "metadata": {},
   "source": [
    "2.4. weight frequencies for weight classes and gender classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc2d86a-9f9f-4ab2-8749-8dc2bd7644a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight-class weights: {'weight_<60': 1.9491579281855735, 'weight_>100': 3.9779507133592737, 'weight_60_100': 0.4473127689054182}\n",
      "Gender-class weights: {1: 0.8402739726027397, 0: 1.2347020933977455}\n",
      "\n",
      "Combined weights for each (weight_class, gender_class):\n",
      "weight_<60 & gender 1: 1.6378266755466175\n",
      "weight_<60 & gender 0: 2.4066293742935403\n",
      "weight_>100 & gender 1: 3.3425684487322993\n",
      "weight_>100 & gender 0: 4.9115840732177505\n",
      "weight_60_100 & gender 1: 0.37586527732408703\n",
      "weight_60_100 & gender 0: 0.5522980121710618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np   # import numpy for numeric operations\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Store the already-computed weights for weight classes\n",
    "#    (use the variables you created when handling weight_kg)\n",
    "# -------------------------------------------------\n",
    "weight_class_weights = {                          # dictionary to hold weight-class weights\n",
    "    'weight_<60':  weight_class_1,                # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,                # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3               # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights to check\n",
    "\n",
    "# gender_weights dict is assumed from previous step, e.g. {0: w0, 1: w1}\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights to check\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Multiply each gender class with each weight class\n",
    "#    wi = w_weight * w_gender\n",
    "# -------------------------------------------------\n",
    "combined_weights = {}                                # dictionary to store combined class weights\n",
    "\n",
    "print(\"\\nCombined weights for each (weight_class, gender_class):\")  # header\n",
    "for w_label, w_w in weight_class_weights.items():    # loop over weight classes\n",
    "    for g_label, w_g in gender_weights.items():      # loop over gender classes\n",
    "        wi = w_w * w_g                               # multiply weight and gender class weights\n",
    "        combined_weights[(w_label, g_label)] = wi    # store in dictionary\n",
    "        print(f\"{w_label} & gender {g_label}: {wi}\") # print each combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487c312-8683-4912-9b37-7e99383b1ed4",
   "metadata": {},
   "source": [
    "2.5. create a dictionary for weights and row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806866b5-519d-48b6-be00-77c2fd191d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before adding index column:\n",
      " Index(['photo_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
      "       ...\n",
      "       'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
      "       'waist', 'wrist', 'gender', 'height_cm', 'weight_kg'],\n",
      "      dtype='object', length=5138)\n"
     ]
    }
   ],
   "source": [
    "# Check current columns in the DataFrame\n",
    "print(\"Columns before adding index column:\\n\", data.columns)\n",
    "\n",
    "# Add a new column named 'index' with values from 0 to number_of_rows-1\n",
    "data['index'] = range(len(data))\n",
    "\n",
    "# Move 'index' to the front (optional, just for nicer viewing)\n",
    "cols = ['index'] + [c for c in data.columns if c != 'index']  # build new column order\n",
    "data = data[cols]                                            # reorder columns\n",
    "\n",
    "# Show first few rows to verify the new indexing column\n",
    "#print(\"\\nDataFrame after adding 'index' column:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41807157-b19f-4328-9e9a-faf126794665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight-class weights: {'weight_<60': 1.9491579281855735, 'weight_>100': 3.9779507133592737, 'weight_60_100': 0.4473127689054182}\n",
      "Gender-class weights: {1: 0.8402739726027397, 0: 1.2347020933977455}\n",
      "\n",
      "Building final_weights dictionary...\n",
      "Number of entries in final_weights: 6134\n",
      "First 5 items in final_weights: [(0, 0.5522980121710618), (1, 0.37586527732408703), (2, 0.37586527732408703), (3, 0.5522980121710618), (4, 0.37586527732408703)]\n",
      "\n",
      "Checking entry with index 0...\n",
      "Row 0 -> gender: 0\n",
      "Row 0 -> weight_kg: 72.0\n",
      "Row 0 -> weight class: weight_60_100\n",
      "w_weight for row 0: 0.4473127689054182\n",
      "w_gender for row 0: 1.2347020933977455\n",
      "Combined weight (calculated): 0.5522980121710618\n",
      "Combined weight from final_weights[0]: 0.5522980121710618\n",
      "\n",
      "Saving final_weights dictionary as pickle file...\n",
      "Dictionary saved to 'final_weights.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np               # import numpy for numeric operations\n",
    "import pickle                    # import pickle to save Python objects\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. We assume these already exist:\n",
    "#    - weight_class_1, weight_class_2, weight_class_3\n",
    "#    - gender_weights   (dict: {gender_class: weight})\n",
    "# -------------------------------------------------\n",
    "\n",
    "# create a dictionary of weight-class weights (same as before)\n",
    "weight_class_weights = {         # dictionary mapping weight class labels to their weights\n",
    "    'weight_<60':  weight_class_1,      # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,      # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3     # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Helper function to get the weight class label for a given weight_kg\n",
    "# -------------------------------------------------\n",
    "def get_weight_class(w):         # define a function that receives a single weight value\n",
    "    if w < 60:                   # check if weight is less than 60\n",
    "        return 'weight_<60'      # return label for class 1\n",
    "    elif w > 100:                # check if weight is greater than 100\n",
    "        return 'weight_>100'     # return label for class 2\n",
    "    else:                        # otherwise weight is between 60 and 100 (inclusive)\n",
    "        return 'weight_60_100'   # return label for class 3\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Build dictionary: keys = index values, values = combined weights\n",
    "# -------------------------------------------------\n",
    "final_weights = {}               # create empty dictionary to store final weights\n",
    "\n",
    "print(\"\\nBuilding final_weights dictionary...\")  # message to track progress\n",
    "\n",
    "for _, row in data.iterrows():   # loop over each row of the DataFrame\n",
    "    idx_val = row['index']       # get the value from the 'index' column for this row\n",
    "    gender_val = row['gender']   # get the gender class value for this row\n",
    "    weight_val = row['weight_kg']# get the weight_kg value for this row\n",
    "\n",
    "    w_class = get_weight_class(weight_val)        # determine weight class label from weight_kg\n",
    "    w_weight = weight_class_weights[w_class]      # look up the weight-class weight\n",
    "    w_gender = gender_weights[gender_val]         # look up the gender-class weight\n",
    "\n",
    "    combined_w = w_weight * w_gender             # multiply to get combined weight w_i\n",
    "    final_weights[idx_val] = combined_w          # store combined weight in dictionary with key=index\n",
    "\n",
    "print(\"Number of entries in final_weights:\", len(final_weights))  # print number of entries\n",
    "print(\"First 5 items in final_weights:\", list(final_weights.items())[:5])  # show first few items\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Check index 0: gender, weight_kg, and combined weight\n",
    "# -------------------------------------------------\n",
    "print(\"\\nChecking entry with index 0...\")        # message to show what we're doing\n",
    "\n",
    "row0 = data.loc[data['index'] == 0].iloc[0]      # select the row where 'index' column equals 0\n",
    "\n",
    "gender0 = row0['gender']                         # get gender value for index 0\n",
    "weight0 = row0['weight_kg']                      # get weight_kg value for index 0\n",
    "w_class0 = get_weight_class(weight0)             # get weight class label for index 0\n",
    "\n",
    "w_weight0 = weight_class_weights[w_class0]       # get weight-class weight for index 0\n",
    "w_gender0 = gender_weights[gender0]              # get gender-class weight for index 0\n",
    "combined0_calc = w_weight0 * w_gender0           # calculate combined weight for index 0\n",
    "\n",
    "print(\"Row 0 -> gender:\", gender0)               # print gender class for index 0\n",
    "print(\"Row 0 -> weight_kg:\", weight0)            # print weight_kg for index 0\n",
    "print(\"Row 0 -> weight class:\", w_class0)        # print weight class label for index 0\n",
    "print(\"w_weight for row 0:\", w_weight0)          # print weight-class weight for index 0\n",
    "print(\"w_gender for row 0:\", w_gender0)          # print gender-class weight for index 0\n",
    "print(\"Combined weight (calculated):\", combined0_calc)        # print calculated combined weight\n",
    "print(\"Combined weight from final_weights[0]:\", final_weights[0])  # print value from dictionary\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Save final_weights dictionary as a pickle file\n",
    "# -------------------------------------------------\n",
    "print(\"\\nSaving final_weights dictionary as pickle file...\")   # message to track saving step\n",
    "\n",
    "with open('final_weights.pkl', 'wb') as f:       # open a file named 'final_weights.pkl' in binary write mode\n",
    "    pickle.dump(final_weights, f)                # write dictionary to the file using pickle\n",
    "\n",
    "print(\"Dictionary saved to 'final_weights.pkl'.\")# confirmation message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f2ebfe-bf9d-4ca8-928f-57c0b04d2f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6ab1d061f51c6079633aeceed2faeb0b</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.108145</td>\n",
       "      <td>-0.138813</td>\n",
       "      <td>0.633156</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>-0.046055</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>-0.058632</td>\n",
       "      <td>...</td>\n",
       "      <td>105.333900</td>\n",
       "      <td>76.817467</td>\n",
       "      <td>35.362858</td>\n",
       "      <td>65.993683</td>\n",
       "      <td>54.459591</td>\n",
       "      <td>88.813789</td>\n",
       "      <td>16.764332</td>\n",
       "      <td>0</td>\n",
       "      <td>170.50</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>e94e2e05fb8b099955bbc4fa5ce81e22</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>-0.093442</td>\n",
       "      <td>0.736929</td>\n",
       "      <td>0.240569</td>\n",
       "      <td>0.089982</td>\n",
       "      <td>-0.112391</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>...</td>\n",
       "      <td>101.478989</td>\n",
       "      <td>85.154358</td>\n",
       "      <td>37.256760</td>\n",
       "      <td>65.861588</td>\n",
       "      <td>52.773052</td>\n",
       "      <td>89.176338</td>\n",
       "      <td>15.690955</td>\n",
       "      <td>1</td>\n",
       "      <td>178.30</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ba6951a4f37fc9302243370e927a02e2</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>-0.071332</td>\n",
       "      <td>-0.154407</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.196485</td>\n",
       "      <td>-0.125341</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>-0.027295</td>\n",
       "      <td>...</td>\n",
       "      <td>97.488243</td>\n",
       "      <td>81.410393</td>\n",
       "      <td>37.503147</td>\n",
       "      <td>66.042679</td>\n",
       "      <td>57.059261</td>\n",
       "      <td>82.201988</td>\n",
       "      <td>16.686253</td>\n",
       "      <td>1</td>\n",
       "      <td>176.25</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>947d16539d4702427aa74f737329ffb9</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>-0.128497</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>-0.089796</td>\n",
       "      <td>...</td>\n",
       "      <td>120.586845</td>\n",
       "      <td>69.361534</td>\n",
       "      <td>34.084633</td>\n",
       "      <td>60.413330</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>102.323845</td>\n",
       "      <td>17.693762</td>\n",
       "      <td>0</td>\n",
       "      <td>152.10</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9326695bf62926ec22690f576a633bba</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>-0.154224</td>\n",
       "      <td>0.528140</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>-0.108486</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>-0.099909</td>\n",
       "      <td>...</td>\n",
       "      <td>110.543564</td>\n",
       "      <td>77.160583</td>\n",
       "      <td>38.086231</td>\n",
       "      <td>68.400543</td>\n",
       "      <td>57.172279</td>\n",
       "      <td>107.378578</td>\n",
       "      <td>16.594791</td>\n",
       "      <td>1</td>\n",
       "      <td>171.50</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                          photo_id        f1        f2        f3  \\\n",
       "0      0  6ab1d061f51c6079633aeceed2faeb0b  0.000068  0.108145 -0.138813   \n",
       "1      1  e94e2e05fb8b099955bbc4fa5ce81e22  0.020843  0.026005 -0.093442   \n",
       "2      2  ba6951a4f37fc9302243370e927a02e2  0.014542 -0.071332 -0.154407   \n",
       "3      3  947d16539d4702427aa74f737329ffb9  0.041775  0.075746 -0.128497   \n",
       "4      4  9326695bf62926ec22690f576a633bba  0.004397  0.058590 -0.154224   \n",
       "\n",
       "         f4        f5        f6        f7        f8  ...         hip  \\\n",
       "0  0.633156  0.346266 -0.046055  0.016021 -0.058632  ...  105.333900   \n",
       "1  0.736929  0.240569  0.089982 -0.112391  0.000435  ...  101.478989   \n",
       "2  0.577781  0.196485 -0.125341 -0.056713 -0.027295  ...   97.488243   \n",
       "3  0.485010  0.120409  0.011227  0.017852 -0.089796  ...  120.586845   \n",
       "4  0.528140  0.290956 -0.108486 -0.021441 -0.099909  ...  110.543564   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh       waist  \\\n",
       "0   76.817467         35.362858           65.993683  54.459591   88.813789   \n",
       "1   85.154358         37.256760           65.861588  52.773052   89.176338   \n",
       "2   81.410393         37.503147           66.042679  57.059261   82.201988   \n",
       "3   69.361534         34.084633           60.413330  65.000000  102.323845   \n",
       "4   77.160583         38.086231           68.400543  57.172279  107.378578   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  16.764332       0     170.50       72.0  \n",
       "1  15.690955       1     178.30       71.8  \n",
       "2  16.686253       1     176.25       76.5  \n",
       "3  17.693762       0     152.10       88.9  \n",
       "4  16.594791       1     171.50       88.4  \n",
       "\n",
       "[5 rows x 5139 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f74299-3350-46fa-a49f-988b733ca1b8",
   "metadata": {},
   "source": [
    "2.6. apply Standard scaling for body measurements and robust scaling for cnn extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf12f1c-f692-47ab-847e-8342c6d34284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import pickle\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "# ---------- scaling ----------\n",
    "exclude_cols = ['photo_id', 'subject_id', 'index', 'gender']\n",
    "\n",
    "standard_cols = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'weight_kg', 'height_cm'\n",
    "]\n",
    "standard_cols = [c for c in standard_cols if c in data.columns]\n",
    "\n",
    "height_col = \"height_cm\"\n",
    "height_cols = [height_col] if height_col in data.columns else []\n",
    "target_cols = [c for c in standard_cols if c != height_col]\n",
    "\n",
    "robust_cols = [\n",
    "    c for c in data.columns\n",
    "    if c not in exclude_cols and c not in target_cols and c not in height_cols\n",
    "]\n",
    "\n",
    "height_scaler = StandardScaler()\n",
    "targets_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "if height_cols:\n",
    "    data[height_cols] = height_scaler.fit_transform(data[height_cols])\n",
    "\n",
    "if target_cols:\n",
    "    data[target_cols] = targets_scaler.fit_transform(data[target_cols])\n",
    "\n",
    "if robust_cols:\n",
    "    data[robust_cols] = robust_scaler.fit_transform(data[robust_cols])\n",
    "\n",
    "# ---------- upload pickles to S3 (no local files) ----------\n",
    "BUCKET = \"ai-bmi-predictor\"\n",
    "FOLDER = \"scalers/\"  # <- \"folder\" (prefix). Must end with \"/\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "def upload_pickle_to_s3(obj, bucket: str, key: str):\n",
    "    buf = io.BytesIO()\n",
    "    pickle.dump(obj, buf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    buf.seek(0)\n",
    "    s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Key=key,\n",
    "        Body=buf.getvalue(),\n",
    "        ContentType=\"application/octet-stream\"\n",
    "    )\n",
    "\n",
    "# (optional) create an empty placeholder object so the folder shows up in some UIs\n",
    "s3.put_object(Bucket=BUCKET, Key=FOLDER)\n",
    "\n",
    "upload_pickle_to_s3(height_scaler,  BUCKET, f\"{FOLDER}scaler_standard_features.pkl\")\n",
    "upload_pickle_to_s3(targets_scaler, BUCKET, f\"{FOLDER}scaler_targets.pkl\")\n",
    "upload_pickle_to_s3(robust_scaler,  BUCKET, f\"{FOLDER}scaler_robust_features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedc423f-20a2-4ff2-a8b9-17d1c011c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# columns to exclude from any scaling\n",
    "exclude_cols = ['photo_id', 'subject_id', 'index','gender']\n",
    "\n",
    "# columns to standard scale\n",
    "standard_cols = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'weight_kg', 'height_cm'\n",
    "]\n",
    "\n",
    "# ensure only existing columns are used\n",
    "standard_cols = [col for col in standard_cols if col in data.columns]\n",
    "\n",
    "# columns to robust scale (all others except excluded and standard-scaled)\n",
    "robust_cols = [\n",
    "    col for col in data.columns\n",
    "    if col not in exclude_cols and col not in standard_cols\n",
    "]\n",
    "\n",
    "# initialize scalers\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# apply scaling\n",
    "data[standard_cols] = standard_scaler.fit_transform(data[standard_cols])\n",
    "data[robust_cols] = robust_scaler.fit_transform(data[robust_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2206d6-2b6d-4376-9352-20c449914d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6ab1d061f51c6079633aeceed2faeb0b</td>\n",
       "      <td>-0.698223</td>\n",
       "      <td>1.138307</td>\n",
       "      <td>0.370072</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.908705</td>\n",
       "      <td>0.577309</td>\n",
       "      <td>0.816638</td>\n",
       "      <td>0.388236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337897</td>\n",
       "      <td>-0.307665</td>\n",
       "      <td>-0.180657</td>\n",
       "      <td>0.190893</td>\n",
       "      <td>0.065198</td>\n",
       "      <td>-0.081858</td>\n",
       "      <td>0.050458</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.081172</td>\n",
       "      <td>-0.231810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>e94e2e05fb8b099955bbc4fa5ce81e22</td>\n",
       "      <td>-0.293652</td>\n",
       "      <td>0.231949</td>\n",
       "      <td>2.686336</td>\n",
       "      <td>0.764837</td>\n",
       "      <td>-0.227144</td>\n",
       "      <td>2.625825</td>\n",
       "      <td>-0.796078</td>\n",
       "      <td>1.650451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131012</td>\n",
       "      <td>1.361007</td>\n",
       "      <td>0.516049</td>\n",
       "      <td>0.164107</td>\n",
       "      <td>-0.280967</td>\n",
       "      <td>-0.051067</td>\n",
       "      <td>-0.705275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721650</td>\n",
       "      <td>-0.243989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ba6951a4f37fc9302243370e927a02e2</td>\n",
       "      <td>-0.416348</td>\n",
       "      <td>-0.842102</td>\n",
       "      <td>-0.426003</td>\n",
       "      <td>-0.096957</td>\n",
       "      <td>-0.700891</td>\n",
       "      <td>-0.616604</td>\n",
       "      <td>-0.096826</td>\n",
       "      <td>1.057898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616444</td>\n",
       "      <td>0.611633</td>\n",
       "      <td>0.606687</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>0.598786</td>\n",
       "      <td>-0.643388</td>\n",
       "      <td>-0.004515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510652</td>\n",
       "      <td>0.042217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>947d16539d4702427aa74f737329ffb9</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.780800</td>\n",
       "      <td>0.896750</td>\n",
       "      <td>-0.599313</td>\n",
       "      <td>-1.518424</td>\n",
       "      <td>1.439894</td>\n",
       "      <td>0.839622</td>\n",
       "      <td>-0.277711</td>\n",
       "      <td>...</td>\n",
       "      <td>2.193258</td>\n",
       "      <td>-1.800009</td>\n",
       "      <td>-0.650875</td>\n",
       "      <td>-0.940681</td>\n",
       "      <td>2.228637</td>\n",
       "      <td>1.065530</td>\n",
       "      <td>0.704842</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.975009</td>\n",
       "      <td>0.797312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9326695bf62926ec22690f576a633bba</td>\n",
       "      <td>-0.613922</td>\n",
       "      <td>0.591494</td>\n",
       "      <td>-0.416686</td>\n",
       "      <td>-0.365764</td>\n",
       "      <td>0.314324</td>\n",
       "      <td>-0.362797</td>\n",
       "      <td>0.346151</td>\n",
       "      <td>-0.493812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971598</td>\n",
       "      <td>-0.238989</td>\n",
       "      <td>0.821185</td>\n",
       "      <td>0.678952</td>\n",
       "      <td>0.621983</td>\n",
       "      <td>1.494821</td>\n",
       "      <td>-0.068911</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021754</td>\n",
       "      <td>0.766864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                          photo_id        f1        f2        f3  \\\n",
       "0      0  6ab1d061f51c6079633aeceed2faeb0b -0.698223  1.138307  0.370072   \n",
       "1      1  e94e2e05fb8b099955bbc4fa5ce81e22 -0.293652  0.231949  2.686336   \n",
       "2      2  ba6951a4f37fc9302243370e927a02e2 -0.416348 -0.842102 -0.426003   \n",
       "3      3  947d16539d4702427aa74f737329ffb9  0.113970  0.780800  0.896750   \n",
       "4      4  9326695bf62926ec22690f576a633bba -0.613922  0.591494 -0.416686   \n",
       "\n",
       "         f4        f5        f6        f7        f8  ...       hip  \\\n",
       "0  0.202900  0.908705  0.577309  0.816638  0.388236  ...  0.337897   \n",
       "1  0.764837 -0.227144  2.625825 -0.796078  1.650451  ... -0.131012   \n",
       "2 -0.096957 -0.700891 -0.616604 -0.096826  1.057898  ... -0.616444   \n",
       "3 -0.599313 -1.518424  1.439894  0.839622 -0.277711  ...  2.193258   \n",
       "4 -0.365764  0.314324 -0.362797  0.346151 -0.493812  ...  0.971598   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch     thigh     waist  \\\n",
       "0   -0.307665         -0.180657            0.190893  0.065198 -0.081858   \n",
       "1    1.361007          0.516049            0.164107 -0.280967 -0.051067   \n",
       "2    0.611633          0.606687            0.200829  0.598786 -0.643388   \n",
       "3   -1.800009         -0.650875           -0.940681  2.228637  1.065530   \n",
       "4   -0.238989          0.821185            0.678952  0.621983  1.494821   \n",
       "\n",
       "      wrist  gender  height_cm  weight_kg  \n",
       "0  0.050458       0  -0.081172  -0.231810  \n",
       "1 -0.705275       1   0.721650  -0.243989  \n",
       "2 -0.004515       1   0.510652   0.042217  \n",
       "3  0.704842       0  -1.975009   0.797312  \n",
       "4 -0.068911       1   0.021754   0.766864  \n",
       "\n",
       "[5 rows x 5139 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4707456-2e11-4ead-9ab7-534b91ca8d19",
   "metadata": {},
   "source": [
    "3. model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e07427-117c-46ac-9bdc-f049f9a1024b",
   "metadata": {},
   "source": [
    "3.1. split the data for independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ffaa0e-f6df-4778-ae89-fb050332a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "Shape of Y (samples, targets): (6134, 14)\n"
     ]
    }
   ],
   "source": [
    "# List of columns to be used as dependent (target) features\n",
    "target_cols = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'weight_kg'\n",
    "]\n",
    "\n",
    "# Select these columns from the DataFrame as the multi-target Y\n",
    "Y = data[target_cols]                  # Y will hold all dependent variables for multi-target regression\n",
    "\n",
    "print(\"Selected target columns:\", target_cols)  # print which columns are used as targets\n",
    "print(\"Shape of Y (samples, targets):\", Y.shape)  # print shape to confirm dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69820f72-d599-4ec3-acdf-ab2cc8e9d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop for X:\n",
      " ['photo_id', 'subject_id', 'index', 'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "\n",
      "Shape of X (samples, independent features): (6134, 5122)\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop for building independent features (X)\n",
    "drop_cols = ['photo_id', 'subject_id','index'] + target_cols   # combine ID columns with target columns\n",
    "\n",
    "print(\"Columns to drop for X:\\n\", drop_cols)           # show which columns will be removed\n",
    "\n",
    "# Create X by dropping ID columns and all target columns\n",
    "X = data.drop(columns=drop_cols)                       # drop the unwanted columns to get independent features\n",
    "\n",
    "print(\"\\nShape of X (samples, independent features):\", X.shape)  # print shape of X\n",
    "#print(\"\\nColumns in X:\\n\", X.columns.tolist())         # list all feature names in X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824e33c-3404-42b5-9619-4b7beabbcea9",
   "metadata": {},
   "source": [
    "3.2. import necessary libraries for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8cb5737-d256-4ae3-bd10-f1567065b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 03:37:04.173589: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-19 03:37:04.189575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-19 03:37:04.214412: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-19 03:37:04.214435: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-19 03:37:04.229318: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-19 03:37:05.078308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (6134, 5122)\n",
      "Shape of Y (targets): (6134, 14)\n",
      "\n",
      "Loading final_weights.pkl ...\n",
      "Number of entries in final_weights_dict: 6134\n",
      "First 5 entries in final_weights_dict: [(0, 0.5522980121710618), (1, 0.37586527732408703), (2, 0.37586527732408703), (3, 0.5522980121710618), (4, 0.37586527732408703)]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "import numpy as np                          # numerical operations\n",
    "import pickle                               # to load the final_weights.pkl file\n",
    "import matplotlib.pyplot as plt             # for plotting loss curves\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # to create train/validation sets\n",
    "\n",
    "import tensorflow as tf                     # main deep learning library\n",
    "from tensorflow.keras.models import Sequential          # model container\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, LeakyReLU, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility (optional)\n",
    "# -----------------------------\n",
    "np.random.seed(42)                          # fix numpy random seed\n",
    "tf.random.set_seed(42)                      # fix tensorflow random seed\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Assume you already have:\n",
    "#    - data DataFrame\n",
    "#    - X (independent features)\n",
    "#    - Y (multi-output targets)\n",
    "# If not, you can recreate X, Y here.\n",
    "# -----------------------------\n",
    "\n",
    "# Example (uncomment if you want everything in one place):\n",
    "# target_cols = [\n",
    "#     'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "#     'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "#     'waist', 'wrist', 'weight_kg'\n",
    "# ]\n",
    "# Y = data[target_cols]                                            # select target columns\n",
    "# drop_cols = ['photo_id', 'subject_id'] + target_cols             # columns not used as features\n",
    "# X = data.drop(columns=drop_cols + ['index'])                     # drop also 'index' from features\n",
    "\n",
    "print(\"Shape of X (features):\", X.shape)           # show shape of feature matrix\n",
    "print(\"Shape of Y (targets):\", Y.shape)           # show shape of target matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load final_weights.pkl (sample weights per index)\n",
    "# -----------------------------\n",
    "print(\"\\nLoading final_weights.pkl ...\")          # status message\n",
    "\n",
    "with open('final_weights.pkl', 'rb') as f:        # open pickle file in read-binary mode\n",
    "    final_weights_dict = pickle.load(f)           # load dictionary {index: weight}\n",
    "\n",
    "print(\"Number of entries in final_weights_dict:\", len(final_weights_dict))  # size of dictionary\n",
    "print(\"First 5 entries in final_weights_dict:\", list(final_weights_dict.items())[:5])  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d78e6-ead3-4131-82b9-cedff7140d2d",
   "metadata": {},
   "source": [
    "3.3. convert weight dictionary for array to balance class imbalance of a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a93e352-a406-4218-8106-1c4481f30ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building sample_weight array ...\n",
      "Sample weights shape: (6134,)\n",
      "First 10 sample weights: [0.552298   0.37586528 0.37586528 0.552298   0.37586528 0.552298\n",
      " 0.37586528 0.37586528 0.552298   0.37586528]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Build sample_weight array based on DataFrame 'index' column\n",
    "# -----------------------------\n",
    "print(\"\\nBuilding sample_weight array ...\")       # status message\n",
    "\n",
    "# map each row's 'index' value to its weight in the dictionary\n",
    "sample_weights = data['index'].map(final_weights_dict).values.astype('float32')\n",
    "\n",
    "print(\"Sample weights shape:\", sample_weights.shape)   # show shape of weight array\n",
    "print(\"First 10 sample weights:\", sample_weights[:10]) # preview some weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5265df0-3fd1-4006-9ddc-290729128dc2",
   "metadata": {},
   "source": [
    "3.5. split the data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1db360ce-79cd-4103-928a-8cbf03ecac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting into train and validation sets ...\n",
      "X_train shape: (4907, 5122)\n",
      "Y_train shape: (4907, 14)\n",
      "X_val shape: (1227, 5122)\n",
      "Y_val shape: (1227, 14)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. Train/validation split (X, Y, and weights)\n",
    "# -----------------------------\n",
    "print(\"\\nSplitting into train and validation sets ...\")  # status message\n",
    "\n",
    "X_train, X_val, Y_train, Y_val, w_train, w_val = train_test_split(\n",
    "    X, Y, sample_weights,           # split features, targets, and weights together\n",
    "    test_size=0.2,                  # 20% validation\n",
    "    random_state=42,                # reproducible split\n",
    "    shuffle=True                    # shuffle data before splitting\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)          # show training feature shape\n",
    "print(\"Y_train shape:\", Y_train.shape)          # show training target shape\n",
    "print(\"X_val shape:\", X_val.shape)              # show validation feature shape\n",
    "print(\"Y_val shape:\", Y_val.shape)              # show validation target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ed6d84a-e81b-42db-8f9b-0f8028f51162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_eff_ann.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_eff_ann.py\n",
    "# import os for paths and environment variables\n",
    "import os  # import os module\n",
    "# import numpy for array operations\n",
    "import numpy as np  # import numpy\n",
    "# import boto3 for S3 interaction\n",
    "import boto3  # import boto3 for AWS S3\n",
    "\n",
    "# import tensorflow main package\n",
    "import tensorflow as tf  # import tensorflow\n",
    "# import Keras model and layers\n",
    "from tensorflow.keras.models import Sequential  # import Sequential model\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, LeakyReLU, Activation  # import layers\n",
    "# import optimizers\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop  # import optimizers\n",
    "# import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau  # import callbacks\n",
    "\n",
    "\n",
    "def build_model(num_hidden_layers, num_neurons, activation_name,\n",
    "                learning_rate, optimizer_name, input_dim, output_dim,\n",
    "                dropout_rate=0.3):  # define function to build model\n",
    "    \"\"\"\n",
    "    Build and compile a Keras Sequential model\n",
    "    for multi-output regression.\n",
    "    \"\"\"  # docstring for build_model\n",
    "\n",
    "    model = Sequential()  # create empty sequential model\n",
    "\n",
    "    model.add(InputLayer(input_shape=(input_dim,)))  # add input layer with input_dim features\n",
    "\n",
    "    for _ in range(num_hidden_layers):  # loop over number of hidden layers\n",
    "        model.add(Dense(num_neurons))  # add dense layer with num_neurons units\n",
    "\n",
    "        if activation_name.lower() == 'leakyrelu':  # check for LeakyReLU activation\n",
    "            model.add(LeakyReLU(alpha=0.1))  # add LeakyReLU layer\n",
    "        elif activation_name.lower() == 'gelu':  # check for GELU activation\n",
    "            model.add(Activation(tf.keras.activations.gelu))  # add GELU activation\n",
    "        elif activation_name.lower() == 'tanh':  # check for tanh activation\n",
    "            model.add(Activation('tanh'))  # add tanh activation\n",
    "        else:  # handle unknown activation name\n",
    "            raise ValueError(f\"Unknown activation: {activation_name}\")  # raise error\n",
    "\n",
    "        model.add(Dropout(dropout_rate))  # add dropout for regularization\n",
    "\n",
    "    model.add(Dense(output_dim, activation='linear'))  # add output layer with linear activation\n",
    "\n",
    "    if optimizer_name.lower() == 'sgd':  # choose optimizer if name is sgd\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)  # create SGD optimizer\n",
    "    elif optimizer_name.lower() == 'adam':  # choose optimizer if name is adam\n",
    "        optimizer = Adam(learning_rate=learning_rate)  # create Adam optimizer\n",
    "    elif optimizer_name.lower() == 'rmsprop':  # choose optimizer if name is rmsprop\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)  # create RMSprop optimizer\n",
    "    else:  # handle unknown optimizer name\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")  # raise error\n",
    "\n",
    "    model.compile(  # compile the model\n",
    "        optimizer=optimizer,  # set optimizer\n",
    "        loss='mse',  # set loss as mean squared error\n",
    "        metrics=[],  # no unweighted metrics\n",
    "        weighted_metrics=[tf.keras.metrics.MeanSquaredError(name='mse')]  # add weighted MSE metric\n",
    "    )\n",
    "\n",
    "    return model  # return compiled model\n",
    "\n",
    "\n",
    "def load_data():  # define function to load data from SageMaker channels\n",
    "    train_dir = os.environ.get('SM_CHANNEL_TRAIN')  # get training channel directory\n",
    "    val_dir = os.environ.get('SM_CHANNEL_VALIDATION')  # get validation channel directory\n",
    "\n",
    "    print(f\"Train dir: {train_dir}\")  # print training directory\n",
    "    print(f\"Validation dir: {val_dir}\")  # print validation directory\n",
    "\n",
    "    X_train = np.load(os.path.join(train_dir, 'X_train.npy'))  # load X_train array\n",
    "    Y_train = np.load(os.path.join(train_dir, 'Y_train.npy'))  # load Y_train array\n",
    "    w_train = np.load(os.path.join(train_dir, 'w_train.npy'))  # load w_train array\n",
    "\n",
    "    X_val = np.load(os.path.join(val_dir, 'X_val.npy'))  # load X_val array\n",
    "    Y_val = np.load(os.path.join(val_dir, 'Y_val.npy'))  # load Y_val array\n",
    "    w_val = np.load(os.path.join(val_dir, 'w_val.npy'))  # load w_val array\n",
    "\n",
    "    return X_train, Y_train, w_train, X_val, Y_val, w_val  # return loaded arrays\n",
    "\n",
    "\n",
    "def main():  # define main function\n",
    "    print(\"Loading data ...\")  # print status message\n",
    "    X_train, Y_train, w_train, X_val, Y_val, w_val = load_data()  # call load_data\n",
    "\n",
    "    input_dim = X_train.shape[1]  # get number of input features\n",
    "    output_dim = Y_train.shape[1]  # get number of output targets\n",
    "\n",
    "    num_hidden_layers_list = [1]  # list of hidden layer counts\n",
    "    num_neurons_list = [256]  # list of neuron counts\n",
    "    activation_list = ['gelu']  # list of activation functions\n",
    "    learning_rates = [1e-4]  # list of learning rates\n",
    "    optimizer_list = ['adam']  # list of optimizers\n",
    "\n",
    "    batch_size = 200  # batch size for training\n",
    "    num_epochs = 300  # maximum number of epochs\n",
    "\n",
    "    total_combinations = (len(num_hidden_layers_list) *  # compute total combinations\n",
    "                          len(num_neurons_list) *\n",
    "                          len(activation_list) *\n",
    "                          len(learning_rates) *\n",
    "                          len(optimizer_list))  # multiply all dimensions\n",
    "\n",
    "    print(f\"Total hyper-parameter combinations: {total_combinations}\")  # print total combinations\n",
    "\n",
    "    best_val_loss = np.inf  # initialize best validation loss\n",
    "    best_history = None  # placeholder for best training history\n",
    "    best_params = None  # placeholder for best hyper-parameters\n",
    "    best_model = None  # placeholder for best model\n",
    "\n",
    "    combo_counter = 0  # initialize combination counter\n",
    "\n",
    "    for num_hidden_layers in num_hidden_layers_list:  # loop over hidden layer options\n",
    "        for num_neurons in num_neurons_list:  # loop over neuron options\n",
    "            for activation_name in activation_list:  # loop over activations\n",
    "                for lr in learning_rates:  # loop over learning rates\n",
    "                    for optimizer_name in optimizer_list:  # loop over optimizers\n",
    "                        combo_counter += 1  # increment combination counter\n",
    "\n",
    "                        print(\"\\n======================================\")  # separator line\n",
    "                        print(f\"Training combination {combo_counter}/{total_combinations}\")  # print combo index\n",
    "                        print(f\"Hidden layers: {num_hidden_layers}\")  # print hidden layers\n",
    "                        print(f\"Neurons per layer: {num_neurons}\")  # print neurons per layer\n",
    "                        print(f\"Activation: {activation_name}\")  # print activation\n",
    "                        print(f\"Learning rate: {lr}\")  # print learning rate\n",
    "                        print(f\"Optimizer: {optimizer_name}\")  # print optimizer\n",
    "                        print(\"======================================\")  # separator line\n",
    "\n",
    "                        tf.keras.backend.clear_session()  # clear previous graph from memory\n",
    "\n",
    "                        model = build_model(  # build model with current configuration\n",
    "                            num_hidden_layers=num_hidden_layers,  # pass hidden layers\n",
    "                            num_neurons=num_neurons,  # pass neurons per layer\n",
    "                            activation_name=activation_name,  # pass activation\n",
    "                            learning_rate=lr,  # pass learning rate\n",
    "                            optimizer_name=optimizer_name,  # pass optimizer\n",
    "                            input_dim=input_dim,  # pass input dimension\n",
    "                            output_dim=output_dim,  # pass output dimension\n",
    "                            dropout_rate=0.3  # pass dropout rate\n",
    "                        )\n",
    "\n",
    "                        early_stop = EarlyStopping(  # define early stopping callback\n",
    "                            monitor='val_loss',  # monitor validation loss\n",
    "                            patience=10,  # stop after 10 epochs with no improvement\n",
    "                            restore_best_weights=True,  # restore best weights\n",
    "                            verbose=1  # print early stopping logs\n",
    "                        )\n",
    "\n",
    "                        lr_scheduler = ReduceLROnPlateau(  # define learning rate scheduler\n",
    "                            monitor='loss',  # monitor training loss\n",
    "                            factor=0.5,  # reduce LR by factor of 0.5\n",
    "                            patience=5,  # wait 5 epochs before reducing LR\n",
    "                            min_lr=1e-6,  # minimum learning rate\n",
    "                            verbose=1  # print LR change logs\n",
    "                        )\n",
    "\n",
    "                        history = model.fit(  # train the model\n",
    "                            X_train,  # training inputs\n",
    "                            Y_train,  # training targets\n",
    "                            sample_weight=w_train,  # training sample weights\n",
    "                            validation_data=(X_val, Y_val, w_val),  # validation data\n",
    "                            epochs=num_epochs,  # number of epochs\n",
    "                            batch_size=batch_size,  # batch size\n",
    "                            callbacks=[early_stop, lr_scheduler],  # callbacks list\n",
    "                            verbose=1  # print training logs per epoch\n",
    "                        )\n",
    "\n",
    "                        min_val_loss = min(history.history['val_loss'])  # get best val_loss for this combo\n",
    "\n",
    "                        print(f\"Finished combination {combo_counter}. \"  # print summary for combo\n",
    "                              f\"Best val_loss for this model: {min_val_loss:.6f}\")  # print best val_loss\n",
    "\n",
    "                        if min_val_loss < best_val_loss:  # check if this is the best so far\n",
    "                            print(\">>> New best model found! Updating best model ...\")  # log improvement\n",
    "\n",
    "                            best_val_loss = min_val_loss  # update best validation loss\n",
    "                            best_history = history  # store best history\n",
    "                            best_params = {  # store best hyper-parameters\n",
    "                                'num_hidden_layers': num_hidden_layers,\n",
    "                                'num_neurons': num_neurons,\n",
    "                                'activation': activation_name,\n",
    "                                'learning_rate': lr,\n",
    "                                'optimizer': optimizer_name\n",
    "                            }\n",
    "                            best_model = model  # store best model\n",
    "\n",
    "    print(\"\\n================ BEST MODEL =================\")  # print header for best model\n",
    "    print(f\"Best validation loss: {best_val_loss}\")  # print best validation loss\n",
    "    print(\"Best hyper-parameters:\")  # header for hyper-parameters\n",
    "    for k, v in best_params.items():  # loop over best_params\n",
    "        print(f\"  {k}: {v}\")  # print each parameter\n",
    "    print(\"=============================================\")  # footer line\n",
    "\n",
    "    model_dir = os.environ.get('SM_MODEL_DIR', '/opt/ml/model')  # get model directory\n",
    "    os.makedirs(model_dir, exist_ok=True)  # create model directory if needed\n",
    "\n",
    "    local_model_path = os.path.join(model_dir, 'eff_ann_version8.h5')  # define local model path\n",
    "\n",
    "    print(f\"\\nSaving best model to {local_model_path} ...\")  # log save path\n",
    "    best_model.save(local_model_path)  # save best model as .h5\n",
    "    print(\"Model saved.\")  # confirm save\n",
    "\n",
    "    target_bucket = 'ai-bmi-predictor'  # set target S3 bucket\n",
    "    target_key = 'trained-models/efficientnet-models/eff_ann_version8.h5'  # set S3 object key\n",
    "\n",
    "    print(f\"Uploading best model to s3://{target_bucket}/{target_key} ...\")  # log upload target\n",
    "    s3_client = boto3.client('s3')  # create S3 client\n",
    "    s3_client.upload_file(local_model_path, target_bucket, target_key)  # upload model file\n",
    "    print(\"Upload complete.\")  # confirm upload\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  # run when script is executed directly\n",
    "    main()  # call main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a200fe-746a-4e8e-8553-d188218fe2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: eff-ann-v8-training-2025-12-19-03-37-10-946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-19 03:37:11 Starting - Starting the training job\n",
      "2025-12-19 03:37:11 Pending - Training job waiting for capacity...\n",
      "2025-12-19 03:37:32 Pending - Preparing the instances for training...\n",
      "2025-12-19 03:38:05 Downloading - Downloading input data...\n",
      "2025-12-19 03:38:20 Downloading - Downloading the training image............\n",
      "2025-12-19 03:40:46 Training - Training image download completed. Training in progress.....\u001b[34m2025-12-19 03:41:15.492248: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:15.540451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[0m\n",
      "\u001b[34mTo enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:17,887 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:17,907 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:18,321 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:18,352 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:18,382 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:18,395 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-19-03-37-10-946/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/x-npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"application/x-npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"eff-ann-v8-training-2025-12-19-03-37-10-946\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://ai-bmi-predictor/eff-ann-v8-training-2025-12-19-03-37-10-946/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_eff_ann\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_eff_ann.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-19-03-37-10-946/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_eff_ann.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_eff_ann\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://ai-bmi-predictor/eff-ann-v8-training-2025-12-19-03-37-10-946/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.16xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-19-03-37-10-946/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"eff-ann-v8-training-2025-12-19-03-37-10-946\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://ai-bmi-predictor/eff-ann-v8-training-2025-12-19-03-37-10-946/source/sourcedir.tar.gz\",\"module_name\":\"train_eff_ann\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_eff_ann.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-19-03-37-10-946/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-19-03-37-10-946/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python310.zip:/usr/local/lib/python3.10:/usr/local/lib/python3.10/lib-dynload:/usr/local/lib/python3.10/site-packages:/usr/local/lib/python3.10/site-packages/smdebug-1.0.33-py3.10.egg:/usr/local/lib/python3.10/site-packages/pyinstrument-3.4.2-py3.10.egg:/usr/local/lib/python3.10/site-packages/pyinstrument_cext-0.2.4-py3.10-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.10 train_eff_ann.py --model_dir s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-19-03-37-10-946/model\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34mLoading data ...\u001b[0m\n",
      "\u001b[34mTrain dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mValidation dir: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mTotal hyper-parameter combinations: 1\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mTraining combination 1/1\u001b[0m\n",
      "\u001b[34mHidden layers: 1\u001b[0m\n",
      "\u001b[34mNeurons per layer: 256\u001b[0m\n",
      "\u001b[34mActivation: gelu\u001b[0m\n",
      "\u001b[34mLearning rate: 0.0001\u001b[0m\n",
      "\u001b[34mOptimizer: adam\u001b[0m\n",
      "\u001b[34m======================================\u001b[0m\n",
      "\u001b[34mEpoch 1/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 31s - loss: 4.1313 - mse: 3.7881\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 1.9893 - mse: 1.9359\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 2s 37ms/step - loss: 1.7512 - mse: 1.7097 - val_loss: 0.7959 - val_mse: 0.7510 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 2/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 1.0883 - mse: 1.0224\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.9423 - mse: 0.9320\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.9175 - mse: 0.8957 - val_loss: 0.6187 - val_mse: 0.5838 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 3/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.7383 - mse: 0.7352\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.7277 - mse: 0.7054\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.7164 - mse: 0.6994 - val_loss: 0.5421 - val_mse: 0.5115 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 4/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.6509 - mse: 0.6230\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.6095 - mse: 0.6096\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.6140 - mse: 0.5994 - val_loss: 0.4955 - val_mse: 0.4676 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 5/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.5308 - mse: 0.5389\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.5652 - mse: 0.5542\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.5596 - mse: 0.5463 - val_loss: 0.4612 - val_mse: 0.4352 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 6/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.4908 - mse: 0.5351\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.5128 - mse: 0.4965\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.5049 - mse: 0.4929 - val_loss: 0.4380 - val_mse: 0.4133 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 7/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.4855 - mse: 0.4984\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.4738 - mse: 0.4604\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.4685 - mse: 0.4574 - val_loss: 0.4177 - val_mse: 0.3941 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 8/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.5063 - mse: 0.4780\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.4457 - mse: 0.4332\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.4401 - mse: 0.4297 - val_loss: 0.4052 - val_mse: 0.3823 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 9/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.5371 - mse: 0.4837\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.4120 - mse: 0.3990\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.4097 - mse: 0.3999 - val_loss: 0.3895 - val_mse: 0.3675 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 10/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.4477 - mse: 0.4044\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.3911 - mse: 0.3810\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.3870 - mse: 0.3778 - val_loss: 0.3744 - val_mse: 0.3532 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 11/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.3031 - mse: 0.3610\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.3545 - mse: 0.3469\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.3583 - mse: 0.3498 - val_loss: 0.3612 - val_mse: 0.3408 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 12/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.3998 - mse: 0.3734\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.3509 - mse: 0.3390\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.3494 - mse: 0.3411 - val_loss: 0.3575 - val_mse: 0.3373 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 13/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.4092 - mse: 0.3587\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.3416 - mse: 0.3348\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.3388 - mse: 0.3307 - val_loss: 0.3534 - val_mse: 0.3335 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 14/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.3214 - mse: 0.3123\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.3256 - mse: 0.3164\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.3235 - mse: 0.3158 - val_loss: 0.3436 - val_mse: 0.3242 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 15/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.3219 - mse: 0.2930\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.3045 - mse: 0.2957\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.3054 - mse: 0.2982 - val_loss: 0.3350 - val_mse: 0.3161 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 16/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.3527 - mse: 0.3014\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2918 - mse: 0.2853\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2912 - mse: 0.2843 - val_loss: 0.3261 - val_mse: 0.3077 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 17/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2734 - mse: 0.2581\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2858 - mse: 0.2794\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2868 - mse: 0.2800 - val_loss: 0.3218 - val_mse: 0.3037 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 18/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2549 - mse: 0.2557\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.2691 - mse: 0.2635\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2711 - mse: 0.2647 - val_loss: 0.3174 - val_mse: 0.2995 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 19/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.3165 - mse: 0.2879\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2658 - mse: 0.2592\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2649 - mse: 0.2587 - val_loss: 0.3097 - val_mse: 0.2922 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 20/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2480 - mse: 0.2338\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2490 - mse: 0.2430\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2500 - mse: 0.2441 - val_loss: 0.3025 - val_mse: 0.2854 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 21/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2452 - mse: 0.2457\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2431 - mse: 0.2384\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2441 - mse: 0.2383 - val_loss: 0.3033 - val_mse: 0.2862 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 22/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2108 - mse: 0.2042\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2374 - mse: 0.2325\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2396 - mse: 0.2339 - val_loss: 0.3007 - val_mse: 0.2837 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 23/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2706 - mse: 0.2542\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2346 - mse: 0.2320\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2344 - mse: 0.2288 - val_loss: 0.2895 - val_mse: 0.2732 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 24/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2281 - mse: 0.2063\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2323 - mse: 0.2289\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2306 - mse: 0.2251 - val_loss: 0.2949 - val_mse: 0.2783 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 25/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2213 - mse: 0.2276\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2215 - mse: 0.2194\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2222 - mse: 0.2169 - val_loss: 0.2983 - val_mse: 0.2814 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 26/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2075 - mse: 0.1901\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2180 - mse: 0.2128\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2162 - mse: 0.2110 - val_loss: 0.2807 - val_mse: 0.2649 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 27/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2039 - mse: 0.1941\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2048 - mse: 0.2039\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2077 - mse: 0.2028 - val_loss: 0.2754 - val_mse: 0.2598 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 28/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2044 - mse: 0.1903\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.2004 - mse: 0.1993\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.2033 - mse: 0.1985 - val_loss: 0.2799 - val_mse: 0.2641 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 29/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1921 - mse: 0.1848\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1985 - mse: 0.1935\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1987 - mse: 0.1940 - val_loss: 0.2730 - val_mse: 0.2576 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 30/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1953 - mse: 0.1824\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1992 - mse: 0.1910\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1965 - mse: 0.1918 - val_loss: 0.2722 - val_mse: 0.2569 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 31/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2035 - mse: 0.1974\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1901 - mse: 0.1871\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1944 - mse: 0.1898 - val_loss: 0.2638 - val_mse: 0.2489 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 32/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1711 - mse: 0.1671\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1890 - mse: 0.1852\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1887 - mse: 0.1842 - val_loss: 0.2760 - val_mse: 0.2604 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 33/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.2017 - mse: 0.1832\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1847 - mse: 0.1821\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1848 - mse: 0.1804 - val_loss: 0.2721 - val_mse: 0.2567 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 34/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1783 - mse: 0.1625\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1861 - mse: 0.1805\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1852 - mse: 0.1808 - val_loss: 0.2554 - val_mse: 0.2410 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 35/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1713 - mse: 0.1685\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1774 - mse: 0.1769\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1787 - mse: 0.1745 - val_loss: 0.2620 - val_mse: 0.2472 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 36/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1586 - mse: 0.1736\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1739 - mse: 0.1693\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1731 - mse: 0.1690 - val_loss: 0.2542 - val_mse: 0.2399 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 37/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1860 - mse: 0.1576\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1738 - mse: 0.1695\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1740 - mse: 0.1699 - val_loss: 0.2618 - val_mse: 0.2470 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 38/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1699 - mse: 0.1643\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1649 - mse: 0.1604\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1657 - mse: 0.1618 - val_loss: 0.2587 - val_mse: 0.2441 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 39/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1536 - mse: 0.1502\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1652 - mse: 0.1609\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1632 - mse: 0.1593 - val_loss: 0.2503 - val_mse: 0.2361 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 40/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1300 - mse: 0.1609\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1612 - mse: 0.1595\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1635 - mse: 0.1596 - val_loss: 0.2473 - val_mse: 0.2334 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 41/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1608 - mse: 0.1433\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1612 - mse: 0.1560\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1600 - mse: 0.1562 - val_loss: 0.2461 - val_mse: 0.2322 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 42/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1390 - mse: 0.1314\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1562 - mse: 0.1521\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1538 - mse: 0.1501 - val_loss: 0.2404 - val_mse: 0.2268 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 43/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1384 - mse: 0.1337\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1520 - mse: 0.1479\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1553 - mse: 0.1516 - val_loss: 0.2387 - val_mse: 0.2252 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 44/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1735 - mse: 0.1589\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1581 - mse: 0.1516\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1557 - mse: 0.1520 - val_loss: 0.2413 - val_mse: 0.2277 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 45/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1467 - mse: 0.1473\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1536 - mse: 0.1488\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1509 - mse: 0.1473 - val_loss: 0.2395 - val_mse: 0.2260 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 46/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1507 - mse: 0.1497\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1468 - mse: 0.1462\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1484 - mse: 0.1448 - val_loss: 0.2371 - val_mse: 0.2237 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 47/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1571 - mse: 0.1438\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1480 - mse: 0.1446\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1478 - mse: 0.1443 - val_loss: 0.2382 - val_mse: 0.2247 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 48/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1405 - mse: 0.1302\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1458 - mse: 0.1427\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1452 - mse: 0.1418 - val_loss: 0.2365 - val_mse: 0.2232 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 49/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1358 - mse: 0.1303\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1413 - mse: 0.1383\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1428 - mse: 0.1394 - val_loss: 0.2285 - val_mse: 0.2156 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 50/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1989 - mse: 0.1790\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1449 - mse: 0.1401\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1427 - mse: 0.1394 - val_loss: 0.2313 - val_mse: 0.2182 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 51/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1301 - mse: 0.1253\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1419 - mse: 0.1359\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1406 - mse: 0.1372 - val_loss: 0.2310 - val_mse: 0.2179 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 52/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1607 - mse: 0.1421\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1345 - mse: 0.1318\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1353 - mse: 0.1321 - val_loss: 0.2278 - val_mse: 0.2149 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 53/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1272 - mse: 0.1299\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1349 - mse: 0.1295\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1326 - mse: 0.1294 - val_loss: 0.2420 - val_mse: 0.2284 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 54/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1156 - mse: 0.1163\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1326 - mse: 0.1306\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1359 - mse: 0.1327 - val_loss: 0.2336 - val_mse: 0.2205 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 55/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1532 - mse: 0.1253\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1366 - mse: 0.1330\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1372 - mse: 0.1340 - val_loss: 0.2263 - val_mse: 0.2135 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 56/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1382 - mse: 0.1293\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1404 - mse: 0.1362\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1404 - mse: 0.1370 - val_loss: 0.2307 - val_mse: 0.2177 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 57/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1574 - mse: 0.1424\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1370 - mse: 0.1318\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1351 - mse: 0.1319 - val_loss: 0.2256 - val_mse: 0.2129 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 58/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1254 - mse: 0.1245\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1338 - mse: 0.1286\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1308 - mse: 0.1277 - val_loss: 0.2359 - val_mse: 0.2226 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 59/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1365 - mse: 0.1390\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1305 - mse: 0.1287\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1300 - mse: 0.1269 - val_loss: 0.2203 - val_mse: 0.2079 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 60/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1075 - mse: 0.1109\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1300 - mse: 0.1269\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1289 - mse: 0.1259 - val_loss: 0.2302 - val_mse: 0.2172 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 61/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1068 - mse: 0.1019\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1266 - mse: 0.1208\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1233 - mse: 0.1204 - val_loss: 0.2169 - val_mse: 0.2047 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 62/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1227 - mse: 0.1081\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1245 - mse: 0.1218\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1244 - mse: 0.1214 - val_loss: 0.2220 - val_mse: 0.2095 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 63/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1304 - mse: 0.1238\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1255 - mse: 0.1208\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1248 - mse: 0.1218 - val_loss: 0.2160 - val_mse: 0.2038 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 64/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1144 - mse: 0.1098\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1253 - mse: 0.1218\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1224 - mse: 0.1195 - val_loss: 0.2117 - val_mse: 0.1998 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 65/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1068 - mse: 0.1035\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1191 - mse: 0.1146\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1189 - mse: 0.1161 - val_loss: 0.2343 - val_mse: 0.2210 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 66/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1181 - mse: 0.1126\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1246 - mse: 0.1231\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1270 - mse: 0.1240 - val_loss: 0.2145 - val_mse: 0.2024 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 67/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1148 - mse: 0.1197\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1259 - mse: 0.1214\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1231 - mse: 0.1202 - val_loss: 0.2092 - val_mse: 0.1974 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 68/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1035 - mse: 0.1121\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1156 - mse: 0.1141\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1176 - mse: 0.1148 - val_loss: 0.2106 - val_mse: 0.1987 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 69/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1136 - mse: 0.1099\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1154 - mse: 0.1117\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1145 - mse: 0.1118 - val_loss: 0.2095 - val_mse: 0.1977 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 70/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1102 - mse: 0.1075\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1106 - mse: 0.1097\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1135 - mse: 0.1108 - val_loss: 0.2031 - val_mse: 0.1916 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 71/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1051 - mse: 0.1111\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1115 - mse: 0.1088\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1128 - mse: 0.1101 - val_loss: 0.2111 - val_mse: 0.1992 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 72/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1248 - mse: 0.1161\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1148 - mse: 0.1120\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1142 - mse: 0.1115 - val_loss: 0.2105 - val_mse: 0.1986 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 73/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1107 - mse: 0.1122\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1132 - mse: 0.1115\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1150 - mse: 0.1123 - val_loss: 0.2018 - val_mse: 0.1904 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 74/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1297 - mse: 0.1203\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1125 - mse: 0.1093\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1133 - mse: 0.1106 - val_loss: 0.2025 - val_mse: 0.1911 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 75/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1221 - mse: 0.1085\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1109 - mse: 0.1079\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1113 - mse: 0.1087 - val_loss: 0.2012 - val_mse: 0.1898 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 76/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1200 - mse: 0.1096\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1118 - mse: 0.1083\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1126 - mse: 0.1099 - val_loss: 0.2063 - val_mse: 0.1947 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 77/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0990 - mse: 0.0951\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1170 - mse: 0.1137\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1167 - mse: 0.1140 - val_loss: 0.2024 - val_mse: 0.1909 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 78/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1132 - mse: 0.1072\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1112 - mse: 0.1067\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1098 - mse: 0.1072 - val_loss: 0.1991 - val_mse: 0.1879 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 79/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1237 - mse: 0.1168\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.1123 - mse: 0.1091\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1141 - mse: 0.1114 - val_loss: 0.2159 - val_mse: 0.2038 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 80/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1039 - mse: 0.1060\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1161 - mse: 0.1142\u001b[0m\n",
      "\n",
      "2025-12-19 03:41:47 Uploading - Uploading generated training model\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1165 - mse: 0.1137 - val_loss: 0.2120 - val_mse: 0.2000 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 81/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1077 - mse: 0.1198\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1078 - mse: 0.1054\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1124 - mse: 0.1097 - val_loss: 0.2003 - val_mse: 0.1890 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 82/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1270 - mse: 0.1091\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1174 - mse: 0.1145\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1198 - mse: 0.1169 - val_loss: 0.2116 - val_mse: 0.1996 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 83/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1066 - mse: 0.0988\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1199 - mse: 0.1181\u001b[0m\n",
      "\u001b[34mEpoch 83: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1173 - mse: 0.1145 - val_loss: 0.2048 - val_mse: 0.1932 - lr: 1.0000e-04\u001b[0m\n",
      "\u001b[34mEpoch 84/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0972 - mse: 0.0965\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.1097 - mse: 0.1058\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.1067 - mse: 0.1042 - val_loss: 0.1971 - val_mse: 0.1860 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 85/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0957 - mse: 0.0936\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0990 - mse: 0.0959\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0976 - mse: 0.0952 - val_loss: 0.1977 - val_mse: 0.1865 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 86/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0814 - mse: 0.0848\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0964 - mse: 0.0929\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0944 - mse: 0.0921 - val_loss: 0.1910 - val_mse: 0.1802 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 87/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.1010 - mse: 0.0954\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0964 - mse: 0.0917\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0939 - mse: 0.0917 - val_loss: 0.1944 - val_mse: 0.1834 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 88/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0970 - mse: 0.0907\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.0930 - mse: 0.0913\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0949 - mse: 0.0927 - val_loss: 0.1895 - val_mse: 0.1788 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 89/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0725 - mse: 0.0784\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0895 - mse: 0.0875\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0907 - mse: 0.0885 - val_loss: 0.1922 - val_mse: 0.1813 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 90/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0800 - mse: 0.0801\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.0884 - mse: 0.0864\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0893 - mse: 0.0872 - val_loss: 0.1902 - val_mse: 0.1795 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 91/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0873 - mse: 0.0893\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0898 - mse: 0.0879\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0909 - mse: 0.0887 - val_loss: 0.1933 - val_mse: 0.1824 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 92/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0839 - mse: 0.0780\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0881 - mse: 0.0864\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0893 - mse: 0.0872 - val_loss: 0.1888 - val_mse: 0.1782 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 93/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0901 - mse: 0.0889\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0844 - mse: 0.0825\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0854 - mse: 0.0834 - val_loss: 0.1928 - val_mse: 0.1819 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 94/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0834 - mse: 0.0883\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0843 - mse: 0.0828\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0867 - mse: 0.0846 - val_loss: 0.1875 - val_mse: 0.1769 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 95/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0916 - mse: 0.0845\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0861 - mse: 0.0857\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0872 - mse: 0.0852 - val_loss: 0.1902 - val_mse: 0.1794 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 96/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0895 - mse: 0.0829\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0887 - mse: 0.0859\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0880 - mse: 0.0859 - val_loss: 0.1953 - val_mse: 0.1843 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 97/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0752 - mse: 0.0799\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0878 - mse: 0.0846\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0875 - mse: 0.0854 - val_loss: 0.1889 - val_mse: 0.1783 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 98/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0861 - mse: 0.0808\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0849 - mse: 0.0838\u001b[0m\n",
      "\u001b[34mEpoch 98: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0865 - mse: 0.0845 - val_loss: 0.1881 - val_mse: 0.1775 - lr: 5.0000e-05\u001b[0m\n",
      "\u001b[34mEpoch 99/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0926 - mse: 0.0864\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0842 - mse: 0.0831\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0851 - mse: 0.0831 - val_loss: 0.1832 - val_mse: 0.1728 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 100/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0859 - mse: 0.0882\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0793 - mse: 0.0782\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0810 - mse: 0.0791 - val_loss: 0.1862 - val_mse: 0.1757 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 101/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0888 - mse: 0.0821\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0812 - mse: 0.0791\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0819 - mse: 0.0799 - val_loss: 0.1887 - val_mse: 0.1781 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 102/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0946 - mse: 0.0811\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0809 - mse: 0.0795\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0814 - mse: 0.0795 - val_loss: 0.1862 - val_mse: 0.1757 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 103/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0806 - mse: 0.0783\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.0792 - mse: 0.0778\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0799 - mse: 0.0780 - val_loss: 0.1815 - val_mse: 0.1713 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 104/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0795 - mse: 0.0730\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0801 - mse: 0.0777\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0797 - mse: 0.0778 - val_loss: 0.1841 - val_mse: 0.1737 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 105/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0814 - mse: 0.0816\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0803 - mse: 0.0794\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0807 - mse: 0.0788 - val_loss: 0.1837 - val_mse: 0.1733 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 106/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0860 - mse: 0.0797\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0812 - mse: 0.0788\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0810 - mse: 0.0791 - val_loss: 0.1842 - val_mse: 0.1738 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 107/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0929 - mse: 0.0776\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.0808 - mse: 0.0785\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0805 - mse: 0.0786 - val_loss: 0.1843 - val_mse: 0.1739 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 108/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0920 - mse: 0.0771\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0791 - mse: 0.0775\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0802 - mse: 0.0783 - val_loss: 0.1857 - val_mse: 0.1752 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 109/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0789 - mse: 0.0813\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0797 - mse: 0.0788\u001b[0m\n",
      "\u001b[34mEpoch 109: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0813 - mse: 0.0793 - val_loss: 0.1797 - val_mse: 0.1695 - lr: 2.5000e-05\u001b[0m\n",
      "\u001b[34mEpoch 110/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0863 - mse: 0.0739\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.0796 - mse: 0.0776\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0797 - mse: 0.0779 - val_loss: 0.1821 - val_mse: 0.1719 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 111/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0702 - mse: 0.0729\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0770 - mse: 0.0750\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0771 - mse: 0.0753 - val_loss: 0.1849 - val_mse: 0.1745 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 112/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0781 - mse: 0.0701\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517/25 [===================>..........] - ETA: 0s - loss: 0.0794 - mse: 0.0762\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0777 - mse: 0.0758 - val_loss: 0.1819 - val_mse: 0.1716 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 113/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0651 - mse: 0.0696\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0764 - mse: 0.0745\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0767 - mse: 0.0749 - val_loss: 0.1841 - val_mse: 0.1737 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 114/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0698 - mse: 0.0674\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0771 - mse: 0.0750\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0765 - mse: 0.0747 - val_loss: 0.1836 - val_mse: 0.1733 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 115/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0788 - mse: 0.0708\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0751 - mse: 0.0738\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0761 - mse: 0.0742 - val_loss: 0.1815 - val_mse: 0.1713 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 116/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0800 - mse: 0.0773\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0781 - mse: 0.0756\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0774 - mse: 0.0756 - val_loss: 0.1847 - val_mse: 0.1742 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 117/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0766 - mse: 0.0791\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0772 - mse: 0.0746\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0765 - mse: 0.0747 - val_loss: 0.1810 - val_mse: 0.1708 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 118/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0753 - mse: 0.0759\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0767 - mse: 0.0764\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0776 - mse: 0.0758 - val_loss: 0.1863 - val_mse: 0.1758 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 119/300\u001b[0m\n",
      "\u001b[34m1/25 [>.............................] - ETA: 0s - loss: 0.0705 - mse: 0.0737\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518/25 [====================>.........] - ETA: 0s - loss: 0.0782 - mse: 0.0768\u001b[0m\n",
      "\u001b[34mRestoring model weights from the end of the best epoch: 109.\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525/25 [==============================] - 0s 5ms/step - loss: 0.0779 - mse: 0.0761 - val_loss: 0.1833 - val_mse: 0.1729 - lr: 1.2500e-05\u001b[0m\n",
      "\u001b[34mEpoch 119: early stopping\u001b[0m\n",
      "\u001b[34mFinished combination 1. Best val_loss for this model: 0.179673\u001b[0m\n",
      "\u001b[34m>>> New best model found! Updating best model ...\u001b[0m\n",
      "\u001b[34m================ BEST MODEL =================\u001b[0m\n",
      "\u001b[34mBest validation loss: 0.1796731799840927\u001b[0m\n",
      "\u001b[34mBest hyper-parameters:\u001b[0m\n",
      "\u001b[34mnum_hidden_layers: 1\n",
      "  num_neurons: 256\n",
      "  activation: gelu\n",
      "  learning_rate: 0.0001\n",
      "  optimizer: adam\u001b[0m\n",
      "\u001b[34m=============================================\u001b[0m\n",
      "\u001b[34mSaving best model to /opt/ml/model/eff_ann_version8.h5 ...\u001b[0m\n",
      "\u001b[34mModel saved.\u001b[0m\n",
      "\u001b[34mUploading best model to s3://ai-bmi-predictor/trained-models/efficientnet-models/eff_ann_version8.h5 ...\u001b[0m\n",
      "\u001b[34mUpload complete.\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:42,083 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:42,083 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:42,084 sagemaker_tensorflow_container.training WARNING  Your model will NOT be servable with SageMaker TensorFlow Serving container. The model artifact was not saved in the TensorFlow SavedModel directory structure:\u001b[0m\n",
      "\u001b[34mhttps://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory\u001b[0m\n",
      "\u001b[34m2025-12-19 03:41:42,084 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-12-19 03:42:00 Completed - Training job completed\n",
      "Training seconds: 234\n",
      "Billable seconds: 234\n"
     ]
    }
   ],
   "source": [
    "# import os for directory handling\n",
    "import os  # import os module\n",
    "# import numpy for saving arrays\n",
    "import numpy as np  # import numpy\n",
    "# import SageMaker SDK\n",
    "import sagemaker  # import sagemaker SDK\n",
    "# import TensorFlow estimator\n",
    "from sagemaker.tensorflow import TensorFlow  # import TensorFlow estimator\n",
    "# import TrainingInput for data channels\n",
    "from sagemaker.inputs import TrainingInput  # import TrainingInput\n",
    "\n",
    "# create local base directory for temporary numpy files\n",
    "local_data_root = \"local_np_data\"  # set local data root folder\n",
    "os.makedirs(local_data_root, exist_ok=True)  # create folder if it does not exist\n",
    "\n",
    "# create separate subfolder for training data\n",
    "local_train_dir = os.path.join(local_data_root, \"train\")  # set local train folder\n",
    "os.makedirs(local_train_dir, exist_ok=True)  # create train folder if needed\n",
    "\n",
    "# create separate subfolder for validation data\n",
    "local_val_dir = os.path.join(local_data_root, \"validation\")  # set local validation folder\n",
    "os.makedirs(local_val_dir, exist_ok=True)  # create validation folder if needed\n",
    "\n",
    "# save training feature array\n",
    "np.save(os.path.join(local_train_dir, \"X_train.npy\"), X_train)  # save X_train to disk\n",
    "# save training target array\n",
    "np.save(os.path.join(local_train_dir, \"Y_train.npy\"), Y_train)  # save Y_train to disk\n",
    "# save training weight array\n",
    "np.save(os.path.join(local_train_dir, \"w_train.npy\"), w_train)  # save w_train to disk\n",
    "\n",
    "# save validation feature array\n",
    "np.save(os.path.join(local_val_dir, \"X_val.npy\"), X_val)  # save X_val to disk\n",
    "# save validation target array\n",
    "np.save(os.path.join(local_val_dir, \"Y_val.npy\"), Y_val)  # save Y_val to disk\n",
    "# save validation weight array\n",
    "np.save(os.path.join(local_val_dir, \"w_val.npy\"), w_val)  # save w_val to disk\n",
    "\n",
    "# create SageMaker session\n",
    "sess = sagemaker.Session()  # create SageMaker session object\n",
    "# get execution role for this notebook\n",
    "role = sagemaker.get_execution_role()  # get IAM execution role\n",
    "\n",
    "# set S3 bucket name for data uploads\n",
    "bucket = \"ai-bmi-predictor\"  # target S3 bucket for data\n",
    "# set base S3 prefix under trained-models/efficientnet-models/train-val-arrays\n",
    "base_prefix = \"trained-models/efficientnet-models/train-val-arrays\"  # base S3 prefix for arrays\n",
    "# set S3 prefix for training data inside base prefix\n",
    "train_prefix = f\"{base_prefix}/train\"  # S3 prefix for training data\n",
    "# set S3 prefix for validation data inside base prefix\n",
    "val_prefix = f\"{base_prefix}/validation\"  # S3 prefix for validation data\n",
    "\n",
    "# upload training folder to S3\n",
    "train_s3_path = sess.upload_data(  # upload training data\n",
    "    path=local_train_dir,  # local train folder path\n",
    "    bucket=bucket,  # S3 bucket name\n",
    "    key_prefix=train_prefix  # S3 key prefix for training data\n",
    ")\n",
    "\n",
    "# upload validation folder to S3\n",
    "val_s3_path = sess.upload_data(  # upload validation data\n",
    "    path=local_val_dir,  # local validation folder path\n",
    "    bucket=bucket,  # S3 bucket name\n",
    "    key_prefix=val_prefix  # S3 key prefix for validation data\n",
    ")\n",
    "\n",
    "# create TrainingInput for training channel\n",
    "train_input = TrainingInput(  # define training channel input\n",
    "    s3_data=train_s3_path,  # S3 path of training data\n",
    "    content_type=\"application/x-npy\"  # content type for numpy files\n",
    ")\n",
    "\n",
    "# create TrainingInput for validation channel\n",
    "validation_input = TrainingInput(  # define validation channel input\n",
    "    s3_data=val_s3_path,  # S3 path of validation data\n",
    "    content_type=\"application/x-npy\"  # content type for numpy files\n",
    ")\n",
    "\n",
    "# define TensorFlow estimator for SageMaker training job\n",
    "estimator = TensorFlow(  # create TensorFlow estimator\n",
    "    entry_point=\"train_eff_ann.py\",  # training script file\n",
    "    role=role,  # IAM role for training job\n",
    "    instance_type=\"ml.g4dn.16xlarge\",  # instance type to use\n",
    "    instance_count=1,  # number of instances\n",
    "    framework_version=\"2.12\",  # TensorFlow version\n",
    "    py_version=\"py310\",  # Python version\n",
    "    sagemaker_session=sess,  # attached SageMaker session\n",
    "    base_job_name=\"eff-ann-v8-training\",  # base name for job\n",
    "    output_path=\"s3://ai-bmi-predictor/trained-models/efficientnet-models/\",  # S3 output path\n",
    "    script_mode=True  # enable script mode\n",
    ")\n",
    "\n",
    "# launch SageMaker training job\n",
    "estimator.fit(  # start training\n",
    "    inputs={\"train\": train_input, \"validation\": validation_input},  # map channels to inputs\n",
    "    wait=True,  # block until job finishes\n",
    "    logs=\"All\"  # stream all training logs to this notebook\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288de1d-b36d-4a20-9fa8-dddc271dbec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
