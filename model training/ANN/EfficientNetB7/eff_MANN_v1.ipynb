{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a089bb-ebd7-4d32-b8ce-89424733811e",
   "metadata": {},
   "source": [
    "1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca32a18-ee45-42b9-848f-47c53613db38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ab1d061f51c6079633aeceed2faeb0b</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.108145</td>\n",
       "      <td>-0.138813</td>\n",
       "      <td>0.633156</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>-0.046055</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>-0.058632</td>\n",
       "      <td>0.097968</td>\n",
       "      <td>...</td>\n",
       "      <td>105.333900</td>\n",
       "      <td>76.817467</td>\n",
       "      <td>35.362858</td>\n",
       "      <td>65.993683</td>\n",
       "      <td>54.459591</td>\n",
       "      <td>88.813789</td>\n",
       "      <td>16.764332</td>\n",
       "      <td>female</td>\n",
       "      <td>170.50</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e94e2e05fb8b099955bbc4fa5ce81e22</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>-0.093442</td>\n",
       "      <td>0.736929</td>\n",
       "      <td>0.240569</td>\n",
       "      <td>0.089982</td>\n",
       "      <td>-0.112391</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.076110</td>\n",
       "      <td>...</td>\n",
       "      <td>101.478989</td>\n",
       "      <td>85.154358</td>\n",
       "      <td>37.256760</td>\n",
       "      <td>65.861588</td>\n",
       "      <td>52.773052</td>\n",
       "      <td>89.176338</td>\n",
       "      <td>15.690955</td>\n",
       "      <td>male</td>\n",
       "      <td>178.30</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba6951a4f37fc9302243370e927a02e2</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>-0.071332</td>\n",
       "      <td>-0.154407</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0.196485</td>\n",
       "      <td>-0.125341</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>-0.027295</td>\n",
       "      <td>0.094879</td>\n",
       "      <td>...</td>\n",
       "      <td>97.488243</td>\n",
       "      <td>81.410393</td>\n",
       "      <td>37.503147</td>\n",
       "      <td>66.042679</td>\n",
       "      <td>57.059261</td>\n",
       "      <td>82.201988</td>\n",
       "      <td>16.686253</td>\n",
       "      <td>male</td>\n",
       "      <td>176.25</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947d16539d4702427aa74f737329ffb9</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.075746</td>\n",
       "      <td>-0.128497</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>-0.089796</td>\n",
       "      <td>-0.011273</td>\n",
       "      <td>...</td>\n",
       "      <td>120.586845</td>\n",
       "      <td>69.361534</td>\n",
       "      <td>34.084633</td>\n",
       "      <td>60.413330</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>102.323845</td>\n",
       "      <td>17.693762</td>\n",
       "      <td>female</td>\n",
       "      <td>152.10</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9326695bf62926ec22690f576a633bba</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>-0.154224</td>\n",
       "      <td>0.528140</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>-0.108486</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>-0.099909</td>\n",
       "      <td>0.080770</td>\n",
       "      <td>...</td>\n",
       "      <td>110.543564</td>\n",
       "      <td>77.160583</td>\n",
       "      <td>38.086231</td>\n",
       "      <td>68.400543</td>\n",
       "      <td>57.172279</td>\n",
       "      <td>107.378578</td>\n",
       "      <td>16.594791</td>\n",
       "      <td>male</td>\n",
       "      <td>171.50</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           photo_id        f1        f2        f3        f4  \\\n",
       "0  6ab1d061f51c6079633aeceed2faeb0b  0.000068  0.108145 -0.138813  0.633156   \n",
       "1  e94e2e05fb8b099955bbc4fa5ce81e22  0.020843  0.026005 -0.093442  0.736929   \n",
       "2  ba6951a4f37fc9302243370e927a02e2  0.014542 -0.071332 -0.154407  0.577781   \n",
       "3  947d16539d4702427aa74f737329ffb9  0.041775  0.075746 -0.128497  0.485010   \n",
       "4  9326695bf62926ec22690f576a633bba  0.004397  0.058590 -0.154224  0.528140   \n",
       "\n",
       "         f5        f6        f7        f8        f9  ...         hip  \\\n",
       "0  0.346266 -0.046055  0.016021 -0.058632  0.097968  ...  105.333900   \n",
       "1  0.240569  0.089982 -0.112391  0.000435 -0.076110  ...  101.478989   \n",
       "2  0.196485 -0.125341 -0.056713 -0.027295  0.094879  ...   97.488243   \n",
       "3  0.120409  0.011227  0.017852 -0.089796 -0.011273  ...  120.586845   \n",
       "4  0.290956 -0.108486 -0.021441 -0.099909  0.080770  ...  110.543564   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh       waist  \\\n",
       "0   76.817467         35.362858           65.993683  54.459591   88.813789   \n",
       "1   85.154358         37.256760           65.861588  52.773052   89.176338   \n",
       "2   81.410393         37.503147           66.042679  57.059261   82.201988   \n",
       "3   69.361534         34.084633           60.413330  65.000000  102.323845   \n",
       "4   77.160583         38.086231           68.400543  57.172279  107.378578   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  16.764332  female     170.50       72.0  \n",
       "1  15.690955    male     178.30       71.8  \n",
       "2  16.686253    male     176.25       76.5  \n",
       "3  17.693762  female     152.10       88.9  \n",
       "4  16.594791    male     171.50       88.4  \n",
       "\n",
       "[5 rows x 5138 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "bucket = \"ai-bmi-predictor\"\n",
    "key = \"data/eff_training.csv\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "data = pd.read_csv(obj[\"Body\"])\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca77b-fb2a-4f3c-9897-29c1e84fcde0",
   "metadata": {},
   "source": [
    "2. data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9d28a-110f-4e9d-9936-f18919462e0e",
   "metadata": {},
   "source": [
    "2.1. categorical encoding for 'gender' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a49b37-abd8-4b37-8802-2c181918c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # import pandas for data handling\n",
    "\n",
    "data['gender'] = data['gender'].astype('category')  # convert 'gender' values to categorical type\n",
    "data['gender'] = data['gender'].cat.codes           # replace 'gender' with its numeric category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73940a3b-8471-40f4-93c3-d720861de107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: gender, dtype: int8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9787987-59e1-42a5-be40-d041b7ec47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['height_cm'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054494a2-7444-472e-837b-ab49865ccca7",
   "metadata": {},
   "source": [
    "2.2. define weight frequencies for class imbalance issue for weight_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e3f129-bcd9-4eb8-b9c6-045dc0d70955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples in dataset: 6134\n",
      "\n",
      "Class frequencies:\n",
      "Class 1 (weight_kg < 60): 1049\n",
      "Class 2 (weight_kg > 100): 514\n",
      "Class 3 (60 <= weight_kg <= 100): 4571\n",
      "\n",
      "Number of classes: 3\n",
      "\n",
      "Class weights (inverse frequency):\n",
      "Weight for Class 1 (weight_kg < 60): 1.9491579281855735\n",
      "Weight for Class 2 (weight_kg > 100): 3.9779507133592737\n",
      "Weight for Class 3 (60 <= weight_kg <= 100): 0.4473127689054182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                     # import pandas for data handling\n",
    "import numpy as np                      # import numpy to help with safe division\n",
    "\n",
    "# Assume 'data' is your DataFrame and already loaded\n",
    "#print(\"Preview of data:\\n\", data.head())  # print first few rows to check data\n",
    "print(\"\\nTotal samples in dataset:\", len(data))  # print total number of rows\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Create boolean masks for the three weight_kg classes\n",
    "# -----------------------------\n",
    "class_1_mask = data['weight_kg'] < 60                      # True where weight_kg is less than 60\n",
    "class_2_mask = data['weight_kg'] > 100                     # True where weight_kg is greater than 100\n",
    "class_3_mask = (data['weight_kg'] >= 60) & (data['weight_kg'] <= 100)  # True where weight is between 60 and 100\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Calculate class frequencies (counts)\n",
    "# -----------------------------\n",
    "freq_class_1 = class_1_mask.sum()          # number of samples with weight_kg < 60\n",
    "freq_class_2 = class_2_mask.sum()          # number of samples with weight_kg > 100\n",
    "freq_class_3 = class_3_mask.sum()          # number of samples with 60 <= weight_kg <= 100\n",
    "\n",
    "print(\"\\nClass frequencies:\")              # header for clarity\n",
    "print(\"Class 1 (weight_kg < 60):\", freq_class_1)   # print frequency of class 1\n",
    "print(\"Class 2 (weight_kg > 100):\", freq_class_2)  # print frequency of class 2\n",
    "print(\"Class 3 (60 <= weight_kg <= 100):\", freq_class_3)  # print frequency of class 3\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Number of classes according to the strategy\n",
    "# -----------------------------\n",
    "num_classes = 3                             # we defined three classes by the rules above\n",
    "print(\"\\nNumber of classes:\", num_classes)  # print number of classes\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compute inverse-frequency weights for each class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------\n",
    "total_samples = len(data)                   # total number of rows in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                # helper function to avoid division by zero\n",
    "    if class_freq == 0:                     # check if a class has zero samples\n",
    "        return np.nan                       # return NaN if no samples exist for that class\n",
    "    return total_samples / (num_classes * class_freq)  # apply weighting formula\n",
    "\n",
    "weight_class_1 = safe_weight(freq_class_1)  # compute weight for class 1\n",
    "weight_class_2 = safe_weight(freq_class_2)  # compute weight for class 2\n",
    "weight_class_3 = safe_weight(freq_class_3)  # compute weight for class 3\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency):\")          # header for class weights\n",
    "print(\"Weight for Class 1 (weight_kg < 60):\", weight_class_1)   # print weight of class 1\n",
    "print(\"Weight for Class 2 (weight_kg > 100):\", weight_class_2)  # print weight of class 2\n",
    "print(\"Weight for Class 3 (60 <= weight_kg <= 100):\", weight_class_3)  # print weight of class 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6008f8b-e977-4bef-ae79-33879ec53c33",
   "metadata": {},
   "source": [
    "2.3. define weight frequencies for class imbalance issue for gender feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f089c02-aff3-4c91-b679-be4b012a9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of gender column:\n",
      " 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: gender, dtype: int8\n",
      "\n",
      "Class frequencies for gender:\n",
      "Class 1: 3650\n",
      "Class 0: 2484\n",
      "\n",
      "Number of gender classes: 2\n",
      "\n",
      "Class weights (inverse frequency) for gender:\n",
      "Weight for class 1: 0.8402739726027397\n",
      "Weight for class 0: 1.2347020933977455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                                      # import numpy for numeric utilities (like NaN)\n",
    "\n",
    "print(\"Preview of gender column:\\n\", data['gender'].head())  # show first few gender values to inspect\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Calculate class frequencies for gender\n",
    "# -----------------------------------\n",
    "gender_counts = data['gender'].value_counts()           # count how many samples belong to each gender class\n",
    "\n",
    "print(\"\\nClass frequencies for gender:\")                # header for class frequency output\n",
    "for gender_class, freq in gender_counts.items():        # loop over each gender class and its frequency\n",
    "    print(f\"Class {gender_class}: {freq}\")              # print the class label and its frequency\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Number of gender classes\n",
    "# -----------------------------------\n",
    "num_gender_classes = len(gender_counts)                 # compute how many distinct gender classes we have\n",
    "print(\"\\nNumber of gender classes:\", num_gender_classes)  # print number of gender classes\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Compute inverse-frequency weights for each gender class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------------\n",
    "total_samples = len(data)                               # total number of samples in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                            # define helper function to compute class weight safely\n",
    "    if class_freq == 0:                                 # check for zero frequency to avoid division by zero\n",
    "        return np.nan                                   # return NaN if a class somehow has zero samples\n",
    "    return total_samples / (num_gender_classes * class_freq)  # apply the inverse-frequency weight formula\n",
    "\n",
    "gender_weights = {}                                     # create an empty dictionary to store weights per class\n",
    "for gender_class, freq in gender_counts.items():        # loop through each gender class and its frequency\n",
    "    gender_weights[gender_class] = safe_weight(freq)    # compute and store the weight for this gender class\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency) for gender:\")  # header for weight output\n",
    "for gender_class, weight in gender_weights.items():     # loop over each class and its weight\n",
    "    print(f\"Weight for class {gender_class}: {weight}\") # print the computed weight for this gender class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981d197-ad20-473e-a854-ffca369ef51e",
   "metadata": {},
   "source": [
    "2.4. weight frequencies for weight classes and gender classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc2d86a-9f9f-4ab2-8749-8dc2bd7644a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight-class weights: {'weight_<60': 1.9491579281855735, 'weight_>100': 3.9779507133592737, 'weight_60_100': 0.4473127689054182}\n",
      "Gender-class weights: {1: 0.8402739726027397, 0: 1.2347020933977455}\n",
      "\n",
      "Combined weights for each (weight_class, gender_class):\n",
      "weight_<60 & gender 1: 1.6378266755466175\n",
      "weight_<60 & gender 0: 2.4066293742935403\n",
      "weight_>100 & gender 1: 3.3425684487322993\n",
      "weight_>100 & gender 0: 4.9115840732177505\n",
      "weight_60_100 & gender 1: 0.37586527732408703\n",
      "weight_60_100 & gender 0: 0.5522980121710618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np   # import numpy for numeric operations\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Store the already-computed weights for weight classes\n",
    "#    (use the variables you created when handling weight_kg)\n",
    "# -------------------------------------------------\n",
    "weight_class_weights = {                          # dictionary to hold weight-class weights\n",
    "    'weight_<60':  weight_class_1,                # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,                # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3               # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights to check\n",
    "\n",
    "# gender_weights dict is assumed from previous step, e.g. {0: w0, 1: w1}\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights to check\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Multiply each gender class with each weight class\n",
    "#    wi = w_weight * w_gender\n",
    "# -------------------------------------------------\n",
    "combined_weights = {}                                # dictionary to store combined class weights\n",
    "\n",
    "print(\"\\nCombined weights for each (weight_class, gender_class):\")  # header\n",
    "for w_label, w_w in weight_class_weights.items():    # loop over weight classes\n",
    "    for g_label, w_g in gender_weights.items():      # loop over gender classes\n",
    "        wi = w_w * w_g                               # multiply weight and gender class weights\n",
    "        combined_weights[(w_label, g_label)] = wi    # store in dictionary\n",
    "        print(f\"{w_label} & gender {g_label}: {wi}\") # print each combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487c312-8683-4912-9b37-7e99383b1ed4",
   "metadata": {},
   "source": [
    "2.5. create a dictionary for weights and row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806866b5-519d-48b6-be00-77c2fd191d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before adding index column:\n",
      " Index(['photo_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
      "       ...\n",
      "       'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
      "       'waist', 'wrist', 'gender', 'height_cm', 'weight_kg'],\n",
      "      dtype='object', length=5138)\n"
     ]
    }
   ],
   "source": [
    "# Check current columns in the DataFrame\n",
    "print(\"Columns before adding index column:\\n\", data.columns)\n",
    "\n",
    "# Add a new column named 'index' with values from 0 to number_of_rows-1\n",
    "data['index'] = range(len(data))\n",
    "\n",
    "# Move 'index' to the front (optional, just for nicer viewing)\n",
    "cols = ['index'] + [c for c in data.columns if c != 'index']  # build new column order\n",
    "data = data[cols]                                            # reorder columns\n",
    "\n",
    "# Show first few rows to verify the new indexing column\n",
    "#print(\"\\nDataFrame after adding 'index' column:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41807157-b19f-4328-9e9a-faf126794665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight-class weights: {'weight_<60': 1.9491579281855735, 'weight_>100': 3.9779507133592737, 'weight_60_100': 0.4473127689054182}\n",
      "Gender-class weights: {1: 0.8402739726027397, 0: 1.2347020933977455}\n",
      "\n",
      "Building final_weights dictionary...\n",
      "Number of entries in final_weights: 6134\n",
      "First 5 items in final_weights: [(0, 0.5522980121710618), (1, 0.37586527732408703), (2, 0.37586527732408703), (3, 0.5522980121710618), (4, 0.37586527732408703)]\n",
      "\n",
      "Checking entry with index 0...\n",
      "Row 0 -> gender: 0\n",
      "Row 0 -> weight_kg: 72.0\n",
      "Row 0 -> weight class: weight_60_100\n",
      "w_weight for row 0: 0.4473127689054182\n",
      "w_gender for row 0: 1.2347020933977455\n",
      "Combined weight (calculated): 0.5522980121710618\n",
      "Combined weight from final_weights[0]: 0.5522980121710618\n",
      "\n",
      "Saving final_weights dictionary as pickle file...\n",
      "Dictionary saved to 'final_weights.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np               # import numpy for numeric operations\n",
    "import pickle                    # import pickle to save Python objects\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. We assume these already exist:\n",
    "#    - weight_class_1, weight_class_2, weight_class_3\n",
    "#    - gender_weights   (dict: {gender_class: weight})\n",
    "# -------------------------------------------------\n",
    "\n",
    "# create a dictionary of weight-class weights (same as before)\n",
    "weight_class_weights = {         # dictionary mapping weight class labels to their weights\n",
    "    'weight_<60':  weight_class_1,      # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,      # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3     # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Helper function to get the weight class label for a given weight_kg\n",
    "# -------------------------------------------------\n",
    "def get_weight_class(w):         # define a function that receives a single weight value\n",
    "    if w < 60:                   # check if weight is less than 60\n",
    "        return 'weight_<60'      # return label for class 1\n",
    "    elif w > 100:                # check if weight is greater than 100\n",
    "        return 'weight_>100'     # return label for class 2\n",
    "    else:                        # otherwise weight is between 60 and 100 (inclusive)\n",
    "        return 'weight_60_100'   # return label for class 3\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Build dictionary: keys = index values, values = combined weights\n",
    "# -------------------------------------------------\n",
    "final_weights = {}               # create empty dictionary to store final weights\n",
    "\n",
    "print(\"\\nBuilding final_weights dictionary...\")  # message to track progress\n",
    "\n",
    "for _, row in data.iterrows():   # loop over each row of the DataFrame\n",
    "    idx_val = row['index']       # get the value from the 'index' column for this row\n",
    "    gender_val = row['gender']   # get the gender class value for this row\n",
    "    weight_val = row['weight_kg']# get the weight_kg value for this row\n",
    "\n",
    "    w_class = get_weight_class(weight_val)        # determine weight class label from weight_kg\n",
    "    w_weight = weight_class_weights[w_class]      # look up the weight-class weight\n",
    "    w_gender = gender_weights[gender_val]         # look up the gender-class weight\n",
    "\n",
    "    combined_w = w_weight * w_gender             # multiply to get combined weight w_i\n",
    "    final_weights[idx_val] = combined_w          # store combined weight in dictionary with key=index\n",
    "\n",
    "print(\"Number of entries in final_weights:\", len(final_weights))  # print number of entries\n",
    "print(\"First 5 items in final_weights:\", list(final_weights.items())[:5])  # show first few items\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Check index 0: gender, weight_kg, and combined weight\n",
    "# -------------------------------------------------\n",
    "print(\"\\nChecking entry with index 0...\")        # message to show what we're doing\n",
    "\n",
    "row0 = data.loc[data['index'] == 0].iloc[0]      # select the row where 'index' column equals 0\n",
    "\n",
    "gender0 = row0['gender']                         # get gender value for index 0\n",
    "weight0 = row0['weight_kg']                      # get weight_kg value for index 0\n",
    "w_class0 = get_weight_class(weight0)             # get weight class label for index 0\n",
    "\n",
    "w_weight0 = weight_class_weights[w_class0]       # get weight-class weight for index 0\n",
    "w_gender0 = gender_weights[gender0]              # get gender-class weight for index 0\n",
    "combined0_calc = w_weight0 * w_gender0           # calculate combined weight for index 0\n",
    "\n",
    "print(\"Row 0 -> gender:\", gender0)               # print gender class for index 0\n",
    "print(\"Row 0 -> weight_kg:\", weight0)            # print weight_kg for index 0\n",
    "print(\"Row 0 -> weight class:\", w_class0)        # print weight class label for index 0\n",
    "print(\"w_weight for row 0:\", w_weight0)          # print weight-class weight for index 0\n",
    "print(\"w_gender for row 0:\", w_gender0)          # print gender-class weight for index 0\n",
    "print(\"Combined weight (calculated):\", combined0_calc)        # print calculated combined weight\n",
    "print(\"Combined weight from final_weights[0]:\", final_weights[0])  # print value from dictionary\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Save final_weights dictionary as a pickle file\n",
    "# -------------------------------------------------\n",
    "print(\"\\nSaving final_weights dictionary as pickle file...\")   # message to track saving step\n",
    "\n",
    "with open('final_weights.pkl', 'wb') as f:       # open a file named 'final_weights.pkl' in binary write mode\n",
    "    pickle.dump(final_weights, f)                # write dictionary to the file using pickle\n",
    "\n",
    "print(\"Dictionary saved to 'final_weights.pkl'.\")# confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f74299-3350-46fa-a49f-988b733ca1b8",
   "metadata": {},
   "source": [
    "2.6. apply min-max scaling with range -1 to 1 for body measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eedc423f-20a2-4ff2-a8b9-17d1c011c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler   # import the scaler for min-max normalization\n",
    "\n",
    "# list of columns to scale between -1 and 1\n",
    "cols_to_scale = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'height_cm', 'weight_kg'\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))    # create a scaler that maps values to range [-1, 1]\n",
    "\n",
    "data[cols_to_scale] = scaler.fit_transform(     # fit the scaler and transform the selected columns\n",
    "    data[cols_to_scale]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4707456-2e11-4ead-9ab7-534b91ca8d19",
   "metadata": {},
   "source": [
    "3. model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e07427-117c-46ac-9bdc-f049f9a1024b",
   "metadata": {},
   "source": [
    "3.1. split the data for independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ffaa0e-f6df-4778-ae89-fb050332a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "Shape of Y (samples, targets): (6134, 14)\n"
     ]
    }
   ],
   "source": [
    "# List of columns to be used as dependent (target) features\n",
    "target_cols = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'weight_kg'\n",
    "]\n",
    "\n",
    "# Select these columns from the DataFrame as the multi-target Y\n",
    "Y = data[target_cols]                  # Y will hold all dependent variables for multi-target regression\n",
    "\n",
    "print(\"Selected target columns:\", target_cols)  # print which columns are used as targets\n",
    "print(\"Shape of Y (samples, targets):\", Y.shape)  # print shape to confirm dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69820f72-d599-4ec3-acdf-ab2cc8e9d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop for X:\n",
      " ['photo_id', 'subject_id', 'index', 'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "\n",
      "Shape of X (samples, independent features): (6134, 5122)\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop for building independent features (X)\n",
    "drop_cols = ['photo_id', 'subject_id','index'] + target_cols   # combine ID columns with target columns\n",
    "\n",
    "print(\"Columns to drop for X:\\n\", drop_cols)           # show which columns will be removed\n",
    "\n",
    "# Create X by dropping ID columns and all target columns\n",
    "X = data.drop(columns=drop_cols)                       # drop the unwanted columns to get independent features\n",
    "\n",
    "print(\"\\nShape of X (samples, independent features):\", X.shape)  # print shape of X\n",
    "#print(\"\\nColumns in X:\\n\", X.columns.tolist())         # list all feature names in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8cb5737-d256-4ae3-bd10-f1567065b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 09:42:09.867171: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-11 09:42:22.675984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-11 09:42:29.515554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-11 09:42:29.573218: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-11 09:42:39.043281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-11 09:42:47.507407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (6134, 5122)\n",
      "Shape of Y (targets): (6134, 14)\n",
      "\n",
      "Loading final_weights.pkl ...\n",
      "Number of entries in final_weights_dict: 6134\n",
      "First 5 entries in final_weights_dict: [(0, 0.5522980121710618), (1, 0.37586527732408703), (2, 0.37586527732408703), (3, 0.5522980121710618), (4, 0.37586527732408703)]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "import numpy as np                          # numerical operations\n",
    "import pickle                               # to load the final_weights.pkl file\n",
    "import matplotlib.pyplot as plt             # for plotting loss curves\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # to create train/validation sets\n",
    "\n",
    "import tensorflow as tf                     # main deep learning library\n",
    "from tensorflow.keras.models import Sequential          # model container\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, LeakyReLU, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility (optional)\n",
    "# -----------------------------\n",
    "np.random.seed(42)                          # fix numpy random seed\n",
    "tf.random.set_seed(42)                      # fix tensorflow random seed\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Assume you already have:\n",
    "#    - data DataFrame\n",
    "#    - X (independent features)\n",
    "#    - Y (multi-output targets)\n",
    "# If not, you can recreate X, Y here.\n",
    "# -----------------------------\n",
    "\n",
    "# Example (uncomment if you want everything in one place):\n",
    "# target_cols = [\n",
    "#     'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "#     'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "#     'waist', 'wrist', 'weight_kg'\n",
    "# ]\n",
    "# Y = data[target_cols]                                            # select target columns\n",
    "# drop_cols = ['photo_id', 'subject_id'] + target_cols             # columns not used as features\n",
    "# X = data.drop(columns=drop_cols + ['index'])                     # drop also 'index' from features\n",
    "\n",
    "print(\"Shape of X (features):\", X.shape)           # show shape of feature matrix\n",
    "print(\"Shape of Y (targets):\", Y.shape)           # show shape of target matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load final_weights.pkl (sample weights per index)\n",
    "# -----------------------------\n",
    "print(\"\\nLoading final_weights.pkl ...\")          # status message\n",
    "\n",
    "with open('final_weights.pkl', 'rb') as f:        # open pickle file in read-binary mode\n",
    "    final_weights_dict = pickle.load(f)           # load dictionary {index: weight}\n",
    "\n",
    "print(\"Number of entries in final_weights_dict:\", len(final_weights_dict))  # size of dictionary\n",
    "print(\"First 5 entries in final_weights_dict:\", list(final_weights_dict.items())[:5])  # preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a93e352-a406-4218-8106-1c4481f30ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building sample_weight array ...\n",
      "Sample weights shape: (6134,)\n",
      "First 10 sample weights: [0.552298   0.37586528 0.37586528 0.552298   0.37586528 0.552298\n",
      " 0.37586528 0.37586528 0.552298   0.37586528]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Build sample_weight array based on DataFrame 'index' column\n",
    "# -----------------------------\n",
    "print(\"\\nBuilding sample_weight array ...\")       # status message\n",
    "\n",
    "# map each row's 'index' value to its weight in the dictionary\n",
    "sample_weights = data['index'].map(final_weights_dict).values.astype('float32')\n",
    "\n",
    "print(\"Sample weights shape:\", sample_weights.shape)   # show shape of weight array\n",
    "print(\"First 10 sample weights:\", sample_weights[:10]) # preview some weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db360ce-79cd-4103-928a-8cbf03ecac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting into train and validation sets ...\n",
      "X_train shape: (4907, 5122)\n",
      "Y_train shape: (4907, 14)\n",
      "X_val shape: (1227, 5122)\n",
      "Y_val shape: (1227, 14)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. Train/validation split (X, Y, and weights)\n",
    "# -----------------------------\n",
    "print(\"\\nSplitting into train and validation sets ...\")  # status message\n",
    "\n",
    "X_train, X_val, Y_train, Y_val, w_train, w_val = train_test_split(\n",
    "    X, Y, sample_weights,           # split features, targets, and weights together\n",
    "    test_size=0.2,                  # 20% validation\n",
    "    random_state=42,                # reproducible split\n",
    "    shuffle=True                    # shuffle data before splitting\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)          # show training feature shape\n",
    "print(\"Y_train shape:\", Y_train.shape)          # show training target shape\n",
    "print(\"X_val shape:\", X_val.shape)              # show validation feature shape\n",
    "print(\"Y_val shape:\", Y_val.shape)              # show validation target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d30b43-c913-4831-86b6-b8ec37c6b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hyper-parameter combinations: 1\n",
      "\n",
      "======================================\n",
      "Training combination 1/1\n",
      "Hidden layers: 3\n",
      "Neurons per layer: 512\n",
      "Activation: gelu\n",
      "Learning rate: 0.001\n",
      "Optimizer: adam\n",
      "======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 09:50:37.372917: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.704801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.708123: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.711635: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.714370: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.716873: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.871702: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.872838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.873837: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-11 09:50:45.875828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13760 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765446668.403207   11667 service.cc:145] XLA service 0x7fc42c5eb800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765446668.403246   11667 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-12-11 09:51:08.633463: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-11 09:51:08.679953: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1765446669.083087   11667 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 23s 40ms/step - loss: 0.1818 - mse: 0.1775 - val_loss: 0.0749 - val_mse: 0.0706 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0762 - mse: 0.0744 - val_loss: 0.0593 - val_mse: 0.0559 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0639 - mse: 0.0624 - val_loss: 0.0518 - val_mse: 0.0488 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0576 - mse: 0.0562 - val_loss: 0.0512 - val_mse: 0.0483 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0504 - mse: 0.0492 - val_loss: 0.0471 - val_mse: 0.0444 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0472 - mse: 0.0461 - val_loss: 0.0377 - val_mse: 0.0356 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0427 - mse: 0.0417 - val_loss: 0.0350 - val_mse: 0.0330 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0393 - mse: 0.0384 - val_loss: 0.0327 - val_mse: 0.0308 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0422 - mse: 0.0412 - val_loss: 0.0387 - val_mse: 0.0365 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0349 - mse: 0.0341 - val_loss: 0.0288 - val_mse: 0.0271 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0335 - mse: 0.0327 - val_loss: 0.0277 - val_mse: 0.0262 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0303 - mse: 0.0296 - val_loss: 0.0265 - val_mse: 0.0250 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0308 - mse: 0.0300 - val_loss: 0.0268 - val_mse: 0.0253 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0302 - mse: 0.0295 - val_loss: 0.0247 - val_mse: 0.0233 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0306 - mse: 0.0299 - val_loss: 0.0309 - val_mse: 0.0291 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0333 - mse: 0.0325 - val_loss: 0.0259 - val_mse: 0.0245 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0290 - mse: 0.0283 - val_loss: 0.0264 - val_mse: 0.0249 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0280 - mse: 0.0273 - val_loss: 0.0231 - val_mse: 0.0218 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0260 - mse: 0.0254 - val_loss: 0.0236 - val_mse: 0.0223 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0250 - mse: 0.0244 - val_loss: 0.0220 - val_mse: 0.0207 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0265 - mse: 0.0259 - val_loss: 0.0280 - val_mse: 0.0264 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0269 - mse: 0.0263 - val_loss: 0.0244 - val_mse: 0.0230 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0247 - mse: 0.0241 - val_loss: 0.0237 - val_mse: 0.0223 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - mse: 0.0232 - val_loss: 0.0257 - val_mse: 0.0243 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0238 - mse: 0.0233 - val_loss: 0.0218 - val_mse: 0.0205 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0258 - mse: 0.0252 - val_loss: 0.0259 - val_mse: 0.0245 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - mse: 0.0232 - val_loss: 0.0216 - val_mse: 0.0203 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0228 - mse: 0.0222 - val_loss: 0.0211 - val_mse: 0.0199 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0225 - mse: 0.0220 - val_loss: 0.0215 - val_mse: 0.0203 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0230 - mse: 0.0224 - val_loss: 0.0214 - val_mse: 0.0202 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0237 - mse: 0.0231 - val_loss: 0.0210 - val_mse: 0.0198 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - mse: 0.0218 - val_loss: 0.0227 - val_mse: 0.0214 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0223 - mse: 0.0217 - val_loss: 0.0197 - val_mse: 0.0186 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0220 - mse: 0.0215 - val_loss: 0.0221 - val_mse: 0.0208 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - mse: 0.0212 - val_loss: 0.0268 - val_mse: 0.0253 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0234 - mse: 0.0228 - val_loss: 0.0211 - val_mse: 0.0199 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - mse: 0.0213 - val_loss: 0.0207 - val_mse: 0.0196 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0212 - mse: 0.0207 - val_loss: 0.0230 - val_mse: 0.0217 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0213 - mse: 0.0208 - val_loss: 0.0194 - val_mse: 0.0183 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - mse: 0.0213 - val_loss: 0.0213 - val_mse: 0.0201 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0218 - mse: 0.0213 - val_loss: 0.0197 - val_mse: 0.0186 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - mse: 0.0200 - val_loss: 0.0186 - val_mse: 0.0176 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0205 - mse: 0.0200 - val_loss: 0.0192 - val_mse: 0.0181 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0211 - mse: 0.0206 - val_loss: 0.0242 - val_mse: 0.0229 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0216 - mse: 0.0211 - val_loss: 0.0188 - val_mse: 0.0178 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0202 - mse: 0.0197 - val_loss: 0.0184 - val_mse: 0.0174 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0193 - mse: 0.0188 - val_loss: 0.0183 - val_mse: 0.0172 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0201 - mse: 0.0197 - val_loss: 0.0188 - val_mse: 0.0177 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - mse: 0.0190 - val_loss: 0.0213 - val_mse: 0.0201 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0194 - mse: 0.0190 - val_loss: 0.0183 - val_mse: 0.0173 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - mse: 0.0182 - val_loss: 0.0187 - val_mse: 0.0177 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - mse: 0.0185 - val_loss: 0.0198 - val_mse: 0.0187 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0186 - mse: 0.0182 - val_loss: 0.0189 - val_mse: 0.0179 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0195 - mse: 0.0190 - val_loss: 0.0246 - val_mse: 0.0232 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0214 - mse: 0.0209 - val_loss: 0.0205 - val_mse: 0.0194 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0197 - mse: 0.0194\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0196 - mse: 0.0192 - val_loss: 0.0182 - val_mse: 0.0172 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0174 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0163 - lr: 5.0000e-04\n",
      "Epoch 58/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0171 - mse: 0.0167 - val_loss: 0.0171 - val_mse: 0.0161 - lr: 5.0000e-04\n",
      "Epoch 59/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0165 - mse: 0.0161 - val_loss: 0.0172 - val_mse: 0.0162 - lr: 5.0000e-04\n",
      "Epoch 60/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0163 - mse: 0.0159 - val_loss: 0.0174 - val_mse: 0.0165 - lr: 5.0000e-04\n",
      "Epoch 61/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - mse: 0.0162 - val_loss: 0.0167 - val_mse: 0.0158 - lr: 5.0000e-04\n",
      "Epoch 62/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - mse: 0.0156 - val_loss: 0.0173 - val_mse: 0.0163 - lr: 5.0000e-04\n",
      "Epoch 63/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - mse: 0.0162 - val_loss: 0.0166 - val_mse: 0.0157 - lr: 5.0000e-04\n",
      "Epoch 64/300\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0165 - mse: 0.0161 - val_loss: 0.0167 - val_mse: 0.0158 - lr: 5.0000e-04\n",
      "Epoch 65/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0166 - mse: 0.0162 - val_loss: 0.0168 - val_mse: 0.0158 - lr: 5.0000e-04\n",
      "Epoch 66/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0159 - mse: 0.0156 - val_loss: 0.0165 - val_mse: 0.0156 - lr: 5.0000e-04\n",
      "Epoch 67/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0161 - mse: 0.0158\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0162 - mse: 0.0158 - val_loss: 0.0163 - val_mse: 0.0154 - lr: 5.0000e-04\n",
      "Epoch 68/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - mse: 0.0152 - val_loss: 0.0163 - val_mse: 0.0154 - lr: 2.5000e-04\n",
      "Epoch 69/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - mse: 0.0149 - val_loss: 0.0161 - val_mse: 0.0152 - lr: 2.5000e-04\n",
      "Epoch 70/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0157 - mse: 0.0153 - val_loss: 0.0164 - val_mse: 0.0155 - lr: 2.5000e-04\n",
      "Epoch 71/300\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0155 - mse: 0.0151 - val_loss: 0.0160 - val_mse: 0.0151 - lr: 2.5000e-04\n",
      "Epoch 72/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - mse: 0.0148 - val_loss: 0.0159 - val_mse: 0.0150 - lr: 2.5000e-04\n",
      "Epoch 73/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - mse: 0.0147 - val_loss: 0.0162 - val_mse: 0.0153 - lr: 2.5000e-04\n",
      "Epoch 74/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - mse: 0.0149 - val_loss: 0.0159 - val_mse: 0.0150 - lr: 2.5000e-04\n",
      "Epoch 75/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - mse: 0.0148 - val_loss: 0.0160 - val_mse: 0.0151 - lr: 2.5000e-04\n",
      "Epoch 76/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0152 - mse: 0.0148 - val_loss: 0.0164 - val_mse: 0.0155 - lr: 2.5000e-04\n",
      "Epoch 77/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0151 - mse: 0.0147 - val_loss: 0.0160 - val_mse: 0.0151 - lr: 2.5000e-04\n",
      "Epoch 78/300\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 0.0151 - mse: 0.0147\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - mse: 0.0147 - val_loss: 0.0162 - val_mse: 0.0153 - lr: 2.5000e-04\n",
      "Epoch 79/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - mse: 0.0146 - val_loss: 0.0158 - val_mse: 0.0149 - lr: 1.2500e-04\n",
      "Epoch 80/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - mse: 0.0142 - val_loss: 0.0157 - val_mse: 0.0148 - lr: 1.2500e-04\n",
      "Epoch 81/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0146 - mse: 0.0143 - val_loss: 0.0157 - val_mse: 0.0148 - lr: 1.2500e-04\n",
      "Epoch 82/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - mse: 0.0144 - val_loss: 0.0158 - val_mse: 0.0149 - lr: 1.2500e-04\n",
      "Epoch 83/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - mse: 0.0143 - val_loss: 0.0159 - val_mse: 0.0150 - lr: 1.2500e-04\n",
      "Epoch 84/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - mse: 0.0142 - val_loss: 0.0158 - val_mse: 0.0149 - lr: 1.2500e-04\n",
      "Epoch 85/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0146 - mse: 0.0143\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0147 - mse: 0.0144 - val_loss: 0.0156 - val_mse: 0.0147 - lr: 1.2500e-04\n",
      "Epoch 86/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - mse: 0.0140 - val_loss: 0.0157 - val_mse: 0.0148 - lr: 6.2500e-05\n",
      "Epoch 87/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - mse: 0.0141 - val_loss: 0.0156 - val_mse: 0.0148 - lr: 6.2500e-05\n",
      "Epoch 88/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - mse: 0.0142 - val_loss: 0.0158 - val_mse: 0.0149 - lr: 6.2500e-05\n",
      "Epoch 89/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - mse: 0.0141 - val_loss: 0.0157 - val_mse: 0.0148 - lr: 6.2500e-05\n",
      "Epoch 90/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - mse: 0.0139 - val_loss: 0.0157 - val_mse: 0.0148 - lr: 6.2500e-05\n",
      "Epoch 91/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0156 - val_mse: 0.0147 - lr: 6.2500e-05\n",
      "Epoch 92/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0145 - mse: 0.0141 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 6.2500e-05\n",
      "Epoch 93/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 6.2500e-05\n",
      "Epoch 94/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0144 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 6.2500e-05\n",
      "Epoch 95/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 6.2500e-05\n",
      "Epoch 96/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0144 - mse: 0.0139\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - mse: 0.0139 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 6.2500e-05\n",
      "Epoch 97/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - mse: 0.0140 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 3.1250e-05\n",
      "Epoch 98/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0156 - val_mse: 0.0147 - lr: 3.1250e-05\n",
      "Epoch 99/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - mse: 0.0139 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 3.1250e-05\n",
      "Epoch 100/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 3.1250e-05\n",
      "Epoch 101/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0141 - mse: 0.0137\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 3.1250e-05\n",
      "Epoch 102/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.5625e-05\n",
      "Epoch 103/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 1.5625e-05\n",
      "Epoch 104/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 1.5625e-05\n",
      "Epoch 105/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 1.5625e-05\n",
      "Epoch 106/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.5625e-05\n",
      "Epoch 107/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.5625e-05\n",
      "Epoch 108/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0140 - mse: 0.0136\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 0.0135 - val_loss: 0.0155 - val_mse: 0.0146 - lr: 1.5625e-05\n",
      "Epoch 109/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 7.8125e-06\n",
      "Epoch 110/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 7.8125e-06\n",
      "Epoch 111/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - mse: 0.0139 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 7.8125e-06\n",
      "Epoch 112/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 7.8125e-06\n",
      "Epoch 113/300\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.0143 - mse: 0.0141\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0142 - mse: 0.0139 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 7.8125e-06\n",
      "Epoch 114/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - mse: 0.0135 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 3.9063e-06\n",
      "Epoch 115/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0143 - mse: 0.0139 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 3.9063e-06\n",
      "Epoch 116/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 3.9063e-06\n",
      "Epoch 117/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 3.9063e-06\n",
      "Epoch 118/300\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 0.0139 - mse: 0.0136\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 3.9063e-06\n",
      "Epoch 119/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0146 - lr: 1.9531e-06\n",
      "Epoch 120/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.9531e-06\n",
      "Epoch 121/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.9531e-06\n",
      "Epoch 122/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.9531e-06\n",
      "Epoch 123/300\n",
      "21/25 [========================>.....] - ETA: 0s - loss: 0.0140 - mse: 0.0138\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.9531e-06\n",
      "Epoch 124/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.0000e-06\n",
      "Epoch 125/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.0000e-06\n",
      "Epoch 126/300\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0138 - mse: 0.0135 - val_loss: 0.0154 - val_mse: 0.0145 - lr: 1.0000e-06\n",
      "Epoch 126: early stopping\n",
      "Restoring model weights from the end of the best epoch: 116.\n",
      "Finished combination 1. Best val_loss: 0.015383\n",
      ">>> New BEST model found!\n",
      "\n",
      "================ BEST MODEL =================\n",
      "Best validation loss: 0.015382734127342701\n",
      "Best hyper-parameters:\n",
      "  num_hidden_layers: 3\n",
      "  num_neurons: 512\n",
      "  activation: gelu\n",
      "  learning_rate: 0.001\n",
      "  optimizer: adam\n",
      "===============================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving best model to 'eff_mann_v1.h5' ...\n",
      "Model saved. Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# IMPORTS\n",
    "# ==============================\n",
    "\n",
    "import numpy as np                              # numerical operations\n",
    "import tensorflow as tf                         # deep learning framework\n",
    "import matplotlib.pyplot as plt                 # plotting training curves\n",
    "\n",
    "from tensorflow.keras import Sequential         # Sequential model builder\n",
    "from tensorflow.keras.layers import (           # layers we need\n",
    "    Dense, Dropout, Activation, LeakyReLU, InputLayer\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop   # optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau  # callbacks\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# MULTITASK MODEL BUILDER (14 regression outputs)\n",
    "# ==============================\n",
    "def build_multitask_model(num_hidden_layers, num_neurons, activation_name,\n",
    "                          learning_rate, optimizer_name, input_dim,\n",
    "                          output_dim=14, dropout_rate=0.3):\n",
    "\n",
    "    model = Sequential()                                        # create empty model\n",
    "    model.add(InputLayer(input_shape=(input_dim,)))             # define input shape\n",
    "\n",
    "    # ----- Build shared hidden layers -----\n",
    "    for _ in range(num_hidden_layers):                          # loop through hidden layers\n",
    "        model.add(Dense(num_neurons))                           # add dense layer with N neurons\n",
    "\n",
    "        # activation selection\n",
    "        if activation_name.lower() == \"leakyrelu\":              # option: LeakyReLU\n",
    "            model.add(LeakyReLU(alpha=0.1))\n",
    "        elif activation_name.lower() == \"gelu\":                 # option: GELU\n",
    "            model.add(Activation(tf.keras.activations.gelu))\n",
    "        elif activation_name.lower() == \"tanh\":                 # option: tanh\n",
    "            model.add(Activation(\"tanh\"))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation_name}\")  # unsupported activation\n",
    "\n",
    "        model.add(Dropout(dropout_rate))                        # dropout for regularization\n",
    "\n",
    "    # ----- Multitask Output Layer (14 tasks) -----\n",
    "    model.add(Dense(output_dim, activation=\"linear\"))           # final linear regression output layer\n",
    "\n",
    "    # ----- Select optimizer -----\n",
    "    if optimizer_name.lower() == \"sgd\":                         # SGD optimizer\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    elif optimizer_name.lower() == \"adam\":                      # Adam optimizer\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name.lower() == \"rmsprop\":                   # RMSProp optimizer\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\") # unsupported optimizer\n",
    "\n",
    "    # ----- Compile model -----\n",
    "    model.compile(\n",
    "        optimizer=optimizer,                                    # selected optimizer\n",
    "        loss=\"mse\",                                             # MSE loss for all outputs\n",
    "        weighted_metrics=[tf.keras.metrics.MeanSquaredError(name=\"mse\")]  # weighted MSE\n",
    "    )\n",
    "\n",
    "    return model                                                # return compiled model\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# HYPERPARAMETER GRID\n",
    "# ==============================\n",
    "\n",
    "num_hidden_layers_list = [3]           # number of hidden layers to test\n",
    "num_neurons_list = [512]                # number of neurons per layer\n",
    "activation_list = [\"gelu\"]             # activation functions to test\n",
    "learning_rates = [1e-3]                # learning rates to test\n",
    "optimizer_list = [\"adam\"]              # optimizers to test\n",
    "\n",
    "batch_size = 200                       # training batch size\n",
    "num_epochs = 300                       # maximum number of epochs to train\n",
    "\n",
    "# compute number of grid search combinations\n",
    "total_combinations = (\n",
    "    len(num_hidden_layers_list) *\n",
    "    len(num_neurons_list) *\n",
    "    len(activation_list) *\n",
    "    len(learning_rates) *\n",
    "    len(optimizer_list)\n",
    ")\n",
    "\n",
    "print(\"Total hyper-parameter combinations:\", total_combinations)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# GRID SEARCH TRAINING LOOP\n",
    "# ==============================\n",
    "\n",
    "best_val_loss = np.inf                 # initialize best validation loss\n",
    "best_history = None                    # store best model training history\n",
    "best_params = None                     # store hyperparameters of best model\n",
    "best_model = None                      # store best model object\n",
    "\n",
    "combo_counter = 0                      # counter for combinations tested\n",
    "\n",
    "input_dim = X_train.shape[1]           # number of input features\n",
    "output_dim = Y_train.shape[1]          # number of target outputs (should be 14)\n",
    "\n",
    "# loop through each combination of hyperparameters\n",
    "for num_hidden_layers in num_hidden_layers_list:\n",
    "    for num_neurons in num_neurons_list:\n",
    "        for activation_name in activation_list:\n",
    "            for lr in learning_rates:\n",
    "                for optimizer_name in optimizer_list:\n",
    "\n",
    "                    combo_counter += 1   # increment combination index\n",
    "\n",
    "                    # print which combination is running\n",
    "                    print(\"\\n======================================\")\n",
    "                    print(f\"Training combination {combo_counter}/{total_combinations}\")\n",
    "                    print(f\"Hidden layers: {num_hidden_layers}\")\n",
    "                    print(f\"Neurons per layer: {num_neurons}\")\n",
    "                    print(f\"Activation: {activation_name}\")\n",
    "                    print(f\"Learning rate: {lr}\")\n",
    "                    print(f\"Optimizer: {optimizer_name}\")\n",
    "                    print(\"======================================\")\n",
    "\n",
    "                    # ----- Build multitask model -----\n",
    "                    model = build_multitask_model(\n",
    "                        num_hidden_layers=num_hidden_layers,\n",
    "                        num_neurons=num_neurons,\n",
    "                        activation_name=activation_name,\n",
    "                        learning_rate=lr,\n",
    "                        optimizer_name=optimizer_name,\n",
    "                        input_dim=input_dim,\n",
    "                        output_dim=output_dim\n",
    "                    )\n",
    "\n",
    "                    # ----- Early stopping -----\n",
    "                    early_stop = EarlyStopping(\n",
    "                        monitor='val_loss',            # track validation loss\n",
    "                        patience=10,                   # stop after 10 epochs with no improvement\n",
    "                        restore_best_weights=True,     # keep best weights\n",
    "                        verbose=1                      # print messages\n",
    "                    )\n",
    "\n",
    "                    # ----- Learning rate scheduler -----\n",
    "                    lr_scheduler = ReduceLROnPlateau(\n",
    "                        monitor=\"loss\",                # reduce LR when training loss stalls\n",
    "                        factor=0.5,                    # reduce LR by half\n",
    "                        patience=5,                    # wait 5 epochs before reducing LR\n",
    "                        min_lr=1e-6,                   # minimum allowed LR\n",
    "                        verbose=1                      # print messages\n",
    "                    )\n",
    "\n",
    "                    callbacks = [early_stop, lr_scheduler]    # list of callbacks\n",
    "\n",
    "                    # ----- Train the model -----\n",
    "                    history = model.fit(\n",
    "                        X_train,                       # training features\n",
    "                        Y_train,                       # training targets (14 outputs)\n",
    "                        sample_weight=w_train,         # sample-level weights\n",
    "                        validation_data=(X_val, Y_val, w_val),  # validation set\n",
    "                        epochs=num_epochs,             # max epochs\n",
    "                        batch_size=batch_size,         # batch size\n",
    "                        callbacks=callbacks,           # callbacks\n",
    "                        verbose=1                      # verbose training output\n",
    "                    )\n",
    "\n",
    "                    # get the minimum validation loss for this model\n",
    "                    min_val_loss = min(history.history[\"val_loss\"])\n",
    "                    print(f\"Finished combination {combo_counter}. Best val_loss: {min_val_loss:.6f}\")\n",
    "\n",
    "                    # update best model if this one is better\n",
    "                    if min_val_loss < best_val_loss:\n",
    "                        print(\">>> New BEST model found!\")\n",
    "                        best_val_loss = min_val_loss\n",
    "                        best_history = history\n",
    "                        best_params = {\n",
    "                            \"num_hidden_layers\": num_hidden_layers,\n",
    "                            \"num_neurons\": num_neurons,\n",
    "                            \"activation\": activation_name,\n",
    "                            \"learning_rate\": lr,\n",
    "                            \"optimizer\": optimizer_name\n",
    "                        }\n",
    "                        best_model = model\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PRINT BEST PARAMETERS\n",
    "# ==============================\n",
    "\n",
    "print(\"\\n================ BEST MODEL =================\")\n",
    "print(\"Best validation loss:\", best_val_loss)\n",
    "print(\"Best hyper-parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PLOT TRAINING CURVES\n",
    "# ==============================\n",
    "\n",
    "plt.figure(figsize=(8, 5))                            # figure size\n",
    "plt.plot(best_history.history[\"loss\"], label=\"Train loss\")          # plot training loss\n",
    "plt.plot(best_history.history[\"val_loss\"], label=\"Validation loss\") # plot validation loss\n",
    "plt.xlabel(\"Epoch\")                                   # x-axis label\n",
    "plt.ylabel(\"Loss (MSE)\")                              # y-axis label\n",
    "plt.title(\"Training vs Validation Loss (Best Model)\") # title\n",
    "plt.legend()                                          # show legend\n",
    "plt.grid(True)                                        # show grid\n",
    "plt.tight_layout()                                    # clean layout\n",
    "plt.show()                                            # display plot\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# SAVE BEST MODEL\n",
    "# ==============================\n",
    "\n",
    "print(\"\\nSaving best model to 'eff_mann_v1.h5' ...\")      # notify save\n",
    "best_model.save(\"eff_mann_v1.h5\")                         # save model to file\n",
    "print(\"Model saved. Done!\")                            # confirmation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "857b5d17-e9bb-402a-b96d-f0964e47485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file: eff_mann_v1.h5\n",
      "Model will be uploaded to s3://ai-bmi-predictor/trained-models/efficientnet-models/eff_mann_version1.h5\n",
      "Uploading model to S3 ...\n",
      "Upload completed successfully!\n",
      "File is now at: s3://ai-bmi-predictor/trained-models/efficientnet-models/eff_mann_version1.h5\n"
     ]
    }
   ],
   "source": [
    "import boto3                    # AWS SDK for Python\n",
    "import os                       # to check file paths\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Local model file info\n",
    "# -----------------------------\n",
    "local_model_path = \"eff_mann_v1.h5\"   # path where you saved the model\n",
    "\n",
    "# check that the file exists before uploading\n",
    "if not os.path.exists(local_model_path):\n",
    "    raise FileNotFoundError(f\"Model file not found: {local_model_path}\")\n",
    "\n",
    "print(f\"Found model file: {local_model_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. S3 bucket and key info\n",
    "# -----------------------------\n",
    "bucket_name = \"ai-bmi-predictor\"  # your S3 bucket name\n",
    "\n",
    "# S3 key (path inside the bucket)\n",
    "s3_key = \"trained-models/efficientnet-models/eff_mann_version1.h5\"\n",
    "\n",
    "print(f\"Model will be uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Create S3 client\n",
    "# -----------------------------\n",
    "# This assumes your AWS credentials are configured (env vars, ~/.aws/credentials, or IAM role)\n",
    "s3_client = boto3.client(\"s3\")    # create S3 client\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Upload the file\n",
    "# -----------------------------\n",
    "print(\"Uploading model to S3 ...\")\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=local_model_path,    # local file path\n",
    "    Bucket=bucket_name,           # target S3 bucket\n",
    "    Key=s3_key                    # target S3 key (including folders and filename)\n",
    ")\n",
    "\n",
    "print(\"Upload completed successfully!\")\n",
    "print(f\"File is now at: s3://{bucket_name}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6d84a-e81b-42db-8f9b-0f8028f51162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
