{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf02b17-8e70-4360-a7a2-064ff4eb779f",
   "metadata": {},
   "source": [
    "here we remove last classificaation layer to get the feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb93344-c57f-4ce6-9429-dd887225dac2",
   "metadata": {},
   "source": [
    "STEP 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91523481-0837-49ad-9e40-eb0a2c0ca10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Imports\n",
    "\n",
    "import os          # work with folders and file paths\n",
    "import pickle      # save and load feature dictionaries\n",
    "import shutil      # remove unwanted folders\n",
    "\n",
    "import torch       # deep learning framework\n",
    "from PIL import Image  # load images\n",
    "\n",
    "import torchvision.models as models       # load MNASNet\n",
    "import torchvision.transforms as T        # image preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cbd90-58ab-474b-87d2-ee14d8f48e55",
   "metadata": {},
   "source": [
    "STEP 2 — Load MNASNet 1.3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66dccd-4a11-4133-8d0f-53fe7354ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Load MNASNet 1.3 model (PyTorch)\n",
    "\n",
    "mnas_model = models.mnasnet1_3(pretrained=True)  # load pretrained CNN\n",
    "mnas_model.classifier = torch.nn.Identity()      # remove classifier to get feature vector\n",
    "mnas_model.eval()                                # set to evaluation mode\n",
    "\n",
    "# build image preprocessing pipeline (same expected ImageNet normalization)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),                   # resize image\n",
    "    T.CenterCrop(224),               # crop center region\n",
    "    T.ToTensor(),                    # convert image → tensor\n",
    "    T.Normalize(                      # apply ImageNet mean & std\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4587193-1cbd-43cc-8504-939b21d77ac7",
   "metadata": {},
   "source": [
    "STEP 3 — Show Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584086dc-23da-4fe5-bb34-5cc058f257a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Show MNASNet model summary\n",
    "\n",
    "print(mnas_model)  # print architecture definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50cc4f8-5111-4be0-82a1-2de8800a08af",
   "metadata": {},
   "source": [
    "STEP 4 — Prepare Feature Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78291d0f-41b0-43f4-a6e4-27c7bb4d00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Prepare feature storage and image directory\n",
    "\n",
    "features = {}                         # dictionary to store feature vectors\n",
    "directory = r\"test - front masked images - side\"     # your image folder path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1e667-3b07-48a4-9b85-673e1d28b47c",
   "metadata": {},
   "source": [
    "STEP 5 — Remove .ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5b20b-0c2c-4fdc-8a58-9aeb16e4876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Remove notebook checkpoint folders\n",
    "\n",
    "folder = \"test - front masked images - side\"\n",
    "\n",
    "for item in os.listdir(folder):           # loop through folder items\n",
    "    path = os.path.join(folder, item)\n",
    "    if item == \".ipynb_checkpoints\" and os.path.isdir(path):\n",
    "        shutil.rmtree(path)              # delete checkpoint folder\n",
    "        print(\"Removed:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92d6b1-4b20-41b7-bdaa-e9a938a4a690",
   "metadata": {},
   "source": [
    "STEP 6 — Extract Features Using MNASNet 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3c824-9dae-45bb-be60-6b8c1e88fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Extract features using MNASNet 1.3\n",
    "\n",
    "valid_extensions = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\"}  # allowed image types\n",
    "\n",
    "file_list = os.listdir(directory)              # list all files\n",
    "print(f\"Found {len(file_list)} files in directory: {directory}\")\n",
    "\n",
    "for idx, image_name in enumerate(file_list, start=1):\n",
    "\n",
    "    image_path = os.path.join(directory, image_name)\n",
    "\n",
    "    # skip non-files\n",
    "    if not os.path.isfile(image_path):\n",
    "        continue\n",
    "\n",
    "    # check extension\n",
    "    ext = os.path.splitext(image_name)[1].lower()\n",
    "    if ext not in valid_extensions:\n",
    "        continue\n",
    "\n",
    "    # load image with PIL\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # apply MNASNet preprocess\n",
    "    img_tensor = preprocess(img).unsqueeze(0)   # add batch dimension\n",
    "\n",
    "    # extract features from CNN\n",
    "    with torch.no_grad():                      # disable gradients\n",
    "        outputs = mnas_model(img_tensor)       # forward pass\n",
    "        feature_vector = outputs.cpu().numpy() # convert tensor → numpy\n",
    "\n",
    "    # store feature\n",
    "    features[image_path] = feature_vector\n",
    "\n",
    "    print(f\"Processed {idx}/{len(file_list)}: {image_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15271fc2-ef10-49bb-8189-c9d96896e601",
   "metadata": {},
   "source": [
    "STEP 7 — Rename Keys → Filenames Only + Save Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ba9da-84c6-468d-a3d1-2082a23ce713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 - Rename dictionary keys and save pickle file\n",
    "\n",
    "features_renamed = {}                            # new dict for filename-based keys\n",
    "\n",
    "for full_path, vec in features.items():\n",
    "    filename = os.path.basename(full_path)        # extract filename only\n",
    "    features_renamed[filename] = vec              # store under simple name\n",
    "\n",
    "features = features_renamed                       # replace dictionary\n",
    "\n",
    "# print sample keys\n",
    "print(\"Sample keys:\")\n",
    "for i, k in enumerate(features.keys()):\n",
    "    print(k)\n",
    "    if i == 4:                                    # show first 5\n",
    "        break\n",
    "\n",
    "pickle_path = \"mnasnet1_3_front_masked_features-testA.pkl\"  # output file name\n",
    "\n",
    "with open(pickle_path, \"wb\") as f:\n",
    "    pickle.dump(features, f)                      # save features\n",
    "\n",
    "print(f\"Saved {len(features)} feature vectors to {pickle_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f247a19-fc38-46b7-ac8f-ceddc7995cc0",
   "metadata": {},
   "source": [
    "STEP 8 — Compare Folder Files vs Feature Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef7868-f5a3-42e4-a47c-2faecf333f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 - Compare actual folder image files vs keys in dictionary\n",
    "\n",
    "image_files_in_dir = []                               # list for actual files\n",
    "\n",
    "for name in os.listdir(directory):\n",
    "    full_path = os.path.join(directory, name)\n",
    "    ext = os.path.splitext(name)[1].lower()\n",
    "\n",
    "    if os.path.isfile(full_path) and ext in valid_extensions:\n",
    "        image_files_in_dir.append(name)\n",
    "\n",
    "files_set = set(image_files_in_dir)\n",
    "keys_set = set(features.keys())\n",
    "\n",
    "files_not_in_dict = files_set - keys_set\n",
    "keys_not_in_folder = keys_set - files_set\n",
    "\n",
    "print(f\"Number of image files: {len(files_set)}\")\n",
    "print(f\"Number of features saved: {len(keys_set)}\\n\")\n",
    "\n",
    "if not files_not_in_dict and not keys_not_in_folder:\n",
    "    print(\"✅ All images match dictionary keys.\")\n",
    "else:\n",
    "    print(\"⚠ Mismatches found:\\n\")\n",
    "\n",
    "    if files_not_in_dict:\n",
    "        print(f\"Files in folder but not in dictionary ({len(files_not_in_dict)}):\")\n",
    "        for i, name in enumerate(sorted(files_not_in_dict)):\n",
    "            print(\"  -\", name)\n",
    "            if i == 9:\n",
    "                break\n",
    "        print()\n",
    "\n",
    "    if keys_not_in_folder:\n",
    "        print(f\"Keys in dictionary without matching files ({len(keys_not_in_folder)}):\")\n",
    "        for i, name in enumerate(sorted(keys_not_in_folder)):\n",
    "            print(\"  -\", name)\n",
    "            if i == 9:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eaf2fe-fd8b-4012-ae07-9887698cc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2b0f1-9a73-42bd-b949-ae6c3bb04f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
