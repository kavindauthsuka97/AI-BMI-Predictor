{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a089bb-ebd7-4d32-b8ce-89424733811e",
   "metadata": {},
   "source": [
    "1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca32a18-ee45-42b9-848f-47c53613db38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5ae8fe5bbdf611a1e8d06e66e849bdf</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>-0.133776</td>\n",
       "      <td>0.881202</td>\n",
       "      <td>0.214236</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>-0.180302</td>\n",
       "      <td>-0.100713</td>\n",
       "      <td>-0.117249</td>\n",
       "      <td>...</td>\n",
       "      <td>106.774690</td>\n",
       "      <td>83.279744</td>\n",
       "      <td>39.922305</td>\n",
       "      <td>70.005128</td>\n",
       "      <td>55.945992</td>\n",
       "      <td>98.250390</td>\n",
       "      <td>20.187082</td>\n",
       "      <td>male</td>\n",
       "      <td>180.00</td>\n",
       "      <td>94.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605a5fd09058c48156b0ef518b63b2de</td>\n",
       "      <td>0.092031</td>\n",
       "      <td>-0.066016</td>\n",
       "      <td>-0.145132</td>\n",
       "      <td>0.687441</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>-0.075221</td>\n",
       "      <td>-0.093846</td>\n",
       "      <td>-0.035840</td>\n",
       "      <td>0.033903</td>\n",
       "      <td>...</td>\n",
       "      <td>102.481633</td>\n",
       "      <td>84.876529</td>\n",
       "      <td>39.974203</td>\n",
       "      <td>73.591637</td>\n",
       "      <td>55.397032</td>\n",
       "      <td>88.003618</td>\n",
       "      <td>17.715785</td>\n",
       "      <td>male</td>\n",
       "      <td>188.90</td>\n",
       "      <td>86.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909c9277309e13ee014e347603aba620</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>-0.051366</td>\n",
       "      <td>-0.148253</td>\n",
       "      <td>0.675916</td>\n",
       "      <td>0.209973</td>\n",
       "      <td>-0.073485</td>\n",
       "      <td>-0.072783</td>\n",
       "      <td>-0.059395</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>...</td>\n",
       "      <td>99.342301</td>\n",
       "      <td>82.275874</td>\n",
       "      <td>36.059983</td>\n",
       "      <td>66.440526</td>\n",
       "      <td>53.742692</td>\n",
       "      <td>82.100598</td>\n",
       "      <td>17.086464</td>\n",
       "      <td>male</td>\n",
       "      <td>179.70</td>\n",
       "      <td>73.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bef6a68bc8dd475c124f6de2413385d3</td>\n",
       "      <td>-0.018792</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>-0.148091</td>\n",
       "      <td>0.464433</td>\n",
       "      <td>0.242849</td>\n",
       "      <td>-0.106556</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.083478</td>\n",
       "      <td>0.096048</td>\n",
       "      <td>...</td>\n",
       "      <td>101.770144</td>\n",
       "      <td>76.081842</td>\n",
       "      <td>34.071748</td>\n",
       "      <td>62.218026</td>\n",
       "      <td>52.396573</td>\n",
       "      <td>83.999124</td>\n",
       "      <td>16.299751</td>\n",
       "      <td>female</td>\n",
       "      <td>166.95</td>\n",
       "      <td>69.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6d7ed4bc4a17546447efed0ca6e2ff11</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>-0.153379</td>\n",
       "      <td>0.635377</td>\n",
       "      <td>0.285274</td>\n",
       "      <td>-0.056372</td>\n",
       "      <td>-0.139008</td>\n",
       "      <td>-0.120711</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>...</td>\n",
       "      <td>94.707063</td>\n",
       "      <td>81.328892</td>\n",
       "      <td>36.834735</td>\n",
       "      <td>64.426273</td>\n",
       "      <td>49.895157</td>\n",
       "      <td>86.020117</td>\n",
       "      <td>16.531431</td>\n",
       "      <td>male</td>\n",
       "      <td>173.20</td>\n",
       "      <td>65.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           photo_id        f1        f2        f3        f4  \\\n",
       "0  e5ae8fe5bbdf611a1e8d06e66e849bdf  0.073159  0.085775 -0.133776  0.881202   \n",
       "1  605a5fd09058c48156b0ef518b63b2de  0.092031 -0.066016 -0.145132  0.687441   \n",
       "2  909c9277309e13ee014e347603aba620  0.057046 -0.051366 -0.148253  0.675916   \n",
       "3  bef6a68bc8dd475c124f6de2413385d3 -0.018792  0.016435 -0.148091  0.464433   \n",
       "4  6d7ed4bc4a17546447efed0ca6e2ff11  0.084419  0.065945 -0.153379  0.635377   \n",
       "\n",
       "         f5        f6        f7        f8        f9  ...         hip  \\\n",
       "0  0.214236  0.016104 -0.180302 -0.100713 -0.117249  ...  106.774690   \n",
       "1  0.186508 -0.075221 -0.093846 -0.035840  0.033903  ...  102.481633   \n",
       "2  0.209973 -0.073485 -0.072783 -0.059395  0.008370  ...   99.342301   \n",
       "3  0.242849 -0.106556  0.001489 -0.083478  0.096048  ...  101.770144   \n",
       "4  0.285274 -0.056372 -0.139008 -0.120711 -0.002466  ...   94.707063   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh      waist  \\\n",
       "0   83.279744         39.922305           70.005128  55.945992  98.250390   \n",
       "1   84.876529         39.974203           73.591637  55.397032  88.003618   \n",
       "2   82.275874         36.059983           66.440526  53.742692  82.100598   \n",
       "3   76.081842         34.071748           62.218026  52.396573  83.999124   \n",
       "4   81.328892         36.834735           64.426273  49.895157  86.020117   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  20.187082    male     180.00      94.60  \n",
       "1  17.715785    male     188.90      86.75  \n",
       "2  17.086464    male     179.70      73.85  \n",
       "3  16.299751  female     166.95      69.05  \n",
       "4  16.531431    male     173.20      65.55  \n",
       "\n",
       "[5 rows x 5138 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "bucket = \"ai-bmi-predictor\"\n",
    "key = \"test-data/eff_testingA.csv\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "data = pd.read_csv(obj[\"Body\"])\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca77b-fb2a-4f3c-9897-29c1e84fcde0",
   "metadata": {},
   "source": [
    "2. data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9d28a-110f-4e9d-9936-f18919462e0e",
   "metadata": {},
   "source": [
    "2.1. categorical encoding for 'gender' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a49b37-abd8-4b37-8802-2c181918c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # import pandas for data handling\n",
    "\n",
    "data['gender'] = data['gender'].astype('category')  # convert 'gender' values to categorical type\n",
    "data['gender'] = data['gender'].cat.codes           # replace 'gender' with its numeric category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73940a3b-8471-40f4-93c3-d720861de107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: gender, dtype: int8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9787987-59e1-42a5-be40-d041b7ec47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['height_cm'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054494a2-7444-472e-837b-ab49865ccca7",
   "metadata": {},
   "source": [
    "2.2. define weight frequencies for class imbalance issue for weight_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e3f129-bcd9-4eb8-b9c6-045dc0d70955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd                     # import pandas for data handling\\nimport numpy as np                      # import numpy to help with safe division\\n\\n# Assume \\'data\\' is your DataFrame and already loaded\\n#print(\"Preview of data:\\n\", data.head())  # print first few rows to check data\\nprint(\"\\nTotal samples in dataset:\", len(data))  # print total number of rows\\n\\n# -----------------------------\\n# 1. Create boolean masks for the three weight_kg classes\\n# -----------------------------\\nclass_1_mask = data[\\'weight_kg\\'] < 60                      # True where weight_kg is less than 60\\nclass_2_mask = data[\\'weight_kg\\'] > 100                     # True where weight_kg is greater than 100\\nclass_3_mask = (data[\\'weight_kg\\'] >= 60) & (data[\\'weight_kg\\'] <= 100)  # True where weight is between 60 and 100\\n\\n# -----------------------------\\n# 2. Calculate class frequencies (counts)\\n# -----------------------------\\nfreq_class_1 = class_1_mask.sum()          # number of samples with weight_kg < 60\\nfreq_class_2 = class_2_mask.sum()          # number of samples with weight_kg > 100\\nfreq_class_3 = class_3_mask.sum()          # number of samples with 60 <= weight_kg <= 100\\n\\nprint(\"\\nClass frequencies:\")              # header for clarity\\nprint(\"Class 1 (weight_kg < 60):\", freq_class_1)   # print frequency of class 1\\nprint(\"Class 2 (weight_kg > 100):\", freq_class_2)  # print frequency of class 2\\nprint(\"Class 3 (60 <= weight_kg <= 100):\", freq_class_3)  # print frequency of class 3\\n\\n# -----------------------------\\n# 3. Number of classes according to the strategy\\n# -----------------------------\\nnum_classes = 3                             # we defined three classes by the rules above\\nprint(\"\\nNumber of classes:\", num_classes)  # print number of classes\\n\\n# -----------------------------\\n# 4. Compute inverse-frequency weights for each class\\n#    Formula: w = total_samples / (num_classes * class_frequency)\\n# -----------------------------\\ntotal_samples = len(data)                   # total number of rows in the dataset\\n\\ndef safe_weight(class_freq):                # helper function to avoid division by zero\\n    if class_freq == 0:                     # check if a class has zero samples\\n        return np.nan                       # return NaN if no samples exist for that class\\n    return total_samples / (num_classes * class_freq)  # apply weighting formula\\n\\nweight_class_1 = safe_weight(freq_class_1)  # compute weight for class 1\\nweight_class_2 = safe_weight(freq_class_2)  # compute weight for class 2\\nweight_class_3 = safe_weight(freq_class_3)  # compute weight for class 3\\n\\nprint(\"\\nClass weights (inverse frequency):\")          # header for class weights\\nprint(\"Weight for Class 1 (weight_kg < 60):\", weight_class_1)   # print weight of class 1\\nprint(\"Weight for Class 2 (weight_kg > 100):\", weight_class_2)  # print weight of class 2\\nprint(\"Weight for Class 3 (60 <= weight_kg <= 100):\", weight_class_3)  # print weight of class 3\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd                     # import pandas for data handling\n",
    "import numpy as np                      # import numpy to help with safe division\n",
    "\n",
    "# Assume 'data' is your DataFrame and already loaded\n",
    "#print(\"Preview of data:\\n\", data.head())  # print first few rows to check data\n",
    "print(\"\\nTotal samples in dataset:\", len(data))  # print total number of rows\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Create boolean masks for the three weight_kg classes\n",
    "# -----------------------------\n",
    "class_1_mask = data['weight_kg'] < 60                      # True where weight_kg is less than 60\n",
    "class_2_mask = data['weight_kg'] > 100                     # True where weight_kg is greater than 100\n",
    "class_3_mask = (data['weight_kg'] >= 60) & (data['weight_kg'] <= 100)  # True where weight is between 60 and 100\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Calculate class frequencies (counts)\n",
    "# -----------------------------\n",
    "freq_class_1 = class_1_mask.sum()          # number of samples with weight_kg < 60\n",
    "freq_class_2 = class_2_mask.sum()          # number of samples with weight_kg > 100\n",
    "freq_class_3 = class_3_mask.sum()          # number of samples with 60 <= weight_kg <= 100\n",
    "\n",
    "print(\"\\nClass frequencies:\")              # header for clarity\n",
    "print(\"Class 1 (weight_kg < 60):\", freq_class_1)   # print frequency of class 1\n",
    "print(\"Class 2 (weight_kg > 100):\", freq_class_2)  # print frequency of class 2\n",
    "print(\"Class 3 (60 <= weight_kg <= 100):\", freq_class_3)  # print frequency of class 3\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Number of classes according to the strategy\n",
    "# -----------------------------\n",
    "num_classes = 3                             # we defined three classes by the rules above\n",
    "print(\"\\nNumber of classes:\", num_classes)  # print number of classes\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compute inverse-frequency weights for each class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------\n",
    "total_samples = len(data)                   # total number of rows in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                # helper function to avoid division by zero\n",
    "    if class_freq == 0:                     # check if a class has zero samples\n",
    "        return np.nan                       # return NaN if no samples exist for that class\n",
    "    return total_samples / (num_classes * class_freq)  # apply weighting formula\n",
    "\n",
    "weight_class_1 = safe_weight(freq_class_1)  # compute weight for class 1\n",
    "weight_class_2 = safe_weight(freq_class_2)  # compute weight for class 2\n",
    "weight_class_3 = safe_weight(freq_class_3)  # compute weight for class 3\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency):\")          # header for class weights\n",
    "print(\"Weight for Class 1 (weight_kg < 60):\", weight_class_1)   # print weight of class 1\n",
    "print(\"Weight for Class 2 (weight_kg > 100):\", weight_class_2)  # print weight of class 2\n",
    "print(\"Weight for Class 3 (60 <= weight_kg <= 100):\", weight_class_3)  # print weight of class 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6008f8b-e977-4bef-ae79-33879ec53c33",
   "metadata": {},
   "source": [
    "2.3. define weight frequencies for class imbalance issue for gender feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f089c02-aff3-4c91-b679-be4b012a9e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np                                      # import numpy for numeric utilities (like NaN)\\n\\nprint(\"Preview of gender column:\\n\", data[\\'gender\\'].head())  # show first few gender values to inspect\\n\\n# -----------------------------------\\n# 1. Calculate class frequencies for gender\\n# -----------------------------------\\ngender_counts = data[\\'gender\\'].value_counts()           # count how many samples belong to each gender class\\n\\nprint(\"\\nClass frequencies for gender:\")                # header for class frequency output\\nfor gender_class, freq in gender_counts.items():        # loop over each gender class and its frequency\\n    print(f\"Class {gender_class}: {freq}\")              # print the class label and its frequency\\n\\n# -----------------------------------\\n# 2. Number of gender classes\\n# -----------------------------------\\nnum_gender_classes = len(gender_counts)                 # compute how many distinct gender classes we have\\nprint(\"\\nNumber of gender classes:\", num_gender_classes)  # print number of gender classes\\n\\n# -----------------------------------\\n# 3. Compute inverse-frequency weights for each gender class\\n#    Formula: w = total_samples / (num_classes * class_frequency)\\n# -----------------------------------\\ntotal_samples = len(data)                               # total number of samples in the dataset\\n\\ndef safe_weight(class_freq):                            # define helper function to compute class weight safely\\n    if class_freq == 0:                                 # check for zero frequency to avoid division by zero\\n        return np.nan                                   # return NaN if a class somehow has zero samples\\n    return total_samples / (num_gender_classes * class_freq)  # apply the inverse-frequency weight formula\\n\\ngender_weights = {}                                     # create an empty dictionary to store weights per class\\nfor gender_class, freq in gender_counts.items():        # loop through each gender class and its frequency\\n    gender_weights[gender_class] = safe_weight(freq)    # compute and store the weight for this gender class\\n\\nprint(\"\\nClass weights (inverse frequency) for gender:\")  # header for weight output\\nfor gender_class, weight in gender_weights.items():     # loop over each class and its weight\\n    print(f\"Weight for class {gender_class}: {weight}\") # print the computed weight for this gender class\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np                                      # import numpy for numeric utilities (like NaN)\n",
    "\n",
    "print(\"Preview of gender column:\\n\", data['gender'].head())  # show first few gender values to inspect\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Calculate class frequencies for gender\n",
    "# -----------------------------------\n",
    "gender_counts = data['gender'].value_counts()           # count how many samples belong to each gender class\n",
    "\n",
    "print(\"\\nClass frequencies for gender:\")                # header for class frequency output\n",
    "for gender_class, freq in gender_counts.items():        # loop over each gender class and its frequency\n",
    "    print(f\"Class {gender_class}: {freq}\")              # print the class label and its frequency\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Number of gender classes\n",
    "# -----------------------------------\n",
    "num_gender_classes = len(gender_counts)                 # compute how many distinct gender classes we have\n",
    "print(\"\\nNumber of gender classes:\", num_gender_classes)  # print number of gender classes\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Compute inverse-frequency weights for each gender class\n",
    "#    Formula: w = total_samples / (num_classes * class_frequency)\n",
    "# -----------------------------------\n",
    "total_samples = len(data)                               # total number of samples in the dataset\n",
    "\n",
    "def safe_weight(class_freq):                            # define helper function to compute class weight safely\n",
    "    if class_freq == 0:                                 # check for zero frequency to avoid division by zero\n",
    "        return np.nan                                   # return NaN if a class somehow has zero samples\n",
    "    return total_samples / (num_gender_classes * class_freq)  # apply the inverse-frequency weight formula\n",
    "\n",
    "gender_weights = {}                                     # create an empty dictionary to store weights per class\n",
    "for gender_class, freq in gender_counts.items():        # loop through each gender class and its frequency\n",
    "    gender_weights[gender_class] = safe_weight(freq)    # compute and store the weight for this gender class\n",
    "\n",
    "print(\"\\nClass weights (inverse frequency) for gender:\")  # header for weight output\n",
    "for gender_class, weight in gender_weights.items():     # loop over each class and its weight\n",
    "    print(f\"Weight for class {gender_class}: {weight}\") # print the computed weight for this gender class\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981d197-ad20-473e-a854-ffca369ef51e",
   "metadata": {},
   "source": [
    "2.4. weight frequencies for weight classes and gender classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc2d86a-9f9f-4ab2-8749-8dc2bd7644a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np   # import numpy for numeric operations\\n\\n# -------------------------------------------------\\n# 1. Store the already-computed weights for weight classes\\n#    (use the variables you created when handling weight_kg)\\n# -------------------------------------------------\\nweight_class_weights = {                          # dictionary to hold weight-class weights\\n    \\'weight_<60\\':  weight_class_1,                # weight for class: weight_kg < 60\\n    \\'weight_>100\\': weight_class_2,                # weight for class: weight_kg > 100\\n    \\'weight_60_100\\': weight_class_3               # weight for class: 60 <= weight_kg <= 100\\n}\\n\\nprint(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights to check\\n\\n# gender_weights dict is assumed from previous step, e.g. {0: w0, 1: w1}\\nprint(\"Gender-class weights:\", gender_weights)        # print gender-class weights to check\\n\\n# -------------------------------------------------\\n# 2. Multiply each gender class with each weight class\\n#    wi = w_weight * w_gender\\n# -------------------------------------------------\\ncombined_weights = {}                                # dictionary to store combined class weights\\n\\nprint(\"\\nCombined weights for each (weight_class, gender_class):\")  # header\\nfor w_label, w_w in weight_class_weights.items():    # loop over weight classes\\n    for g_label, w_g in gender_weights.items():      # loop over gender classes\\n        wi = w_w * w_g                               # multiply weight and gender class weights\\n        combined_weights[(w_label, g_label)] = wi    # store in dictionary\\n        print(f\"{w_label} & gender {g_label}: {wi}\") # print each combination'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np   # import numpy for numeric operations\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Store the already-computed weights for weight classes\n",
    "#    (use the variables you created when handling weight_kg)\n",
    "# -------------------------------------------------\n",
    "weight_class_weights = {                          # dictionary to hold weight-class weights\n",
    "    'weight_<60':  weight_class_1,                # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,                # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3               # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights to check\n",
    "\n",
    "# gender_weights dict is assumed from previous step, e.g. {0: w0, 1: w1}\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights to check\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Multiply each gender class with each weight class\n",
    "#    wi = w_weight * w_gender\n",
    "# -------------------------------------------------\n",
    "combined_weights = {}                                # dictionary to store combined class weights\n",
    "\n",
    "print(\"\\nCombined weights for each (weight_class, gender_class):\")  # header\n",
    "for w_label, w_w in weight_class_weights.items():    # loop over weight classes\n",
    "    for g_label, w_g in gender_weights.items():      # loop over gender classes\n",
    "        wi = w_w * w_g                               # multiply weight and gender class weights\n",
    "        combined_weights[(w_label, g_label)] = wi    # store in dictionary\n",
    "        print(f\"{w_label} & gender {g_label}: {wi}\") # print each combination'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487c312-8683-4912-9b37-7e99383b1ed4",
   "metadata": {},
   "source": [
    "2.5. create a dictionary for weights and row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806866b5-519d-48b6-be00-77c2fd191d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Check current columns in the DataFrame\\nprint(\"Columns before adding index column:\\n\", data.columns)\\n\\n# Add a new column named \\'index\\' with values from 0 to number_of_rows-1\\ndata[\\'index\\'] = range(len(data))\\n\\n# Move \\'index\\' to the front (optional, just for nicer viewing)\\ncols = [\\'index\\'] + [c for c in data.columns if c != \\'index\\']  # build new column order\\ndata = data[cols]                                            # reorder columns\\n\\n# Show first few rows to verify the new indexing column\\n#print(\"\\nDataFrame after adding \\'index\\' column:\\n\", data.head())\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Check current columns in the DataFrame\n",
    "print(\"Columns before adding index column:\\n\", data.columns)\n",
    "\n",
    "# Add a new column named 'index' with values from 0 to number_of_rows-1\n",
    "data['index'] = range(len(data))\n",
    "\n",
    "# Move 'index' to the front (optional, just for nicer viewing)\n",
    "cols = ['index'] + [c for c in data.columns if c != 'index']  # build new column order\n",
    "data = data[cols]                                            # reorder columns\n",
    "\n",
    "# Show first few rows to verify the new indexing column\n",
    "#print(\"\\nDataFrame after adding 'index' column:\\n\", data.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41807157-b19f-4328-9e9a-faf126794665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np               # import numpy for numeric operations\\nimport pickle                    # import pickle to save Python objects\\n\\n# -------------------------------------------------\\n# 0. We assume these already exist:\\n#    - weight_class_1, weight_class_2, weight_class_3\\n#    - gender_weights   (dict: {gender_class: weight})\\n# -------------------------------------------------\\n\\n# create a dictionary of weight-class weights (same as before)\\nweight_class_weights = {         # dictionary mapping weight class labels to their weights\\n    \\'weight_<60\\':  weight_class_1,      # weight for class: weight_kg < 60\\n    \\'weight_>100\\': weight_class_2,      # weight for class: weight_kg > 100\\n    \\'weight_60_100\\': weight_class_3     # weight for class: 60 <= weight_kg <= 100\\n}\\n\\nprint(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights\\nprint(\"Gender-class weights:\", gender_weights)        # print gender-class weights\\n\\n# -------------------------------------------------\\n# 1. Helper function to get the weight class label for a given weight_kg\\n# -------------------------------------------------\\ndef get_weight_class(w):         # define a function that receives a single weight value\\n    if w < 60:                   # check if weight is less than 60\\n        return \\'weight_<60\\'      # return label for class 1\\n    elif w > 100:                # check if weight is greater than 100\\n        return \\'weight_>100\\'     # return label for class 2\\n    else:                        # otherwise weight is between 60 and 100 (inclusive)\\n        return \\'weight_60_100\\'   # return label for class 3\\n\\n# -------------------------------------------------\\n# 2. Build dictionary: keys = index values, values = combined weights\\n# -------------------------------------------------\\nfinal_weights = {}               # create empty dictionary to store final weights\\n\\nprint(\"\\nBuilding final_weights dictionary...\")  # message to track progress\\n\\nfor _, row in data.iterrows():   # loop over each row of the DataFrame\\n    idx_val = row[\\'index\\']       # get the value from the \\'index\\' column for this row\\n    gender_val = row[\\'gender\\']   # get the gender class value for this row\\n    weight_val = row[\\'weight_kg\\']# get the weight_kg value for this row\\n\\n    w_class = get_weight_class(weight_val)        # determine weight class label from weight_kg\\n    w_weight = weight_class_weights[w_class]      # look up the weight-class weight\\n    w_gender = gender_weights[gender_val]         # look up the gender-class weight\\n\\n    combined_w = w_weight * w_gender             # multiply to get combined weight w_i\\n    final_weights[idx_val] = combined_w          # store combined weight in dictionary with key=index\\n\\nprint(\"Number of entries in final_weights:\", len(final_weights))  # print number of entries\\nprint(\"First 5 items in final_weights:\", list(final_weights.items())[:5])  # show first few items\\n\\n# -------------------------------------------------\\n# 3. Check index 0: gender, weight_kg, and combined weight\\n# -------------------------------------------------\\nprint(\"\\nChecking entry with index 0...\")        # message to show what we\\'re doing\\n\\nrow0 = data.loc[data[\\'index\\'] == 0].iloc[0]      # select the row where \\'index\\' column equals 0\\n\\ngender0 = row0[\\'gender\\']                         # get gender value for index 0\\nweight0 = row0[\\'weight_kg\\']                      # get weight_kg value for index 0\\nw_class0 = get_weight_class(weight0)             # get weight class label for index 0\\n\\nw_weight0 = weight_class_weights[w_class0]       # get weight-class weight for index 0\\nw_gender0 = gender_weights[gender0]              # get gender-class weight for index 0\\ncombined0_calc = w_weight0 * w_gender0           # calculate combined weight for index 0\\n\\nprint(\"Row 0 -> gender:\", gender0)               # print gender class for index 0\\nprint(\"Row 0 -> weight_kg:\", weight0)            # print weight_kg for index 0\\nprint(\"Row 0 -> weight class:\", w_class0)        # print weight class label for index 0\\nprint(\"w_weight for row 0:\", w_weight0)          # print weight-class weight for index 0\\nprint(\"w_gender for row 0:\", w_gender0)          # print gender-class weight for index 0\\nprint(\"Combined weight (calculated):\", combined0_calc)        # print calculated combined weight\\nprint(\"Combined weight from final_weights[0]:\", final_weights[0])  # print value from dictionary\\n\\n# -------------------------------------------------\\n# 4. Save final_weights dictionary as a pickle file\\n# -------------------------------------------------\\nprint(\"\\nSaving final_weights dictionary as pickle file...\")   # message to track saving step\\n\\nwith open(\\'final_weights.pkl\\', \\'wb\\') as f:       # open a file named \\'final_weights.pkl\\' in binary write mode\\n    pickle.dump(final_weights, f)                # write dictionary to the file using pickle\\n\\nprint(\"Dictionary saved to \\'final_weights.pkl\\'.\")# confirmation message\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np               # import numpy for numeric operations\n",
    "import pickle                    # import pickle to save Python objects\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. We assume these already exist:\n",
    "#    - weight_class_1, weight_class_2, weight_class_3\n",
    "#    - gender_weights   (dict: {gender_class: weight})\n",
    "# -------------------------------------------------\n",
    "\n",
    "# create a dictionary of weight-class weights (same as before)\n",
    "weight_class_weights = {         # dictionary mapping weight class labels to their weights\n",
    "    'weight_<60':  weight_class_1,      # weight for class: weight_kg < 60\n",
    "    'weight_>100': weight_class_2,      # weight for class: weight_kg > 100\n",
    "    'weight_60_100': weight_class_3     # weight for class: 60 <= weight_kg <= 100\n",
    "}\n",
    "\n",
    "print(\"Weight-class weights:\", weight_class_weights)  # print weight-class weights\n",
    "print(\"Gender-class weights:\", gender_weights)        # print gender-class weights\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Helper function to get the weight class label for a given weight_kg\n",
    "# -------------------------------------------------\n",
    "def get_weight_class(w):         # define a function that receives a single weight value\n",
    "    if w < 60:                   # check if weight is less than 60\n",
    "        return 'weight_<60'      # return label for class 1\n",
    "    elif w > 100:                # check if weight is greater than 100\n",
    "        return 'weight_>100'     # return label for class 2\n",
    "    else:                        # otherwise weight is between 60 and 100 (inclusive)\n",
    "        return 'weight_60_100'   # return label for class 3\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Build dictionary: keys = index values, values = combined weights\n",
    "# -------------------------------------------------\n",
    "final_weights = {}               # create empty dictionary to store final weights\n",
    "\n",
    "print(\"\\nBuilding final_weights dictionary...\")  # message to track progress\n",
    "\n",
    "for _, row in data.iterrows():   # loop over each row of the DataFrame\n",
    "    idx_val = row['index']       # get the value from the 'index' column for this row\n",
    "    gender_val = row['gender']   # get the gender class value for this row\n",
    "    weight_val = row['weight_kg']# get the weight_kg value for this row\n",
    "\n",
    "    w_class = get_weight_class(weight_val)        # determine weight class label from weight_kg\n",
    "    w_weight = weight_class_weights[w_class]      # look up the weight-class weight\n",
    "    w_gender = gender_weights[gender_val]         # look up the gender-class weight\n",
    "\n",
    "    combined_w = w_weight * w_gender             # multiply to get combined weight w_i\n",
    "    final_weights[idx_val] = combined_w          # store combined weight in dictionary with key=index\n",
    "\n",
    "print(\"Number of entries in final_weights:\", len(final_weights))  # print number of entries\n",
    "print(\"First 5 items in final_weights:\", list(final_weights.items())[:5])  # show first few items\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Check index 0: gender, weight_kg, and combined weight\n",
    "# -------------------------------------------------\n",
    "print(\"\\nChecking entry with index 0...\")        # message to show what we're doing\n",
    "\n",
    "row0 = data.loc[data['index'] == 0].iloc[0]      # select the row where 'index' column equals 0\n",
    "\n",
    "gender0 = row0['gender']                         # get gender value for index 0\n",
    "weight0 = row0['weight_kg']                      # get weight_kg value for index 0\n",
    "w_class0 = get_weight_class(weight0)             # get weight class label for index 0\n",
    "\n",
    "w_weight0 = weight_class_weights[w_class0]       # get weight-class weight for index 0\n",
    "w_gender0 = gender_weights[gender0]              # get gender-class weight for index 0\n",
    "combined0_calc = w_weight0 * w_gender0           # calculate combined weight for index 0\n",
    "\n",
    "print(\"Row 0 -> gender:\", gender0)               # print gender class for index 0\n",
    "print(\"Row 0 -> weight_kg:\", weight0)            # print weight_kg for index 0\n",
    "print(\"Row 0 -> weight class:\", w_class0)        # print weight class label for index 0\n",
    "print(\"w_weight for row 0:\", w_weight0)          # print weight-class weight for index 0\n",
    "print(\"w_gender for row 0:\", w_gender0)          # print gender-class weight for index 0\n",
    "print(\"Combined weight (calculated):\", combined0_calc)        # print calculated combined weight\n",
    "print(\"Combined weight from final_weights[0]:\", final_weights[0])  # print value from dictionary\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Save final_weights dictionary as a pickle file\n",
    "# -------------------------------------------------\n",
    "print(\"\\nSaving final_weights dictionary as pickle file...\")   # message to track saving step\n",
    "\n",
    "with open('final_weights.pkl', 'wb') as f:       # open a file named 'final_weights.pkl' in binary write mode\n",
    "    pickle.dump(final_weights, f)                # write dictionary to the file using pickle\n",
    "\n",
    "print(\"Dictionary saved to 'final_weights.pkl'.\")# confirmation message\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f74299-3350-46fa-a49f-988b733ca1b8",
   "metadata": {},
   "source": [
    "2.6. apply stnadard sclaer for body measurements and robust scaler for cnn extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eedc423f-20a2-4ff2-a8b9-17d1c011c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Columns\n",
    "# -----------------------------\n",
    "\n",
    "# columns to exclude from any scaling\n",
    "exclude_cols = ['photo_id', 'subject_id', 'index', 'gender']\n",
    "\n",
    "# target columns (predicted outputs) -> DO NOT SCALE\n",
    "target_cols = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'weight_kg'\n",
    "]\n",
    "\n",
    "# feature columns that must use StandardScaler (but are NOT targets)\n",
    "standard_feature_cols = ['height_cm']\n",
    "\n",
    "# keep only existing columns\n",
    "target_cols = [c for c in target_cols if c in data.columns]\n",
    "standard_feature_cols = [c for c in standard_feature_cols if c in data.columns]\n",
    "\n",
    "# remaining feature columns -> RobustScaler (exclude cols + targets + standard-scaled features)\n",
    "robust_feature_cols = [\n",
    "    col for col in data.columns\n",
    "    if col not in exclude_cols\n",
    "    and col not in target_cols\n",
    "    and col not in standard_feature_cols\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Create scalers (features only)\n",
    "# -----------------------------\n",
    "\n",
    "scaler_standard_features = StandardScaler()\n",
    "scaler_robust_features = RobustScaler()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Fit & transform (features only)\n",
    "# -----------------------------\n",
    "\n",
    "if standard_feature_cols:\n",
    "    data[standard_feature_cols] = scaler_standard_features.fit_transform(\n",
    "        data[standard_feature_cols]\n",
    "    )\n",
    "\n",
    "if robust_feature_cols:\n",
    "    data[robust_feature_cols] = scaler_robust_features.fit_transform(\n",
    "        data[robust_feature_cols]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4707456-2e11-4ead-9ab7-534b91ca8d19",
   "metadata": {},
   "source": [
    "3. model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e07427-117c-46ac-9bdc-f049f9a1024b",
   "metadata": {},
   "source": [
    "3.1. split the data for independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ffaa0e-f6df-4778-ae89-fb050332a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "Shape of Y (samples, targets): (1684, 14)\n"
     ]
    }
   ],
   "source": [
    "# List of columns to be used as dependent (target) features\n",
    "target_cols = [\n",
    "    'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip',\n",
    "    'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh',\n",
    "    'waist', 'wrist', 'weight_kg'\n",
    "]\n",
    "\n",
    "# Select these columns from the DataFrame as the multi-target Y\n",
    "Y = data[target_cols]                  # Y will hold all dependent variables for multi-target regression\n",
    "\n",
    "print(\"Selected target columns:\", target_cols)  # print which columns are used as targets\n",
    "print(\"Shape of Y (samples, targets):\", Y.shape)  # print shape to confirm dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69820f72-d599-4ec3-acdf-ab2cc8e9d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop for X:\n",
      " ['photo_id', 'subject_id', 'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "\n",
      "Shape of X (samples, independent features): (1684, 5122)\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop for building independent features (X)\n",
    "drop_cols = ['photo_id', 'subject_id'] + target_cols   # combine ID columns with target columns\n",
    "\n",
    "print(\"Columns to drop for X:\\n\", drop_cols)           # show which columns will be removed\n",
    "\n",
    "# Create X by dropping ID columns and all target columns\n",
    "X = data.drop(columns=drop_cols)                       # drop the unwanted columns to get independent features\n",
    "\n",
    "print(\"\\nShape of X (samples, independent features):\", X.shape)  # print shape of X\n",
    "#print(\"\\nColumns in X:\\n\", X.columns.tolist())         # list all feature names in X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa19694-b660-4eb9-8f1d-bf26d30204ee",
   "metadata": {},
   "source": [
    "3.2. load the model for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b11412f-6c51-4892-ae2b-2049d76b46b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 15:05:01.178834: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-19 15:05:08.830378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-19 15:05:12.944438: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-19 15:05:12.976286: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-19 15:05:18.711015: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-19 15:05:28.578418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating S3 client...\n",
      "Reading model bytes from s3://ai-bmi-predictor/trained-models/efficientnet-models/eff_ann_version12.h5\n",
      "Opening HDF5 file from memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 15:05:35.803101: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:43.843325: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:43.846488: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:43.851027: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:43.853613: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:43.856153: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:44.331329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:44.332452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:44.333439: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-19 15:05:44.335242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13760 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from S3 (in-memory)!\n"
     ]
    }
   ],
   "source": [
    "import boto3                                             # import boto3 to read from S3\n",
    "import io                                                # import io for in-memory byte streams\n",
    "import h5py                                              # import h5py to open HDF5 file objects\n",
    "import tensorflow as tf                                  # import tensorflow for loading the model\n",
    "\n",
    "bucket_name = \"ai-bmi-predictor\"                         # S3 bucket name\n",
    "model_key  = \"trained-models/efficientnet-models/eff_ann_version12.h5\"  # path of model file in S3\n",
    "\n",
    "print(\"Creating S3 client...\")                           # status message\n",
    "s3 = boto3.client(\"s3\")                                  # create S3 client (uses your AWS credentials)\n",
    "\n",
    "print(f\"Reading model bytes from s3://{bucket_name}/{model_key}\")  # status message\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=model_key)   # download object bytes into memory\n",
    "model_bytes = obj[\"Body\"].read()                         # read the body content as raw bytes\n",
    "\n",
    "byte_stream = io.BytesIO(model_bytes)                    # wrap bytes in an in-memory binary stream\n",
    "\n",
    "print(\"Opening HDF5 file from memory...\")                # status message\n",
    "with h5py.File(byte_stream, 'r') as h5file:              # open the stream as an HDF5 file\n",
    "    best_model = tf.keras.models.load_model(h5file)      # load Keras model from this HDF5 file object\n",
    "\n",
    "print(\"Model loaded successfully from S3 (in-memory)!\")  # confirmation message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91cf567-300a-43e2-9b58-c922fb627b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               2622976   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 14)                7182      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3155470 (12.04 MB)\n",
      "Trainable params: 3155470 (12.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce39fa-f08d-4daa-a744-5928bab65364",
   "metadata": {},
   "source": [
    "3.3. calculate performance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7bd7df-d012-4afa-9869-98552cf0be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation X: (1684, 5122)\n",
      "Shape of validation Y: (1684, 14)\n",
      "\n",
      "Target columns (body measurements):\n",
      "['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 1. Imports\n",
    "# -------------------------------------------\n",
    "import numpy as np                               # numerical operations\n",
    "import pandas as pd                              # to build a nice results table\n",
    "import tensorflow as tf                          # to load and run the Keras model\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error  # metrics\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3. Prepare validation data\n",
    "#    We assume:\n",
    "#      - X : pandas DataFrame with validation independent features (already scaled)\n",
    "#      - Y : pandas DataFrame with validation targets (same order as training, already scaled)\n",
    "# -------------------------------------------\n",
    "\n",
    "print(\"Shape of validation X:\", X.shape)            # show shape of validation features\n",
    "print(\"Shape of validation Y:\", Y.shape)            # show shape of validation targets\n",
    "\n",
    "# Save target column names (body measurement names)\n",
    "target_cols = list(Y.columns)                       # list of body measurement names\n",
    "print(\"\\nTarget columns (body measurements):\")\n",
    "print(target_cols)                                  # print body measurement names\n",
    "\n",
    "# Convert X and Y to NumPy arrays for prediction / metric computation\n",
    "X_val = X.values.astype(\"float32\")                  # features as float32 array\n",
    "Y_val = Y.values.astype(\"float32\")                  # targets as float32 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ecb203-bd7d-4068-9562-fc9708734567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference on validation data ...\n",
      "Inference completed.\n",
      "Predictions shape: (1684, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------\n",
    "# 4. Run inference to get predictions\n",
    "# -------------------------------------------\n",
    "print(\"\\nRunning inference on validation data ...\") # status message\n",
    "Y_pred = best_model.predict(X_val, verbose=0)       # model predictions for validation data\n",
    "print(\"Inference completed.\")\n",
    "print(\"Predictions shape:\", Y_pred.shape)           # check prediction shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e628a-3004-48db-a051-48cd5eb4a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# -------------------------------------------\n",
    "# 4.1 Inverse-transform targets to original units\n",
    "#      Assumes scaler_targets was fitted on target_cols during preprocessing\n",
    "# -------------------------------------------\n",
    "\n",
    "# Y_val and Y_pred are currently in [-1, 1] scaled space\n",
    "# Convert both back to original measurement units (cm, kg, etc.)\n",
    "Y_true_orig = scaler_targets.inverse_transform(Y_val)\n",
    "Y_pred_orig = scaler_targets.inverse_transform(Y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a217273b-8669-4a88-9b76-eb5e30f2db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics (R^2, MSE, MAE) for each body measurement ...\n",
      "ankle                -> R^2: 0.4293, MSE: 1.788787, MAE: 1.039674\n",
      "arm-length           -> R^2: 0.4781, MSE: 4.773264, MAE: 1.698977\n",
      "bicep                -> R^2: 0.5648, MSE: 5.929685, MAE: 1.978127\n",
      "calf                 -> R^2: 0.3100, MSE: 6.181846, MAE: 2.052739\n",
      "chest                -> R^2: 0.7074, MSE: 30.031097, MAE: 4.450536\n",
      "forearm              -> R^2: 0.5592, MSE: 2.432892, MAE: 1.248617\n",
      "hip                  -> R^2: 0.5615, MSE: 32.853966, MAE: 4.708916\n",
      "leg-length           -> R^2: 0.3984, MSE: 13.720290, MAE: 2.875653\n",
      "shoulder-breadth     -> R^2: 0.7043, MSE: 1.706782, MAE: 1.062428\n",
      "shoulder-to-crotch   -> R^2: 0.6199, MSE: 7.150671, MAE: 2.184376\n",
      "thigh                -> R^2: 0.6072, MSE: 11.367884, MAE: 2.759248\n",
      "waist                -> R^2: 0.4769, MSE: 55.510918, MAE: 6.204419\n",
      "wrist                -> R^2: 0.4322, MSE: 0.913207, MAE: 0.748591\n",
      "weight_kg            -> R^2: 0.5613, MSE: 87.306488, MAE: 7.547867\n",
      "\n",
      "Per-measurement metrics table:\n",
      "      body_measurement        r2        mse       mae\n",
      "0                ankle  0.429321   1.788787  1.039674\n",
      "1           arm-length  0.478129   4.773264  1.698977\n",
      "2                bicep  0.564808   5.929685  1.978127\n",
      "3                 calf  0.309980   6.181846  2.052739\n",
      "4                chest  0.707365  30.031097  4.450536\n",
      "5              forearm  0.559159   2.432892  1.248617\n",
      "6                  hip  0.561502  32.853966  4.708916\n",
      "7           leg-length  0.398393  13.720290  2.875653\n",
      "8     shoulder-breadth  0.704314   1.706782  1.062428\n",
      "9   shoulder-to-crotch  0.619886   7.150671  2.184376\n",
      "10               thigh  0.607201  11.367884  2.759248\n",
      "11               waist  0.476922  55.510918  6.204419\n",
      "12               wrist  0.432195   0.913207  0.748591\n",
      "13           weight_kg  0.561295  87.306488  7.547867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------\n",
    "# 5. Compute metrics per body measurement\n",
    "# -------------------------------------------\n",
    "print(\"\\nComputing metrics (R^2, MSE, MAE) for each body measurement ...\")\n",
    "\n",
    "results = []                                        # list to collect metric rows\n",
    "\n",
    "# Loop over each target dimension / body measurement\n",
    "for i, name in enumerate(target_cols):              # i = column index, name = column name\n",
    "    y_true = Y_val[:, i]                            # true values for this measurement\n",
    "    y_pred = Y_pred[:, i]                           # predicted values for this measurement\n",
    "\n",
    "    r2  = r2_score(y_true, y_pred)                  # compute R^2 score\n",
    "    mse = mean_squared_error(y_true, y_pred)        # compute mean squared error\n",
    "    mae = mean_absolute_error(y_true, y_pred)       # compute mean absolute error\n",
    "\n",
    "    # append metrics as a dict (one row)\n",
    "    results.append({\n",
    "        \"body_measurement\": name,                   # column for measurement name\n",
    "        \"r2\": r2,                                   # R^2 value\n",
    "        \"mse\": mse,                                 # MSE value\n",
    "        \"mae\": mae                                  # MAE value\n",
    "    })\n",
    "\n",
    "    # print quick summary for this measurement\n",
    "    print(f\"{name:20s} -> R^2: {r2:.4f}, MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "# Convert results list to a DataFrame for nice tabular view\n",
    "results_df = pd.DataFrame(results)                  # create DataFrame from list of dicts\n",
    "\n",
    "print(\"\\nPer-measurement metrics table:\")\n",
    "print(results_df)                                   # display table with all metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be0280ab-a6d8-4acd-b0ff-20fd0f29b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall (mean) scores across all body measurements:\n",
      "Mean R^2 : 0.5293\n",
      "Mean MSE : 18.690556\n",
      "Mean MAE : 2.897155\n",
      "\n",
      "Metrics table including overall mean row:\n",
      "      body_measurement        r2        mse       mae\n",
      "0                ankle  0.429321   1.788787  1.039674\n",
      "1           arm-length  0.478129   4.773264  1.698977\n",
      "2                bicep  0.564808   5.929685  1.978127\n",
      "3                 calf  0.309980   6.181846  2.052739\n",
      "4                chest  0.707365  30.031097  4.450536\n",
      "5              forearm  0.559159   2.432892  1.248617\n",
      "6                  hip  0.561502  32.853966  4.708916\n",
      "7           leg-length  0.398393  13.720290  2.875653\n",
      "8     shoulder-breadth  0.704314   1.706782  1.062428\n",
      "9   shoulder-to-crotch  0.619886   7.150671  2.184376\n",
      "10               thigh  0.607201  11.367884  2.759248\n",
      "11               waist  0.476922  55.510918  6.204419\n",
      "12               wrist  0.432195   0.913207  0.748591\n",
      "13           weight_kg  0.561295  87.306488  7.547867\n",
      "14        OVERALL_MEAN  0.529319  18.690556  2.897155\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# 6. Compute overall (mean) scores across all measurements\n",
    "# -------------------------------------------\n",
    "overall_r2  = results_df[\"r2\"].mean()               # mean R^2 over all body measurements\n",
    "overall_mse = results_df[\"mse\"].mean()              # mean MSE over all body measurements\n",
    "overall_mae = results_df[\"mae\"].mean()              # mean MAE over all body measurements\n",
    "\n",
    "print(\"\\nOverall (mean) scores across all body measurements:\")\n",
    "print(f\"Mean R^2 : {overall_r2:.4f}\")\n",
    "print(f\"Mean MSE : {overall_mse:.6f}\")\n",
    "print(f\"Mean MAE : {overall_mae:.6f}\")\n",
    "\n",
    "# Optionally, add a final row with the overall mean scores to the table\n",
    "overall_row = {\n",
    "    \"body_measurement\": \"OVERALL_MEAN\",             # label row as overall\n",
    "    \"r2\": overall_r2,\n",
    "    \"mse\": overall_mse,\n",
    "    \"mae\": overall_mae\n",
    "}\n",
    "results_df = pd.concat([results_df, pd.DataFrame([overall_row])], ignore_index=True)\n",
    "\n",
    "print(\"\\nMetrics table including overall mean row:\")\n",
    "print(results_df)                                   # final table with per-measurement + overall row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910a9a1-ffc5-4bff-86d5-f775515d86f2",
   "metadata": {},
   "source": [
    "3.4. performance based on real values after inverse transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be6e32-bb65-4367-befa-a1ed4087a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 4.1 Inverse-transform targets to original units\n",
    "# -------------------------------------------\n",
    "\n",
    "Y_true_orig = scaler_targets.inverse_transform(Y_val)\n",
    "Y_pred_orig = scaler_targets.inverse_transform(Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24489d70-7176-43ca-a972-aa8983766745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 5. Compute metrics per body measurement (in original units)\n",
    "# -------------------------------------------\n",
    "print(\"\\nComputing metrics (R^2, MSE, MAE) for each body measurement in ORIGINAL UNITS ...\")\n",
    "\n",
    "results = []                                        # list to collect metric rows\n",
    "\n",
    "# Loop over each target dimension / body measurement\n",
    "for i, name in enumerate(target_cols):              # i = column index, name = column name\n",
    "    # use inverse-transformed (real-unit) values\n",
    "    y_true = Y_true_orig[:, i]                      # true values for this measurement (cm, kg, etc.)\n",
    "    y_pred = Y_pred_orig[:, i]                      # predicted values for this measurement (cm, kg, etc.)\n",
    "\n",
    "    r2  = r2_score(y_true, y_pred)                  # compute R^2 score\n",
    "    mse = mean_squared_error(y_true, y_pred)        # compute mean squared error\n",
    "    mae = mean_absolute_error(y_true, y_pred)       # compute mean absolute error\n",
    "\n",
    "    # append metrics as a dict (one row)\n",
    "    results.append({\n",
    "        \"body_measurement\": name,                   # column for measurement name\n",
    "        \"r2\": r2,                                   # R^2 value\n",
    "        \"mse\": mse,                                 # MSE value (in squared real units)\n",
    "        \"mae\": mae                                  # MAE value (in real units)\n",
    "    })\n",
    "\n",
    "    # print quick summary for this measurement\n",
    "    print(f\"{name:20s} -> R^2: {r2:.4f}, MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "# Convert results list to a DataFrame for nice tabular view\n",
    "results_df = pd.DataFrame(results)                  # create DataFrame from list of dicts\n",
    "\n",
    "print(\"\\nPer-measurement metrics table (original units):\")\n",
    "print(results_df)                                   # display table with all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c605b2-2b1c-4edb-b08e-c63123dadd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 6. Compute overall (mean) scores across all measurements (original units)\n",
    "# -------------------------------------------\n",
    "overall_r2  = results_df[\"r2\"].mean()               # mean R^2 over all body measurements\n",
    "overall_mse = results_df[\"mse\"].mean()              # mean MSE over all body measurements\n",
    "overall_mae = results_df[\"mae\"].mean()              # mean MAE over all body measurements\n",
    "\n",
    "print(\"\\nOverall (mean) scores across all body measurements (original units):\")\n",
    "print(f\"Mean R^2 : {overall_r2:.4f}\")\n",
    "print(f\"Mean MSE : {overall_mse:.6f}\")\n",
    "print(f\"Mean MAE : {overall_mae:.6f}\")\n",
    "\n",
    "# Optionally, add a final row with the overall mean scores to the table\n",
    "overall_row = {\n",
    "    \"body_measurement\": \"OVERALL_MEAN\",             # label row as overall\n",
    "    \"r2\": overall_r2,\n",
    "    \"mse\": overall_mse,\n",
    "    \"mae\": overall_mae\n",
    "}\n",
    "results_df = pd.concat([results_df, pd.DataFrame([overall_row])], ignore_index=True)\n",
    "\n",
    "print(\"\\nMetrics table including overall mean row (original units):\")\n",
    "print(results_df)                                   # final table with per-measurement + overall row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba927f97-1b75-48fd-9010-317317118fd2",
   "metadata": {},
   "source": [
    "* MAE = 2.5 -> predictions are off (away) by about 2.5 units from the true values. Sometimes error can be above (overestimates) and sometimes error can be below (underestimated). On average model is wrong by 2.5 unots\n",
    "* R Squared = 0.55 -> model explains about 55% of the variation in the overall body measurements\n",
    "* MSE = 12.25 -> squared error between the predictions and true values are 12.25 units\n",
    "* MSE < 0 ->  get smaller overall error by ignoring all inputs and just predicting the average hip size for everyone, instead of using your modelâ€™s predictions.\n",
    "* MSE = -0.5 -> worse than the mean, with 50% more squared error than the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5a5cc-06a1-4761-961a-056550ae2539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
