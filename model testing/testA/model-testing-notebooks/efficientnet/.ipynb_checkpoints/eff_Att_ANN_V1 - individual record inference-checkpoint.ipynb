{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb4717e-2f3d-489c-9541-9cd95ce4f14a",
   "metadata": {},
   "source": [
    "Cell 1: Load libraries and dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf407d34-00fc-4a9d-8c2c-2aea6530eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5ae8fe5bbdf611a1e8d06e66e849bdf</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>-0.133776</td>\n",
       "      <td>0.881202</td>\n",
       "      <td>0.214236</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>-0.180302</td>\n",
       "      <td>-0.100713</td>\n",
       "      <td>-0.117249</td>\n",
       "      <td>...</td>\n",
       "      <td>106.774690</td>\n",
       "      <td>83.279744</td>\n",
       "      <td>39.922305</td>\n",
       "      <td>70.005128</td>\n",
       "      <td>55.945992</td>\n",
       "      <td>98.250390</td>\n",
       "      <td>20.187082</td>\n",
       "      <td>male</td>\n",
       "      <td>180.00</td>\n",
       "      <td>94.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605a5fd09058c48156b0ef518b63b2de</td>\n",
       "      <td>0.092031</td>\n",
       "      <td>-0.066016</td>\n",
       "      <td>-0.145132</td>\n",
       "      <td>0.687441</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>-0.075221</td>\n",
       "      <td>-0.093846</td>\n",
       "      <td>-0.035840</td>\n",
       "      <td>0.033903</td>\n",
       "      <td>...</td>\n",
       "      <td>102.481633</td>\n",
       "      <td>84.876529</td>\n",
       "      <td>39.974203</td>\n",
       "      <td>73.591637</td>\n",
       "      <td>55.397032</td>\n",
       "      <td>88.003618</td>\n",
       "      <td>17.715785</td>\n",
       "      <td>male</td>\n",
       "      <td>188.90</td>\n",
       "      <td>86.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909c9277309e13ee014e347603aba620</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>-0.051366</td>\n",
       "      <td>-0.148253</td>\n",
       "      <td>0.675916</td>\n",
       "      <td>0.209973</td>\n",
       "      <td>-0.073485</td>\n",
       "      <td>-0.072783</td>\n",
       "      <td>-0.059395</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>...</td>\n",
       "      <td>99.342301</td>\n",
       "      <td>82.275874</td>\n",
       "      <td>36.059983</td>\n",
       "      <td>66.440526</td>\n",
       "      <td>53.742692</td>\n",
       "      <td>82.100598</td>\n",
       "      <td>17.086464</td>\n",
       "      <td>male</td>\n",
       "      <td>179.70</td>\n",
       "      <td>73.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bef6a68bc8dd475c124f6de2413385d3</td>\n",
       "      <td>-0.018792</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>-0.148091</td>\n",
       "      <td>0.464433</td>\n",
       "      <td>0.242849</td>\n",
       "      <td>-0.106556</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.083478</td>\n",
       "      <td>0.096048</td>\n",
       "      <td>...</td>\n",
       "      <td>101.770144</td>\n",
       "      <td>76.081842</td>\n",
       "      <td>34.071748</td>\n",
       "      <td>62.218026</td>\n",
       "      <td>52.396573</td>\n",
       "      <td>83.999124</td>\n",
       "      <td>16.299751</td>\n",
       "      <td>female</td>\n",
       "      <td>166.95</td>\n",
       "      <td>69.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6d7ed4bc4a17546447efed0ca6e2ff11</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>-0.153379</td>\n",
       "      <td>0.635377</td>\n",
       "      <td>0.285274</td>\n",
       "      <td>-0.056372</td>\n",
       "      <td>-0.139008</td>\n",
       "      <td>-0.120711</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>...</td>\n",
       "      <td>94.707063</td>\n",
       "      <td>81.328892</td>\n",
       "      <td>36.834735</td>\n",
       "      <td>64.426273</td>\n",
       "      <td>49.895157</td>\n",
       "      <td>86.020117</td>\n",
       "      <td>16.531431</td>\n",
       "      <td>male</td>\n",
       "      <td>173.20</td>\n",
       "      <td>65.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           photo_id        f1        f2        f3        f4  \\\n",
       "0  e5ae8fe5bbdf611a1e8d06e66e849bdf  0.073159  0.085775 -0.133776  0.881202   \n",
       "1  605a5fd09058c48156b0ef518b63b2de  0.092031 -0.066016 -0.145132  0.687441   \n",
       "2  909c9277309e13ee014e347603aba620  0.057046 -0.051366 -0.148253  0.675916   \n",
       "3  bef6a68bc8dd475c124f6de2413385d3 -0.018792  0.016435 -0.148091  0.464433   \n",
       "4  6d7ed4bc4a17546447efed0ca6e2ff11  0.084419  0.065945 -0.153379  0.635377   \n",
       "\n",
       "         f5        f6        f7        f8        f9  ...         hip  \\\n",
       "0  0.214236  0.016104 -0.180302 -0.100713 -0.117249  ...  106.774690   \n",
       "1  0.186508 -0.075221 -0.093846 -0.035840  0.033903  ...  102.481633   \n",
       "2  0.209973 -0.073485 -0.072783 -0.059395  0.008370  ...   99.342301   \n",
       "3  0.242849 -0.106556  0.001489 -0.083478  0.096048  ...  101.770144   \n",
       "4  0.285274 -0.056372 -0.139008 -0.120711 -0.002466  ...   94.707063   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh      waist  \\\n",
       "0   83.279744         39.922305           70.005128  55.945992  98.250390   \n",
       "1   84.876529         39.974203           73.591637  55.397032  88.003618   \n",
       "2   82.275874         36.059983           66.440526  53.742692  82.100598   \n",
       "3   76.081842         34.071748           62.218026  52.396573  83.999124   \n",
       "4   81.328892         36.834735           64.426273  49.895157  86.020117   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  20.187082    male     180.00      94.60  \n",
       "1  17.715785    male     188.90      86.75  \n",
       "2  17.086464    male     179.70      73.85  \n",
       "3  16.299751  female     166.95      69.05  \n",
       "4  16.531431    male     173.20      65.55  \n",
       "\n",
       "[5 rows x 5138 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Load libraries and dataset from S3\n",
    "\n",
    "import boto3        # import boto3 to connect to AWS S3\n",
    "import pandas as pd # import pandas for data handling\n",
    "\n",
    "bucket = \"ai-bmi-predictor\"                 # name of the S3 bucket\n",
    "key = \"test-data/eff_testingA.csv\"         # path to the CSV file inside the bucket\n",
    "\n",
    "s3 = boto3.client(\"s3\")                    # create an S3 client using your AWS credentials\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)  # download the S3 object that contains the CSV file\n",
    "\n",
    "data = pd.read_csv(obj[\"Body\"])           # read the CSV content from the S3 object body into a DataFrame\n",
    "\n",
    "data.head()                               # display the first few rows to confirm the data loaded correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746c73e-e192-4ab0-8fc1-cacbb25a6e60",
   "metadata": {},
   "source": [
    "Cell 2: Compute BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f757059-e4d5-47aa-95e5-c998199d62bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1684.000000\n",
       "mean       24.056672\n",
       "std         4.147934\n",
       "min        16.019762\n",
       "25%        21.851282\n",
       "50%        23.221269\n",
       "75%        25.538605\n",
       "max        37.510454\n",
       "Name: BMI, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Compute BMI (using original height and weight) and store it in the dataset\n",
    "\n",
    "data[\"BMI\"] = data[\"weight_kg\"] / ((data[\"height_cm\"] / 100) ** 2)  # calculate BMI and save as a new column\n",
    "data[\"BMI\"].describe()                                              # quickly inspect BMI statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987d758-efbe-4d73-8f78-d941f7f106e1",
   "metadata": {},
   "source": [
    "Cell 3: Categorical encoding for 'gender' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138ee473-3f8a-494f-8bf3-a65e15cfe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Categorical encoding for 'gender' feature\n",
    "\n",
    "data[\"gender\"] = data[\"gender\"].astype(\"category\")  # convert 'gender' column to categorical type\n",
    "data[\"gender\"] = data[\"gender\"].cat.codes           # replace categories with numeric codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d447e5-eedb-4a0f-a64f-eee4e8272f2b",
   "metadata": {},
   "source": [
    "Cell 4: Min-max scaling (range -1 to 1) for body measurements and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fedf7f1-6371-4786-8cf2-9725bdbeab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Min-max scaling (range -1 to 1) for body measurements and height\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # import the MinMaxScaler for normalization\n",
    "\n",
    "cols_to_scale_targets = [\n",
    "    \"ankle\", \"arm-length\", \"bicep\", \"calf\", \"chest\", \"forearm\", \"hip\",\n",
    "    \"leg-length\", \"shoulder-breadth\", \"shoulder-to-crotch\", \"thigh\",\n",
    "    \"waist\", \"wrist\", \"weight_kg\"\n",
    "]                                               # list of target columns to scale (body measurements and weight)\n",
    "\n",
    "height_col = [\"height_cm\"]                      # list containing the name of the height column (input only)\n",
    "\n",
    "scaler_targets = MinMaxScaler(feature_range=(-1, 1))  # scaler for target body measurements and weight\n",
    "scaler_height = MinMaxScaler(feature_range=(-1, 1))   # scaler for height_cm (input feature)\n",
    "\n",
    "data[cols_to_scale_targets] = scaler_targets.fit_transform(  # fit & transform target columns with scaler_targets\n",
    "    data[cols_to_scale_targets]\n",
    ")\n",
    "\n",
    "data[height_col] = scaler_height.fit_transform(             # fit & transform height column with scaler_height\n",
    "    data[height_col]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae955a0-cc64-44dd-a796-6440a1271fb9",
   "metadata": {},
   "source": [
    "Cell 5: Create X (independent features) and Y (multi-target outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06786adf-6764-4afa-bcf8-cd94d2b12aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "Shape of Y (samples, targets): (1684, 14)\n",
      "Columns to drop for X:\n",
      " ['photo_id', 'subject_id', 'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg', 'BMI']\n",
      "\n",
      "Shape of X (samples, independent features): (1684, 5122)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create X (independent features) and Y (multi-target outputs)\n",
    "\n",
    "target_cols = [\n",
    "    \"ankle\", \"arm-length\", \"bicep\", \"calf\", \"chest\", \"forearm\", \"hip\",\n",
    "    \"leg-length\", \"shoulder-breadth\", \"shoulder-to-crotch\", \"thigh\",\n",
    "    \"waist\", \"wrist\", \"weight_kg\"\n",
    "]                                                # list of target columns for multi-target regression\n",
    "\n",
    "Y = data[target_cols]                            # select target columns as Y (scaled values)\n",
    "print(\"Selected target columns:\", target_cols)   # print which columns are used as targets\n",
    "print(\"Shape of Y (samples, targets):\", Y.shape) # print the shape of Y to confirm dimensions\n",
    "\n",
    "drop_cols = [\"photo_id\", \"subject_id\"] + target_cols + [\"BMI\"]  # columns to drop when building X (IDs, targets, BMI helper column)\n",
    "\n",
    "print(\"Columns to drop for X:\\n\", drop_cols)     # show which columns will be removed from data to form X\n",
    "\n",
    "X = data.drop(columns=drop_cols)                 # drop unwanted columns to create feature matrix X\n",
    "\n",
    "print(\"\\nShape of X (samples, independent features):\", X.shape)  # print shape of X\n",
    "# print(\"\\nColumns in X:\\n\", X.columns.tolist())   # optional: print all feature names in X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3f04c-f199-4a55-92cb-7531546731f2",
   "metadata": {},
   "source": [
    "Cell 6: Load trained Keras model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24cda960-86fc-4671-a121-0b0bcb69f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 13:17:29.682895: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 13:17:39.332981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-03 13:17:44.773734: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-03 13:17:44.830328: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-03 13:17:52.711839: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 13:18:02.620564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating S3 client...\n",
      "Reading model bytes from s3://ai-bmi-predictor/trained-models/efficientnet-models/eff_ann_version3.h5\n",
      "Opening HDF5 file from memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 13:18:09.311134: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:12.789836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:12.793226: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:12.797090: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:12.799796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:12.802428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:13.392317: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:13.393422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:13.394403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-03 13:18:13.396047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13760 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from S3 (in-memory)!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load trained Keras model from S3 (in-memory)\n",
    "\n",
    "import io                                        # import io for in-memory byte streams\n",
    "import h5py                                      # import h5py to open HDF5 file objects\n",
    "import tensorflow as tf                          # import tensorflow to load the Keras model\n",
    "\n",
    "bucket_name = \"ai-bmi-predictor\"                 # S3 bucket name for the trained model\n",
    "model_key  = \"trained-models/efficientnet-models/eff_ann_version3.h5\"  # path of model file in S3\n",
    "\n",
    "print(\"Creating S3 client...\")                   # status message to show progress\n",
    "s3 = boto3.client(\"s3\")                          # create a new S3 client (safe even if one already exists)\n",
    "\n",
    "print(f\"Reading model bytes from s3://{bucket_name}/{model_key}\")  # show which model file is being read\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=model_key)             # download the model file as an S3 object\n",
    "model_bytes = obj[\"Body\"].read()                                   # read the S3 object body as raw bytes\n",
    "\n",
    "byte_stream = io.BytesIO(model_bytes)           # wrap the raw bytes in an in-memory binary stream\n",
    "\n",
    "print(\"Opening HDF5 file from memory...\")        # status message before loading HDF5\n",
    "with h5py.File(byte_stream, \"r\") as h5file:      # open the binary stream as an HDF5 file\n",
    "    best_model = tf.keras.models.load_model(h5file)  # load the Keras model from the HDF5 file\n",
    "\n",
    "print(\"Model loaded successfully from S3 (in-memory)!\")  # confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c6842-6ab1-4a1e-afcb-4a67534270ff",
   "metadata": {},
   "source": [
    "Cell 7: Pick one random record within a BMI range, predict targets, and compare with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a691857d-ecb8-4585-bb17-ffbb2e2a3268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in BMI range: 90\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Selected sample index: 280\n",
      "BMI of selected sample: 19.74\n",
      "\n",
      "Actual vs Predicted values for the selected record:\n",
      "\n",
      "                       Actual  Predicted\n",
      "ankle               21.172955  21.496042\n",
      "arm-length          48.619260  45.545853\n",
      "bicep               23.578033  26.940432\n",
      "calf                32.970005  33.435440\n",
      "chest               89.989174  92.277100\n",
      "forearm             22.829291  23.463467\n",
      "hip                 92.125618  97.474609\n",
      "leg-length          79.345838  77.415649\n",
      "shoulder-breadth    31.251341  32.057907\n",
      "shoulder-to-crotch  59.567098  59.752468\n",
      "thigh               46.052163  52.937538\n",
      "waist               76.294553  77.588676\n",
      "wrist               15.936303  15.317590\n",
      "weight_kg           54.000000  57.697151\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Pick one random record within a BMI range, predict targets, and compare with actual values\n",
    "\n",
    "bmi_min = 18.0                                    # minimum BMI value for selection\n",
    "bmi_max = 20.0                                    # maximum BMI value for selection\n",
    "\n",
    "bmi_filtered = data[(data[\"BMI\"] >= bmi_min) &    # filter rows where BMI is greater than or equal to bmi_min\n",
    "                    (data[\"BMI\"] <= bmi_max)]     # and BMI is less than or equal to bmi_max\n",
    "\n",
    "print(\"Number of records in BMI range:\", len(bmi_filtered))  # show how many records match the BMI condition\n",
    "\n",
    "if bmi_filtered.empty:                            # check if there are no rows in the requested BMI range\n",
    "    raise ValueError(\"No records found in the BMI range 18–20. Please adjust the range or check the data.\")  # raise an error if none\n",
    "\n",
    "sample_row = bmi_filtered.sample(n=1, random_state=None)  # randomly pick a single row from the filtered DataFrame\n",
    "\n",
    "sample_index = sample_row.index[0]               # get the index of the selected row\n",
    "\n",
    "X_sample = X.loc[[sample_index]]                 # extract the corresponding feature row from X (as a DataFrame)\n",
    "Y_sample_scaled = Y.loc[[sample_index]]          # extract the corresponding scaled targets row from Y\n",
    "\n",
    "y_pred_scaled = best_model.predict(X_sample)     # use the trained model to predict scaled target values for the selected record\n",
    "\n",
    "y_actual = scaler_targets.inverse_transform(     # inverse-transform scaled actual targets back to original units\n",
    "    Y_sample_scaled.values\n",
    ")\n",
    "\n",
    "y_pred = scaler_targets.inverse_transform(       # inverse-transform scaled predicted targets back to original units\n",
    "    y_pred_scaled\n",
    ")\n",
    "\n",
    "actual_df = pd.DataFrame(y_actual, columns=target_cols).T   # create a DataFrame for actual values (transpose for nicer layout)\n",
    "actual_df.columns = [\"Actual\"]                              # rename the single column to 'Actual'\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred, columns=target_cols).T       # create a DataFrame for predicted values (transpose for nicer layout)\n",
    "pred_df.columns = [\"Predicted\"]                             # rename the single column to 'Predicted'\n",
    "\n",
    "result_df = pd.concat([actual_df, pred_df], axis=1)         # combine actual and predicted values side-by-side\n",
    "\n",
    "print(f\"Selected sample index: {sample_index}\")             # show the index of the selected sample\n",
    "print(f\"BMI of selected sample: {data.loc[sample_index, 'BMI']:.2f}\")  # print the BMI of the selected record\n",
    "print(\"\\nActual vs Predicted values for the selected record:\\n\")      # header for clarity\n",
    "print(result_df)                                             # print the table with actual and predicted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3a288-5082-45b4-839f-ed1958254509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
