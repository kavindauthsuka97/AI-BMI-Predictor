{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb4717e-2f3d-489c-9541-9cd95ce4f14a",
   "metadata": {},
   "source": [
    "Cell 1: Load libraries and dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf407d34-00fc-4a9d-8c2c-2aea6530eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>hip</th>\n",
       "      <th>leg-length</th>\n",
       "      <th>shoulder-breadth</th>\n",
       "      <th>shoulder-to-crotch</th>\n",
       "      <th>thigh</th>\n",
       "      <th>waist</th>\n",
       "      <th>wrist</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5ae8fe5bbdf611a1e8d06e66e849bdf</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>-0.133776</td>\n",
       "      <td>0.881202</td>\n",
       "      <td>0.214236</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>-0.180302</td>\n",
       "      <td>-0.100713</td>\n",
       "      <td>-0.117249</td>\n",
       "      <td>...</td>\n",
       "      <td>106.774690</td>\n",
       "      <td>83.279744</td>\n",
       "      <td>39.922305</td>\n",
       "      <td>70.005128</td>\n",
       "      <td>55.945992</td>\n",
       "      <td>98.250390</td>\n",
       "      <td>20.187082</td>\n",
       "      <td>male</td>\n",
       "      <td>180.00</td>\n",
       "      <td>94.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605a5fd09058c48156b0ef518b63b2de</td>\n",
       "      <td>0.092031</td>\n",
       "      <td>-0.066016</td>\n",
       "      <td>-0.145132</td>\n",
       "      <td>0.687441</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>-0.075221</td>\n",
       "      <td>-0.093846</td>\n",
       "      <td>-0.035840</td>\n",
       "      <td>0.033903</td>\n",
       "      <td>...</td>\n",
       "      <td>102.481633</td>\n",
       "      <td>84.876529</td>\n",
       "      <td>39.974203</td>\n",
       "      <td>73.591637</td>\n",
       "      <td>55.397032</td>\n",
       "      <td>88.003618</td>\n",
       "      <td>17.715785</td>\n",
       "      <td>male</td>\n",
       "      <td>188.90</td>\n",
       "      <td>86.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909c9277309e13ee014e347603aba620</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>-0.051366</td>\n",
       "      <td>-0.148253</td>\n",
       "      <td>0.675916</td>\n",
       "      <td>0.209973</td>\n",
       "      <td>-0.073485</td>\n",
       "      <td>-0.072783</td>\n",
       "      <td>-0.059395</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>...</td>\n",
       "      <td>99.342301</td>\n",
       "      <td>82.275874</td>\n",
       "      <td>36.059983</td>\n",
       "      <td>66.440526</td>\n",
       "      <td>53.742692</td>\n",
       "      <td>82.100598</td>\n",
       "      <td>17.086464</td>\n",
       "      <td>male</td>\n",
       "      <td>179.70</td>\n",
       "      <td>73.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bef6a68bc8dd475c124f6de2413385d3</td>\n",
       "      <td>-0.018792</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>-0.148091</td>\n",
       "      <td>0.464433</td>\n",
       "      <td>0.242849</td>\n",
       "      <td>-0.106556</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.083478</td>\n",
       "      <td>0.096048</td>\n",
       "      <td>...</td>\n",
       "      <td>101.770144</td>\n",
       "      <td>76.081842</td>\n",
       "      <td>34.071748</td>\n",
       "      <td>62.218026</td>\n",
       "      <td>52.396573</td>\n",
       "      <td>83.999124</td>\n",
       "      <td>16.299751</td>\n",
       "      <td>female</td>\n",
       "      <td>166.95</td>\n",
       "      <td>69.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6d7ed4bc4a17546447efed0ca6e2ff11</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>-0.153379</td>\n",
       "      <td>0.635377</td>\n",
       "      <td>0.285274</td>\n",
       "      <td>-0.056372</td>\n",
       "      <td>-0.139008</td>\n",
       "      <td>-0.120711</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>...</td>\n",
       "      <td>94.707063</td>\n",
       "      <td>81.328892</td>\n",
       "      <td>36.834735</td>\n",
       "      <td>64.426273</td>\n",
       "      <td>49.895157</td>\n",
       "      <td>86.020117</td>\n",
       "      <td>16.531431</td>\n",
       "      <td>male</td>\n",
       "      <td>173.20</td>\n",
       "      <td>65.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           photo_id        f1        f2        f3        f4  \\\n",
       "0  e5ae8fe5bbdf611a1e8d06e66e849bdf  0.073159  0.085775 -0.133776  0.881202   \n",
       "1  605a5fd09058c48156b0ef518b63b2de  0.092031 -0.066016 -0.145132  0.687441   \n",
       "2  909c9277309e13ee014e347603aba620  0.057046 -0.051366 -0.148253  0.675916   \n",
       "3  bef6a68bc8dd475c124f6de2413385d3 -0.018792  0.016435 -0.148091  0.464433   \n",
       "4  6d7ed4bc4a17546447efed0ca6e2ff11  0.084419  0.065945 -0.153379  0.635377   \n",
       "\n",
       "         f5        f6        f7        f8        f9  ...         hip  \\\n",
       "0  0.214236  0.016104 -0.180302 -0.100713 -0.117249  ...  106.774690   \n",
       "1  0.186508 -0.075221 -0.093846 -0.035840  0.033903  ...  102.481633   \n",
       "2  0.209973 -0.073485 -0.072783 -0.059395  0.008370  ...   99.342301   \n",
       "3  0.242849 -0.106556  0.001489 -0.083478  0.096048  ...  101.770144   \n",
       "4  0.285274 -0.056372 -0.139008 -0.120711 -0.002466  ...   94.707063   \n",
       "\n",
       "   leg-length  shoulder-breadth  shoulder-to-crotch      thigh      waist  \\\n",
       "0   83.279744         39.922305           70.005128  55.945992  98.250390   \n",
       "1   84.876529         39.974203           73.591637  55.397032  88.003618   \n",
       "2   82.275874         36.059983           66.440526  53.742692  82.100598   \n",
       "3   76.081842         34.071748           62.218026  52.396573  83.999124   \n",
       "4   81.328892         36.834735           64.426273  49.895157  86.020117   \n",
       "\n",
       "       wrist  gender  height_cm  weight_kg  \n",
       "0  20.187082    male     180.00      94.60  \n",
       "1  17.715785    male     188.90      86.75  \n",
       "2  17.086464    male     179.70      73.85  \n",
       "3  16.299751  female     166.95      69.05  \n",
       "4  16.531431    male     173.20      65.55  \n",
       "\n",
       "[5 rows x 5138 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Load libraries and dataset from S3\n",
    "\n",
    "import boto3        # import boto3 to connect to AWS S3\n",
    "import pandas as pd # import pandas for data handling\n",
    "\n",
    "bucket = \"ai-bmi-predictor\"                 # name of the S3 bucket\n",
    "key = \"test-data/eff_testingA.csv\"         # path to the CSV file inside the bucket\n",
    "\n",
    "s3 = boto3.client(\"s3\")                    # create an S3 client using your AWS credentials\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)  # download the S3 object that contains the CSV file\n",
    "\n",
    "data = pd.read_csv(obj[\"Body\"])           # read the CSV content from the S3 object body into a DataFrame\n",
    "\n",
    "data.head()                               # display the first few rows to confirm the data loaded correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746c73e-e192-4ab0-8fc1-cacbb25a6e60",
   "metadata": {},
   "source": [
    "Cell 2: Compute BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f757059-e4d5-47aa-95e5-c998199d62bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1684.000000\n",
       "mean       24.056672\n",
       "std         4.147934\n",
       "min        16.019762\n",
       "25%        21.851282\n",
       "50%        23.221269\n",
       "75%        25.538605\n",
       "max        37.510454\n",
       "Name: BMI, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Compute BMI (using original height and weight) and store it in the dataset\n",
    "\n",
    "data[\"BMI\"] = data[\"weight_kg\"] / ((data[\"height_cm\"] / 100) ** 2)  # calculate BMI and save as a new column\n",
    "data[\"BMI\"].describe()                                              # quickly inspect BMI statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987d758-efbe-4d73-8f78-d941f7f106e1",
   "metadata": {},
   "source": [
    "Cell 3: Categorical encoding for 'gender' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138ee473-3f8a-494f-8bf3-a65e15cfe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Categorical encoding for 'gender' feature\n",
    "\n",
    "data[\"gender\"] = data[\"gender\"].astype(\"category\")  # convert 'gender' column to categorical type\n",
    "data[\"gender\"] = data[\"gender\"].cat.codes           # replace categories with numeric codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d447e5-eedb-4a0f-a64f-eee4e8272f2b",
   "metadata": {},
   "source": [
    "Cell 4: Min-max scaling (range -1 to 1) for body measurements and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fedf7f1-6371-4786-8cf2-9725bdbeab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Min-max scaling (range -1 to 1) for body measurements and height\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # import the MinMaxScaler for normalization\n",
    "\n",
    "cols_to_scale_targets = [\n",
    "    \"ankle\", \"arm-length\", \"bicep\", \"calf\", \"chest\", \"forearm\", \"hip\",\n",
    "    \"leg-length\", \"shoulder-breadth\", \"shoulder-to-crotch\", \"thigh\",\n",
    "    \"waist\", \"wrist\", \"weight_kg\"\n",
    "]                                               # list of target columns to scale (body measurements and weight)\n",
    "\n",
    "height_col = [\"height_cm\"]                      # list containing the name of the height column (input only)\n",
    "\n",
    "scaler_targets = MinMaxScaler(feature_range=(-1, 1))  # scaler for target body measurements and weight\n",
    "scaler_height = MinMaxScaler(feature_range=(-1, 1))   # scaler for height_cm (input feature)\n",
    "\n",
    "data[cols_to_scale_targets] = scaler_targets.fit_transform(  # fit & transform target columns with scaler_targets\n",
    "    data[cols_to_scale_targets]\n",
    ")\n",
    "\n",
    "data[height_col] = scaler_height.fit_transform(             # fit & transform height column with scaler_height\n",
    "    data[height_col]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae955a0-cc64-44dd-a796-6440a1271fb9",
   "metadata": {},
   "source": [
    "Cell 5: Create X (independent features) and Y (multi-target outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06786adf-6764-4afa-bcf8-cd94d2b12aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: ['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg']\n",
      "Shape of Y (samples, targets): (1684, 14)\n",
      "Columns to drop for X:\n",
      " ['photo_id', 'subject_id', 'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist', 'weight_kg', 'BMI']\n",
      "\n",
      "Shape of X (samples, independent features): (1684, 5122)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create X (independent features) and Y (multi-target outputs)\n",
    "\n",
    "target_cols = [\n",
    "    \"ankle\", \"arm-length\", \"bicep\", \"calf\", \"chest\", \"forearm\", \"hip\",\n",
    "    \"leg-length\", \"shoulder-breadth\", \"shoulder-to-crotch\", \"thigh\",\n",
    "    \"waist\", \"wrist\", \"weight_kg\"\n",
    "]                                                # list of target columns for multi-target regression\n",
    "\n",
    "Y = data[target_cols]                            # select target columns as Y (scaled values)\n",
    "print(\"Selected target columns:\", target_cols)   # print which columns are used as targets\n",
    "print(\"Shape of Y (samples, targets):\", Y.shape) # print the shape of Y to confirm dimensions\n",
    "\n",
    "drop_cols = [\"photo_id\", \"subject_id\"] + target_cols + [\"BMI\"]  # columns to drop when building X (IDs, targets, BMI helper column)\n",
    "\n",
    "print(\"Columns to drop for X:\\n\", drop_cols)     # show which columns will be removed from data to form X\n",
    "\n",
    "X = data.drop(columns=drop_cols)                 # drop unwanted columns to create feature matrix X\n",
    "\n",
    "print(\"\\nShape of X (samples, independent features):\", X.shape)  # print shape of X\n",
    "# print(\"\\nColumns in X:\\n\", X.columns.tolist())   # optional: print all feature names in X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3f04c-f199-4a55-92cb-7531546731f2",
   "metadata": {},
   "source": [
    "Cell 6: Load trained Keras model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24cda960-86fc-4671-a121-0b0bcb69f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 09:14:09.683566: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 09:14:09.696877: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-09 09:14:09.716750: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-09 09:14:09.716776: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-09 09:14:09.728962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-09 09:14:10.604787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating S3 client...\n",
      "Reading model bytes from s3://ai-bmi-predictor/trained-models/efficientnet-models/eff_ann_version3.h5\n",
      "Opening HDF5 file from memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 09:14:11.749176: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.795990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.797067: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.798670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.799702: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.800668: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.949032: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.950184: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.951203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-09 09:14:11.952147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 112 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "2025-12-09 09:14:11.968655: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1566] failed to allocate 112.81MiB (118292480 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from S3 (in-memory)!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load trained Keras model from S3 (in-memory)\n",
    "\n",
    "import io                                        # import io for in-memory byte streams\n",
    "import h5py                                      # import h5py to open HDF5 file objects\n",
    "import tensorflow as tf                          # import tensorflow to load the Keras model\n",
    "\n",
    "bucket_name = \"ai-bmi-predictor\"                 # S3 bucket name for the trained model\n",
    "model_key  = \"trained-models/efficientnet-models/eff_ann_version3.h5\"  # path of model file in S3\n",
    "\n",
    "print(\"Creating S3 client...\")                   # status message to show progress\n",
    "s3 = boto3.client(\"s3\")                          # create a new S3 client (safe even if one already exists)\n",
    "\n",
    "print(f\"Reading model bytes from s3://{bucket_name}/{model_key}\")  # show which model file is being read\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=model_key)             # download the model file as an S3 object\n",
    "model_bytes = obj[\"Body\"].read()                                   # read the S3 object body as raw bytes\n",
    "\n",
    "byte_stream = io.BytesIO(model_bytes)           # wrap the raw bytes in an in-memory binary stream\n",
    "\n",
    "print(\"Opening HDF5 file from memory...\")        # status message before loading HDF5\n",
    "with h5py.File(byte_stream, \"r\") as h5file:      # open the binary stream as an HDF5 file\n",
    "    best_model = tf.keras.models.load_model(h5file)  # load the Keras model from the HDF5 file\n",
    "\n",
    "print(\"Model loaded successfully from S3 (in-memory)!\")  # confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c6842-6ab1-4a1e-afcb-4a67534270ff",
   "metadata": {},
   "source": [
    "Cell 7: Pick one random record within a BMI range, predict targets, and compare with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a691857d-ecb8-4585-bb17-ffbb2e2a3268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in BMI range: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 09:14:17.677126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:191] failed to create cublas handle: the resource allocation failed\n",
      "2025-12-09 09:14:17.677159: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:194] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2025-12-09 09:14:17.677179: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INTERNAL: No blas support for stream\n",
      "\t [[{{node sequential/dense/MatMul}}]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node sequential/dense/MatMul defined at (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2974, in run_cell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3256, in run_cell_async\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n\n  File \"/tmp/ipykernel_18902/1126383453.py\", line 21, in <cell line: 21>\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2650, in predict\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2436, in predict_function\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2421, in step_function\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2409, in run_step\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2377, in predict_step\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 588, in __call__\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filezetbjpti.py\", line 34, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/sequential.py\", line 394, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/sequential.py\", line 397, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 514, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 661, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 663, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 663, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 663, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 671, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filezetbjpti.py\", line 34, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/layers/core/dense.py\", line 212, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/layers/core/dense.py\", line 218, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/layers/core/dense.py\", line 241, in call\n\nNo blas support for stream\n\t [[{{node sequential/dense/MatMul}}]] [Op:__inference_predict_function_411]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18902/1126383453.py\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mY_sample_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# extract the corresponding scaled targets row from Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0my_pred_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# use the trained model to predict scaled target values for the selected record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m y_actual = scaler_targets.inverse_transform(     # inverse-transform scaled actual targets back to original units\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node sequential/dense/MatMul defined at (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2974, in run_cell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3256, in run_cell_async\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n\n  File \"/tmp/ipykernel_18902/1126383453.py\", line 21, in <cell line: 21>\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2650, in predict\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2436, in predict_function\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2421, in step_function\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2409, in run_step\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 2377, in predict_step\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 588, in __call__\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filezetbjpti.py\", line 34, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/sequential.py\", line 394, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/sequential.py\", line 397, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 514, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 661, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 663, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 663, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 663, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/functional.py\", line 671, in _run_internal_graph\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_filezetbjpti.py\", line 34, in error_handler\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/layers/core/dense.py\", line 212, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/layers/core/dense.py\", line 218, in call\n\n  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/layers/core/dense.py\", line 241, in call\n\nNo blas support for stream\n\t [[{{node sequential/dense/MatMul}}]] [Op:__inference_predict_function_411]"
     ]
    }
   ],
   "source": [
    "# Cell 7: Pick one random record within a BMI range, predict targets, and compare with actual values\n",
    "\n",
    "bmi_min = 18.0                                    # minimum BMI value for selection\n",
    "bmi_max = 20.0                                    # maximum BMI value for selection\n",
    "\n",
    "bmi_filtered = data[(data[\"BMI\"] >= bmi_min) &    # filter rows where BMI is greater than or equal to bmi_min\n",
    "                    (data[\"BMI\"] <= bmi_max)]     # and BMI is less than or equal to bmi_max\n",
    "\n",
    "print(\"Number of records in BMI range:\", len(bmi_filtered))  # show how many records match the BMI condition\n",
    "\n",
    "if bmi_filtered.empty:                            # check if there are no rows in the requested BMI range\n",
    "    raise ValueError(\"No records found in the BMI range 18–20. Please adjust the range or check the data.\")  # raise an error if none\n",
    "\n",
    "sample_row = bmi_filtered.sample(n=1, random_state=None)  # randomly pick a single row from the filtered DataFrame\n",
    "\n",
    "sample_index = sample_row.index[0]               # get the index of the selected row\n",
    "\n",
    "X_sample = X.loc[[sample_index]]                 # extract the corresponding feature row from X (as a DataFrame)\n",
    "Y_sample_scaled = Y.loc[[sample_index]]          # extract the corresponding scaled targets row from Y\n",
    "\n",
    "y_pred_scaled = best_model.predict(X_sample)     # use the trained model to predict scaled target values for the selected record\n",
    "\n",
    "y_actual = scaler_targets.inverse_transform(     # inverse-transform scaled actual targets back to original units\n",
    "    Y_sample_scaled.values\n",
    ")\n",
    "\n",
    "y_pred = scaler_targets.inverse_transform(       # inverse-transform scaled predicted targets back to original units\n",
    "    y_pred_scaled\n",
    ")\n",
    "\n",
    "actual_df = pd.DataFrame(y_actual, columns=target_cols).T   # create a DataFrame for actual values (transpose for nicer layout)\n",
    "actual_df.columns = [\"Actual\"]                              # rename the single column to 'Actual'\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred, columns=target_cols).T       # create a DataFrame for predicted values (transpose for nicer layout)\n",
    "pred_df.columns = [\"Predicted\"]                             # rename the single column to 'Predicted'\n",
    "\n",
    "result_df = pd.concat([actual_df, pred_df], axis=1)         # combine actual and predicted values side-by-side\n",
    "\n",
    "print(f\"Selected sample index: {sample_index}\")             # show the index of the selected sample\n",
    "print(f\"BMI of selected sample: {data.loc[sample_index, 'BMI']:.2f}\")  # print the BMI of the selected record\n",
    "print(\"\\nActual vs Predicted values for the selected record:\\n\")      # header for clarity\n",
    "print(result_df)                                             # print the table with actual and predicted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3a288-5082-45b4-839f-ed1958254509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
