{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ede6b9-77ec-4b5e-b012-5a03df03b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated deploy_bmi/code/inference.py and requirements.txt\n",
      "üìÇ ['requirements.txt', 'inference.py']\n"
     ]
    }
   ],
   "source": [
    "import os  # filesystem ops\n",
    "\n",
    "os.makedirs(\"deploy_bmi/code\", exist_ok=True)  # ensure folder exists\n",
    "\n",
    "inference_py = r'''\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "TARGET_COLS = [\n",
    "    \"ankle\", \"arm-length\", \"bicep\", \"calf\", \"chest\", \"forearm\", \"hip\",\n",
    "    \"leg-length\", \"shoulder-breadth\", \"shoulder-to-crotch\", \"thigh\",\n",
    "    \"waist\", \"wrist\", \"weight_kg\",\n",
    "]\n",
    "\n",
    "GENDER_MAPPING = {\"female\": 0, \"male\": 1}\n",
    "\n",
    "\n",
    "def _b64_to_pil(b64_str: str):\n",
    "    img_bytes = base64.b64decode(b64_str)\n",
    "    return Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def _extract_features(feature_model, pil_img: Image.Image):\n",
    "    img = pil_img.resize((600, 600))\n",
    "    arr = np.array(img).astype(np.float32)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    arr = tf.keras.applications.efficientnet.preprocess_input(arr)\n",
    "    feat = feature_model.predict(arr, verbose=0)\n",
    "    return np.asarray(feat).reshape(-1)\n",
    "\n",
    "\n",
    "def model_fn(model_dir: str):\n",
    "    # --- ANN SavedModel path REQUIRED by TF Serving container ---\n",
    "    ann_savedmodel = os.path.join(model_dir, \"model\", \"1\")\n",
    "\n",
    "    # --- assets ---\n",
    "    assets_dir = os.path.join(model_dir, \"assets\")\n",
    "    w_path = os.path.join(assets_dir, \"efficientnetb7_imagenet.h5\")\n",
    "\n",
    "    robust_path = os.path.join(assets_dir, \"scaler_robust_features.pkl\")\n",
    "    height_path = os.path.join(assets_dir, \"scaler_standard_features.pkl\")\n",
    "    target_path = os.path.join(assets_dir, \"scaler_targets.pkl\")\n",
    "\n",
    "    # --- load ANN from SavedModel ---\n",
    "    bmi_model = tf.keras.models.load_model(ann_savedmodel, compile=False)\n",
    "\n",
    "    # --- EfficientNet feature extractor (NO internet download) ---\n",
    "    base = tf.keras.applications.EfficientNetB7(weights=None)\n",
    "    base.load_weights(w_path)\n",
    "    feature_model = tf.keras.Model(inputs=base.inputs, outputs=base.layers[-2].output)\n",
    "\n",
    "    # --- load scalers ---\n",
    "    with open(robust_path, \"rb\") as f:\n",
    "        robust_scaler = pickle.load(f)\n",
    "    with open(height_path, \"rb\") as f:\n",
    "        height_scaler = pickle.load(f)\n",
    "    with open(target_path, \"rb\") as f:\n",
    "        target_scaler = pickle.load(f)\n",
    "\n",
    "    return {\n",
    "        \"bmi_model\": bmi_model,\n",
    "        \"feature_model\": feature_model,\n",
    "        \"robust_scaler\": robust_scaler,\n",
    "        \"height_scaler\": height_scaler,\n",
    "        \"target_scaler\": target_scaler,\n",
    "    }\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type != \"application/json\":\n",
    "        raise ValueError(\"Only application/json is supported\")\n",
    "\n",
    "    payload = json.loads(request_body)\n",
    "\n",
    "    front_img = _b64_to_pil(payload[\"front_mask_b64\"])\n",
    "    side_img = _b64_to_pil(payload[\"side_mask_b64\"])\n",
    "    gender = payload[\"gender\"]\n",
    "    height_cm = float(payload[\"height_cm\"])\n",
    "\n",
    "    return {\"front_img\": front_img, \"side_img\": side_img, \"gender\": gender, \"height_cm\": height_cm}\n",
    "\n",
    "\n",
    "def predict_fn(data, m):\n",
    "    feature_model = m[\"feature_model\"]\n",
    "    bmi_model = m[\"bmi_model\"]\n",
    "    robust_scaler = m[\"robust_scaler\"]\n",
    "    height_scaler = m[\"height_scaler\"]\n",
    "    target_scaler = m[\"target_scaler\"]\n",
    "\n",
    "    front_vec = _extract_features(feature_model, data[\"front_img\"])\n",
    "    side_vec = _extract_features(feature_model, data[\"side_img\"])\n",
    "\n",
    "    feats = np.concatenate([front_vec, side_vec], axis=0)\n",
    "    feats_scaled = robust_scaler.transform(feats.reshape(1, -1))\n",
    "\n",
    "    g = data[\"gender\"]\n",
    "    if isinstance(g, str):\n",
    "        gender_code = float(GENDER_MAPPING[g.strip().lower()])\n",
    "    else:\n",
    "        gender_code = float(g)\n",
    "\n",
    "    height_scaled = height_scaler.transform(np.array([[data[\"height_cm\"]]], dtype=np.float32))\n",
    "\n",
    "    x = np.concatenate(\n",
    "        [feats_scaled, np.array([[gender_code]], dtype=np.float32), height_scaled.astype(np.float32)],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    y_scaled = bmi_model.predict(x, verbose=0)\n",
    "    y = target_scaler.inverse_transform(y_scaled)\n",
    "\n",
    "    preds = {TARGET_COLS[i]: float(y[0, i]) for i in range(len(TARGET_COLS))}\n",
    "    return {\"predictions\": preds, \"predictions_order\": TARGET_COLS}\n",
    "\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    if accept == \"application/json\":\n",
    "        return json.dumps(prediction), accept\n",
    "    raise ValueError(\"Only application/json is supported\")\n",
    "'''\n",
    "\n",
    "with open(\"deploy_bmi/code/inference.py\", \"w\") as f:\n",
    "    f.write(inference_py)\n",
    "\n",
    "with open(\"deploy_bmi/code/requirements.txt\", \"w\") as f:\n",
    "    f.write(\"scikit-learn\\npillow\\nnumpy\\n\")\n",
    "\n",
    "print(\"‚úÖ Updated deploy_bmi/code/inference.py and requirements.txt\")\n",
    "print(\"üìÇ\", os.listdir(\"deploy_bmi/code\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc707bb-257b-41b3-8f9c-3e54912ac347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:35:45.764283: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-18 17:35:45.780049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-18 17:35:45.804989: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-18 17:35:45.805027: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-18 17:35:45.820389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 17:35:46.685763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded: s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-18-11-02-51-500/output/model.tar.gz\n",
      "‚úÖ Extracted original tar\n",
      "‚úÖ Found H5: bmi_pkg_endpoint_v2/extract/eff_ann_version8.h5\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 17:35:48.162855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.209801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.210851: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.212555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.213565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.214512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.348692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.349789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.350773: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 17:35:48.351694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 721 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bmi_pkg_endpoint_v2/model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bmi_pkg_endpoint_v2/model/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported SavedModel to: bmi_pkg_endpoint_v2/model/1\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7.h5\n",
      "268326632/268326632 [==============================] - 8s 0us/step\n",
      "‚úÖ Bundled EfficientNet weights: bmi_pkg_endpoint_v2/assets/efficientnetb7_imagenet.h5\n",
      "‚úÖ Bundled scalers into assets/\n",
      "‚úÖ Created packaged tar: bmi_pkg_endpoint_v2/model.tar.gz\n",
      "‚úÖ Uploaded packaged model: s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-18-11-02-51-500/output/packaged-for-endpoint/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "import tensorflow as tf\n",
    "\n",
    "# ---- inputs ----\n",
    "H5_TAR_S3_URI = \"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-18-11-02-51-500/output/model.tar.gz\"\n",
    "\n",
    "ROBUST_SCALER_S3_URI = \"s3://ai-bmi-predictor/scalers/scaler_robust_features.pkl\"\n",
    "HEIGHT_SCALER_S3_URI = \"s3://ai-bmi-predictor/scalers/scaler_standard_features.pkl\"\n",
    "TARGET_SCALER_S3_URI = \"s3://ai-bmi-predictor/scalers/scaler_targets.pkl\"\n",
    "\n",
    "PACKAGED_S3_URI = \"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-18-11-02-51-500/output/packaged-for-endpoint/model.tar.gz\"\n",
    "\n",
    "# ---- helpers ----\n",
    "def parse_s3_uri(uri: str):\n",
    "    p = urlparse(uri)\n",
    "    if p.scheme != \"s3\":\n",
    "        raise ValueError(f\"Invalid S3 URI: {uri}\")\n",
    "    return p.netloc, p.path.lstrip(\"/\")\n",
    "\n",
    "def s3_download(uri: str, local_path: str):\n",
    "    b, k = parse_s3_uri(uri)\n",
    "    boto3.client(\"s3\").download_file(b, k, local_path)\n",
    "\n",
    "def s3_upload(local_path: str, uri: str):\n",
    "    b, k = parse_s3_uri(uri)\n",
    "    boto3.client(\"s3\").upload_file(local_path, b, k)\n",
    "\n",
    "# ---- workspace ----\n",
    "workdir = \"bmi_pkg_endpoint_v2\"\n",
    "extract_dir = os.path.join(workdir, \"extract\")\n",
    "assets_dir = os.path.join(workdir, \"assets\")\n",
    "serving_dir = os.path.join(workdir, \"model\", \"1\")  # REQUIRED path for SavedModel\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "os.makedirs(assets_dir, exist_ok=True)\n",
    "os.makedirs(serving_dir, exist_ok=True)\n",
    "\n",
    "# ---- download & extract original tar (contains .h5) ----\n",
    "local_in_tar = os.path.join(workdir, \"original_model.tar.gz\")\n",
    "s3_download(H5_TAR_S3_URI, local_in_tar)\n",
    "print(\"‚úÖ Downloaded:\", H5_TAR_S3_URI)\n",
    "\n",
    "with tarfile.open(local_in_tar, \"r:gz\") as tar:\n",
    "    tar.extractall(extract_dir)\n",
    "print(\"‚úÖ Extracted original tar\")\n",
    "\n",
    "# ---- locate .h5 ----\n",
    "h5_path = None\n",
    "for root, _, files in os.walk(extract_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".h5\", \".hdf5\")):\n",
    "            h5_path = os.path.join(root, f)\n",
    "            break\n",
    "    if h5_path:\n",
    "        break\n",
    "if not h5_path:\n",
    "    raise ValueError(\"‚ùå No .h5 found in original tar\")\n",
    "\n",
    "print(\"‚úÖ Found H5:\", h5_path)\n",
    "\n",
    "# ---- convert H5 -> SavedModel at model/1/ ----\n",
    "ann = tf.keras.models.load_model(h5_path, compile=False)\n",
    "ann.save(serving_dir, include_optimizer=False, save_format=\"tf\")\n",
    "print(\"‚úÖ Exported SavedModel to:\", serving_dir)\n",
    "\n",
    "# ---- cache EfficientNetB7 imagenet weights locally (not in endpoint) ----\n",
    "_ = tf.keras.applications.EfficientNetB7(weights=\"imagenet\")\n",
    "\n",
    "# ---- copy cached EfficientNetB7 weights into assets/ ----\n",
    "keras_models_dir = os.path.expanduser(\"~/.keras/models\")\n",
    "cands = [os.path.join(keras_models_dir, f) for f in os.listdir(keras_models_dir)\n",
    "         if \"efficientnetb7\" in f.lower() and f.lower().endswith(\".h5\")]\n",
    "if not cands:\n",
    "    raise ValueError(\"‚ùå EfficientNetB7 weights not found in ~/.keras/models\")\n",
    "\n",
    "weights_src = sorted(cands)[-1]\n",
    "weights_dst = os.path.join(assets_dir, \"efficientnetb7_imagenet.h5\")\n",
    "shutil.copy2(weights_src, weights_dst)\n",
    "print(\"‚úÖ Bundled EfficientNet weights:\", weights_dst)\n",
    "\n",
    "# ---- download scalers into assets/ with exact filenames inference.py expects ----\n",
    "s3_download(ROBUST_SCALER_S3_URI, os.path.join(assets_dir, \"scaler_robust_features.pkl\"))\n",
    "s3_download(HEIGHT_SCALER_S3_URI, os.path.join(assets_dir, \"scaler_standard_features.pkl\"))\n",
    "s3_download(TARGET_SCALER_S3_URI, os.path.join(assets_dir, \"scaler_targets.pkl\"))\n",
    "print(\"‚úÖ Bundled scalers into assets/\")\n",
    "\n",
    "# ---- ensure code exists ----\n",
    "assert os.path.exists(\"deploy_bmi/code/inference.py\"), \"‚ùå Missing inference.py\"\n",
    "assert os.path.exists(\"deploy_bmi/code/requirements.txt\"), \"‚ùå Missing requirements.txt\"\n",
    "\n",
    "# ---- build final model.tar.gz ----\n",
    "out_tar = os.path.join(workdir, \"model.tar.gz\")\n",
    "with tarfile.open(out_tar, \"w:gz\") as tar:\n",
    "    tar.add(os.path.join(workdir, \"model\"), arcname=\"model\")      # SavedModel bundle\n",
    "    tar.add(assets_dir, arcname=\"assets\")                         # scalers + effnet weights\n",
    "    tar.add(\"deploy_bmi/code\", arcname=\"code\")                    # inference.py + requirements.txt\n",
    "\n",
    "print(\"‚úÖ Created packaged tar:\", out_tar)\n",
    "\n",
    "# ---- upload ----\n",
    "s3_upload(out_tar, PACKAGED_S3_URI)\n",
    "print(\"‚úÖ Uploaded packaged model:\", PACKAGED_S3_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3855770-b405-49fa-bf44-b9780a44d969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# -------- config --------\n",
    "REGION = boto3.Session().region_name\n",
    "ROLE = get_execution_role()\n",
    "\n",
    "INSTANCE_TYPE = \"ml.g4dn.xlarge\"\n",
    "ENDPOINT_NAME = \"BMI-predcitor-V8-4\"  # use a NEW name\n",
    "MODEL_DATA = \"s3://ai-bmi-predictor/trained-models/efficientnet-models/eff-ann-v8-training-2025-12-18-11-02-51-500/output/packaged-for-endpoint/model.tar.gz\"\n",
    "\n",
    "# ‚úÖ TensorFlow inference DLC (includes python tensorflow)\n",
    "image_uri = image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=REGION,\n",
    "    version=\"2.11\",\n",
    "    py_version=\"py310\",          # set python version here\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=INSTANCE_TYPE,\n",
    ")\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "tf_model = TensorFlowModel(\n",
    "    model_data=MODEL_DATA,\n",
    "    role=ROLE,\n",
    "    framework_version=\"2.11\",    # keep\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"deploy_bmi/code\",\n",
    "    image_uri=image_uri,         # critical\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "predictor = tf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    container_startup_health_check_timeout=1200,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Deployed:\", ENDPOINT_NAME)\n",
    "print(\"‚úÖ Image:\", image_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc156a7-347a-4878-be78-eb35a84aff7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
