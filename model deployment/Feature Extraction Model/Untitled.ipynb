{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2892edbb-1c28-4bf8-bdd5-f19ea3f2576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 15:45:38.642776: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-29 15:45:45.534363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-29 15:45:49.227437: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-29 15:45:49.257270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-29 15:45:54.556281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-29 15:46:03.455611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_S3_URI: s3://ai-bmi-predictor-v2/feature-extraction-data/feature-extraction-efficientnetb7-6/model.tar.gz\n",
      "✅ Using SageMaker Role: arn:aws:iam::252375266853:role/service-role/AmazonSageMaker-ExecutionRole-20250911T180987\n",
      "\n",
      "[STEP 1] Loading EfficientNetB7 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 15:46:10.663410: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.357525: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.360809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.364580: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.367341: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.369889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.807894: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.808992: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.809995: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-29 15:46:16.811754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13760 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7.h5\n",
      "268326632/268326632 [==============================] - 7s 0us/step\n",
      "✅ Feature extractor output shape: (None, 2560)\n",
      "\n",
      "[STEP 1.5] Creating bytes->image->features SavedModel wrapper...\n",
      "\n",
      "[STEP 2] Saving model in TensorFlow SavedModel format...\n",
      "INFO:tensorflow:Assets written to: efficientnet_work/model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_work/model/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: efficientnet_work/model/1\n",
      "\n",
      "[STEP 3] Creating model.tar.gz...\n",
      "✅ Tarball created: efficientnet_work/model.tar.gz\n",
      "\n",
      "[STEP 4] Uploading to S3: s3://ai-bmi-predictor-v2/feature-extraction-data/feature-extraction-efficientnetb7-6/model.tar.gz\n",
      "✅ Model uploaded to: s3://ai-bmi-predictor-v2/feature-extraction-data/feature-extraction-efficientnetb7-6/model.tar.gz\n",
      "\n",
      "[STEP 5] Deploying model to endpoint: feature-extraction-efficientnetb7-6\n",
      "---------!\n",
      "[STEP 6] Enabling autoscaling (Option A: min>=1, max=N)...\n",
      "\n",
      "✅✅✅ SUCCESS! ✅✅✅\n",
      "Endpoint Name: feature-extraction-efficientnetb7-6\n",
      "Region: eu-west-2\n",
      "Model S3 URI: s3://ai-bmi-predictor-v2/feature-extraction-data/feature-extraction-efficientnetb7-6/model.tar.gz\n",
      "Autoscaling Variant: AllTraffic\n",
      "Autoscaling Min: 1  Max: 4\n",
      "Target Invocations/Instance: 50.0\n",
      "\n",
      "Call format: {'instances':[{'image_bytes': {'b64':'<base64>'}}]}\n"
     ]
    }
   ],
   "source": [
    "import os  # file ops\n",
    "import tarfile  # tar.gz create\n",
    "import boto3  # AWS SDK\n",
    "import sagemaker  # SageMaker SDK\n",
    "from sagemaker.tensorflow import TensorFlowModel  # TF model wrapper\n",
    "\n",
    "import tensorflow as tf  # TensorFlow\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input\n",
    "from tensorflow.keras.models import Model  # Model class\n",
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "S3_BUCKET = \"ai-bmi-predictor-v2\"\n",
    "S3_PREFIX = \"feature-extraction-data\"\n",
    "ENDPOINT_NAME = \"feature-extraction-efficientnetb7-6\"\n",
    "INSTANCE_TYPE = \"ml.g4dn.xlarge\"\n",
    "FRAMEWORK_VERSION = \"2.11.0\"\n",
    "\n",
    "# ---- Option A autoscaling settings (min >= 1) ----\n",
    "AUTOSCALING_MIN_CAPACITY = 1\n",
    "AUTOSCALING_MAX_CAPACITY = 4\n",
    "TARGET_INVOCATIONS_PER_INSTANCE = 50.0\n",
    "SCALE_OUT_COOLDOWN_SECONDS = 60\n",
    "SCALE_IN_COOLDOWN_SECONDS = 300\n",
    "\n",
    "# versioned model path (recommended)\n",
    "MODEL_S3_URI = f\"s3://{S3_BUCKET}/{S3_PREFIX}/{ENDPOINT_NAME}/model.tar.gz\"\n",
    "print(f\"MODEL_S3_URI: {MODEL_S3_URI}\")\n",
    "\n",
    "# =========================\n",
    "# Get SageMaker execution role\n",
    "# =========================\n",
    "try:\n",
    "    ROLE  # type: ignore\n",
    "except NameError:\n",
    "    try:\n",
    "        from sagemaker import get_execution_role\n",
    "        ROLE = get_execution_role()\n",
    "    except Exception:\n",
    "        ROLE = None\n",
    "\n",
    "if not ROLE:\n",
    "    raise ValueError(\"ROLE is None. Set ROLE to your SageMaker execution role ARN.\")\n",
    "\n",
    "print(f\"✅ Using SageMaker Role: {ROLE}\")\n",
    "\n",
    "# =========================\n",
    "# Step 1: Build EfficientNetB7 feature extractor\n",
    "# =========================\n",
    "print(\"\\n[STEP 1] Loading EfficientNetB7 model...\")\n",
    "\n",
    "base_model = EfficientNetB7(weights=\"imagenet\")\n",
    "feature_extractor = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "print(f\"✅ Feature extractor output shape: {feature_extractor.output_shape}\")\n",
    "\n",
    "# =========================\n",
    "# Step 1.5: Wrap as SavedModel that accepts BYTES input named 'image_bytes'\n",
    "# TF Serving will decode {\"b64\":\"...\"} into raw bytes automatically.\n",
    "# =========================\n",
    "print(\"\\n[STEP 1.5] Creating bytes->image->features SavedModel wrapper...\")\n",
    "\n",
    "class FeatureServingModule(tf.Module):\n",
    "    def __init__(self, extractor):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string, name=\"image_bytes\")])\n",
    "    def serving_default(self, image_bytes):\n",
    "        # image_bytes: batch of raw image bytes (png/jpg), already decoded by TF Serving\n",
    "\n",
    "        def _decode_resize(x):\n",
    "            img = tf.io.decode_image(x, channels=3, expand_animations=False)\n",
    "            img = tf.image.resize(img, (600, 600))\n",
    "            img = tf.cast(img, tf.float32)\n",
    "            return img\n",
    "\n",
    "        images = tf.map_fn(\n",
    "            _decode_resize,\n",
    "            image_bytes,\n",
    "            fn_output_signature=tf.TensorSpec(shape=(600, 600, 3), dtype=tf.float32),\n",
    "        )\n",
    "\n",
    "        images = preprocess_input(images)\n",
    "        feats = self.extractor(images, training=False)  # (batch, 2560)\n",
    "\n",
    "        return {\"features\": feats}\n",
    "\n",
    "serving_module = FeatureServingModule(feature_extractor)\n",
    "\n",
    "# =========================\n",
    "# Step 2: Save as TensorFlow SavedModel format (model/1/)\n",
    "# =========================\n",
    "print(\"\\n[STEP 2] Saving model in TensorFlow SavedModel format...\")\n",
    "\n",
    "workdir = \"efficientnet_work\"\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "serving_root = os.path.join(workdir, \"model\")\n",
    "version_dir = os.path.join(serving_root, \"1\")\n",
    "os.makedirs(version_dir, exist_ok=True)\n",
    "\n",
    "tf.saved_model.save(\n",
    "    serving_module,\n",
    "    version_dir,\n",
    "    signatures={\"serving_default\": serving_module.serving_default},\n",
    ")\n",
    "\n",
    "print(f\"✅ Model saved to: {version_dir}\")\n",
    "\n",
    "# =========================\n",
    "# Step 3: Create tarball (model.tar.gz)\n",
    "# =========================\n",
    "print(\"\\n[STEP 3] Creating model.tar.gz...\")\n",
    "\n",
    "tarball_path = os.path.join(workdir, \"model.tar.gz\")\n",
    "with tarfile.open(tarball_path, \"w:gz\") as tar:\n",
    "    tar.add(serving_root, arcname=\"model\")\n",
    "\n",
    "print(f\"✅ Tarball created: {tarball_path}\")\n",
    "\n",
    "# =========================\n",
    "# Step 4: Upload tarball to S3\n",
    "# =========================\n",
    "print(f\"\\n[STEP 4] Uploading to S3: {MODEL_S3_URI}\")\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "key = f\"{S3_PREFIX}/{ENDPOINT_NAME}/model.tar.gz\"\n",
    "s3_client.upload_file(tarball_path, S3_BUCKET, key)\n",
    "\n",
    "print(f\"✅ Model uploaded to: {MODEL_S3_URI}\")\n",
    "\n",
    "# =========================\n",
    "# Step 5: Deploy to SageMaker endpoint (PURE TF SERVING)\n",
    "# =========================\n",
    "print(f\"\\n[STEP 5] Deploying model to endpoint: {ENDPOINT_NAME}\")\n",
    "\n",
    "session = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "tf_model = TensorFlowModel(\n",
    "    model_data=MODEL_S3_URI,\n",
    "    role=ROLE,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "predictor = tf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 6: Enable autoscaling (Option A)\n",
    "# =========================\n",
    "print(\"\\n[STEP 6] Enabling autoscaling (Option A: min>=1, max=N)...\")\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "aas = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "# Get the production variant name from the endpoint config\n",
    "ep_desc = sm.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "epc_desc = sm.describe_endpoint_config(EndpointConfigName=ep_desc[\"EndpointConfigName\"])\n",
    "variant_name = epc_desc[\"ProductionVariants\"][0][\"VariantName\"]\n",
    "\n",
    "resource_id = f\"endpoint/{ENDPOINT_NAME}/variant/{variant_name}\"\n",
    "\n",
    "# Register scalable target\n",
    "aas.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=AUTOSCALING_MIN_CAPACITY,\n",
    "    MaxCapacity=AUTOSCALING_MAX_CAPACITY,\n",
    ")\n",
    "\n",
    "# Put scaling policy (target tracking)\n",
    "aas.put_scaling_policy(\n",
    "    PolicyName=f\"{ENDPOINT_NAME}-invocations-tt\",\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\n",
    "        },\n",
    "        \"TargetValue\": TARGET_INVOCATIONS_PER_INSTANCE,\n",
    "        \"ScaleOutCooldown\": SCALE_OUT_COOLDOWN_SECONDS,\n",
    "        \"ScaleInCooldown\": SCALE_IN_COOLDOWN_SECONDS,\n",
    "        \"DisableScaleIn\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\n✅✅✅ SUCCESS! ✅✅✅\")\n",
    "print(f\"Endpoint Name: {ENDPOINT_NAME}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Model S3 URI: {MODEL_S3_URI}\")\n",
    "print(f\"Autoscaling Variant: {variant_name}\")\n",
    "print(f\"Autoscaling Min: {AUTOSCALING_MIN_CAPACITY}  Max: {AUTOSCALING_MAX_CAPACITY}\")\n",
    "print(f\"Target Invocations/Instance: {TARGET_INVOCATIONS_PER_INSTANCE}\")\n",
    "print(\"\\nCall format: {'instances':[{'image_bytes': {'b64':'<base64>'}}]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89be0a-ecea-4957-8406-e89e17a84dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
